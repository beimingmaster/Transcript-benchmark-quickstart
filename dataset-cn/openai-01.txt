A Survey of Techniques for Maximizing LLM Performance - YouTube
https://www.youtube.com/watch?v=ahnGLM-RC1Y

Transcript:
(00:00) [音乐] [鼓掌] -大家好。 我希望你们都喜欢这个主题演讲。 我知道我做到了。 我希望大家 在 OpenAI 首届开发者大会上度过愉快的时光。 在本次分组讨论中， 我们将讨论 在解决 您最关心的问题时可以用来最大限度提高 LLM 绩效的所有不同技术。 自我介绍一下， 我叫约翰·阿拉德。 我是 OpenAI 微调产品团队的工程主管，对于 OpenAI 的 微调来说，这几个月确实非常令人兴奋 。 早在八月份， 我们就推出了 3.5 Turbo 微调， 开发者社区的反响令我们震惊。 我们随后添加了 一些重要的功能， 因此 对函数调用数据进行了微调。 进行持续微调， 您可以采用 现有的微调模型并继续 对其进行微调过程。 我们甚至推出了一个完整的用户界面， 用于在平台内进行微调。 在过去的几个月里， 我们能够 与来自 行业各个角落的开发人员密切合作。 独立开发者、 来自初创公司的开发者
(01:04) 以及来自 地球上一些最大企业的开发者。 我们已经能够看到他们 试图解决的问题是什么， 他们如何尝试使用法学硕士 来解决这些问题， 特别是他们如何尝试 使用法学硕士的微调来解决 这些问题。 我希望今天能与大家分享其中的一些见解 。 话虽如此，我 将转告我的同事科林 让我们开始。 - 谢谢，约翰。 嘿伙计。 我是科林。 很高兴见到你。 我负责我们在欧洲的解决方案实践 ， 这基本上意味着 与我们的一些战略客户合作， 尝试解决 他们最复杂的问题。 您可能会毫不惊讶地 听到，在过去的一年里， 优化一直是 每个人最关注的焦点。 努力让法学硕士可靠地 投入生产。 为何如此受关注？ 优化 LLM 是很困难的。 尽管有所有的框架， 尽管 每个人都发布了所有的内容，尽管人们提供了 所有的指标 和所有不同的工具 。 它仍然是最大的焦点之一， 并且仍然没有 关于如何优化的一站式服务。 这实际上取决于 您遇到的问题类别 以及您如何解决它。 我认为我们 今天希望向您展示的是 找出问题所在 以及如何解决问题的框架，
(02:08) 然后是 您可以用来解决问题的工具。 原因—— 我想，首先是 困难的原因。 很难将 信号与噪声分开。 确切地知道问题是什么。 这是第一处。 第二件事是，法学硕士的表现 可能非常抽象且难以 衡量， 因此很难 知道您遇到的问题有多大。 即使您知道 问题是什么以及 问题的严重程度，也很难 知道使用哪种方法来解决 已识别的问题， 因此这才是今天的重点。 今天的讨论 主要是关于性能最大化。 我们希望 您离开这里时能够了解不同选项 的心理模型 ， 了解何时使用其中一个选项 ， 并有信心继续 自己的优化之旅。 首先， 优化 LLM 性能 并不总是线性的。 很多人都会展示 这样的图表，您从 快速工程开始， 然后继续 进行检索增强生成， 然后继续进行微调， 这就是 优化法学硕士的方法。 这是有问题的， 因为检索增强生成
(03:14) 和微调解决了不同的问题。 有时您需要一个， 有时您需要另一个， 有时您需要两者，具体 取决于 您正在处理的问题的类别。 我们认为它更像是这样的。 您可以在两个轴上进行优化。 其中之一是上下文优化。 模型需要知道什么才能解决 您的问题？ 另一个是LLM优化。 模型需要如何行动？ 为了真正解决您的问题，它 需要执行什么方法 或需要采取什么行动 ？ 您看到的典型流程是 从左下角开始进行 快速工程。 通过快速的工程设计，您可以同时做到这两点。 你只是无法很好地扩展它。 快速工程始终是 最好的起点。 你可以很快地测试和学习， 你应该做的第一件事是 从提示开始， 进行评估， 弄清楚你将如何 一致地评估你的输出。 从那里你可以决定， 这是一个上下文问题 还是这是我们需要 模型如何行动的问题？ 如果您需要更多上下文 或更多相关上下文， 那么您可以使用 检索增强生成 或 RAG。 如果您需要遵循更一致的指令 ， 那么您可以直接进行微调。
(04:17) 这两件事叠加在一起， 它们是相加的，所以有时 你的问题需要两者兼而有之。 我们将为您提供 一些例子，说明人们在哪里 只使用了一两个，以及在哪里人们 已经使用了所有这些来解决 他们的问题。 典型的优化之旅 通常看起来很像这样。 您从左下角开始， 收到提示， 创建评估， 然后找出基线 是什么。 然后通常是简单的下一步， 添加少量示例。 为 模型提供几个输入、 输出示例，说明您希望 模型如何运行。 可以说，在这一点上， 实际上那些很少的例子 大大提高了性能， 所以让我们将其连接到某种 知识库， 我们可以将该过程工业化， 这通常是人们 添加某种 检索增强生成的地方 。 假设它现在有了上下文， 但它并没有以我们每次想要的 格式或风格准确地生成输出 ， 因此我们可能会微调模型。 然后，经典的下一步可能是 检索并不 像您希望的那么好。 也许该内容可能 与模型的需求更相关。 然后您返回并 再次优化检索增强生成。
(05:22) 现在您已经再次优化了 检索增强生成， 您希望使用在 更新的 检索增强生成中引入的这些新示例再次微调您的模型。 这是我们看到的 经典优化流程的一个例子 。 如果我可以用 最简单的术语来概括它， 你尝试一些东西， 你评估， 然后你尝试其他东西。 这是最简单的说法。 现在 让我们深入研究 每个象限。 我们将从左下角开始进行 快速工程， 然后我们将继续 进行检索增强生成和 微调。 然后我们将通过 我和约翰接受的实际挑战来尝试这一切，并向您展示 这在实践中是如何运作的。 及时工程。 现在，我知道 观众中的大多数人都会非常 非常熟悉这一点， 因此我们将以 合理的速度跳过这一点， 但最好总是开始 并确保每个人都了解 这里的原则。 及时工程。 这里有一些策略。 这来自 我们文档中的最佳实践， 但只是回顾一下。 首先，写出明确的指示。 我将举一个例子来说明这意味着什么， 但这通常是人们首先跌倒的地方 。
(06:27) 其次，将复杂的任务分解 为更简单的子任务。 如果您可以想象该模型 正在尝试对您要解决的 每个子单元或子任务进行预测或一系列预测 ，那么您应该给它 尽可能具体的指令 来分解该问题，以便它能够 更好的机会去执行它。 同样，给 GPT 时间思考。 我将向您提供一个人们用来执行此操作的 非常常见的框架的示例 。 最后一件事—— 我已经提到过这一点， 但测试会系统地改变。 很多时候，我们看到我们的客户最终陷入 这种打地鼠的境地， 他们改变一件事， 他们改变另一件事， 他们改变另一件事。 他们只是 在评估矩阵上跳来跳去， 他们不觉得自己正在朝着 正确的方向前进。 这确实是您需要 一组可靠的评估和通常 某种 LLMOps 的地方， 以便您可以 在更改这些内容时系统地测量它们。 之后，最常见的下一步 是将其扩展到参考文本 或使其能够访问外部工具， 这将我们更多地带 入 检索增强生成领域。 首先，让我们回顾一下 它们在实践中的样子。 首先， 关于快速工程的一些直觉。
(07:32) 提示工程，已经说过 几次了，我会再说一遍，这是 最好的起点，实际上也可以是 一个很好的终点，具体 取决于您的用例。 有 什么用？ 尽早进行测试和学习， 并将其 与评估结合起来， 为进一步优化提供基线。 应该永远是你开始的地方。 有 什么不好呢？ 一些东西。 介绍新信息。 您可以将相当 多的信息打包到提示中， 实际上，使用 GPT-4 Turbo， 您现在可以将大量信息打包 到提示中。 也就是说，这并不是一种 使用即时工程来实现此目的的超级可扩展方法。 我们将看到几种 可以 使用其他方法来解决这个问题的方法。 此外，可靠地复制复杂的样式 或方法，同样 受到上下文窗口 在 实际可以向模型显示的示例数量方面的限制。 这是一个很好的起点， 但 根据您任务的复杂程度， 可能无法实现这一目标。 最后一件事是最大限度地减少令牌的使用，这是即时工程中 非常常见的问题 。 你不断地遇到问题， 并不断地 在提示中添加越来越多的方面来实际处理 这些问题， 最终你会使用 越来越多的令牌， 这会导致你的延迟、 成本等等。
(08:35) 再次强调，快速工程并不是 解决 该特定问题的好方法。 快速回顾不该做的事情， 按照提示做的事情。 我们在这里得到了一个非常糟糕的提示，其中 包含一些模糊的说明 和一些相当随机的输出， 并且只是回顾了几种 改进方法。 明确的指示。 准确地告诉它它将 面临什么 以及它的任务是什么。 给时间思考。 这不是 一个特别好的例子。 我告诉它 一步一步地完成任务，等等， 但是给它时间思考 我会想到更多的东西， 比如反应框架，你可以让它 写出推理步骤。 它基本上是在帮助 自己找到答案。 React 框架只是 实现这一目标的一种方法， 但是给 GPT 时间 思考是另一种很好的方法，可以处理您 需要它执行的一些非常复杂的逻辑推理，因为它会 在结束时完成。 那天， 它是下一个令牌预测器。 它正在打印所需的标记， 以帮助它更接近答案，具体取决于 提示的强度。 最后一件事 是将复杂的任务分解 为更简单的任务。 在这种情况下， 我提到将每一步都
(09:40) 视为一个预测。 在这种情况下，只需将它们 尽可能清晰地布置即可。 在右侧，我们可以看到 格式相当漂亮的 JSON 输出。 再说一遍，只是基础知识， 但只是想在 继续之前回顾一下这些内容。 共同的下一步。 在 提示工程中，您 基本上试图告诉模型 您想要如何行动， 但通常很难真正 知道哪些标记 实际上对 模型影响最大？ 一个很好的开始方式实际上是将 其作为一个展示问题 而不是讲述问题来处理。 只需提供一些示例， 即可为其提供输入和输出对， 并实际向其显示 您希望其具有的行为。 这很好地引导我们进入 下一步， 通常人们会看到 一些良好的性能改进。 我们将 在实践部分看到，这 给我们所 承担的实际任务带来了很大的提升。 他们希望将其工业化， 并且希望这些少数示例 能够 基于用户的问题 或基于 该特定问题的上下文。 人们通常会在这种情况下进行 几次尝试，然后转向 检索增强生成（ RAG）。
(10:45) 让我们直接开始吧。在 真正开始 RAG 之前， 我只想给您 一个快速的心理模型， 让您了解基本上该去哪里。 我们从快速工程开始。 我们已经评估， 我们已经确定了差距， 现在我们正在尝试确定它 是否是我们需要的 检索增强一代 ，或者是否是 我们需要的微调。 有时将其视为 短期记忆 与长期记忆问题是有用的。 如果我们认为这可能是在 准备考试。 您的提示是向他们提供 完成考试所需的说明。 微调就像 您之前为学习 回答这些问题所需的方法和实际框架所做的所有学习一样。 检索增强生成 就像 在他们真正去考试时给他们一本打开的书。 如果他们知道方法论 并且知道需要寻找什么， 那么检索增强生成 意味着他们可以打开书本， 转到正确的页面， 并实际提取 他们需要的内容。 这就是为什么这两件事 解决的问题截然不同。 没有方法论 ，没有内容，就 不可能 解决某些问题。 在这种情况下，我们假设 我们有 短期记忆问题。 我们希望为模型提供回答问题 所需的正确上下文
(11:49) 。 检索增强生成 （RAG）就是让 模型访问特定领域 的内容。 快速回顾一下 RAG 是什么。 我知道， 房间里的大多数人都会 很熟悉，但我只是 为了所有人的利益而回顾一下这一点。 您通常会从某种 知识库或某个领域开始， 您希望获得一些内容来 回答这些问题。 在这种情况下，我们将 使用一个相当典型的流程， 即我们有一些文档， 我们将嵌入它们， 我们将它们粘贴在某个地方。 再说一遍，我知道人们 可能有 自己的搜索服务， 他们会使用的所有文档来源， 这很公平。 对于这个例子，我们假设 我们有一些文档， 我们嵌入它们，我们创建一个知识库。 然后当用户进来时， 他们会问一个问题。 比方说，“加拿大有多少 人口？” 我们将去，而 不是直接将其提供 给法学硕士，我们将 使用某种搜索在我们的知识库中激发它 。 假设我们进行相似性搜索。 我们将撤回一些内容。 我们有一些内容说明了 加拿大的人口数量。 然后我们将把 它与提示结合起来。 我们将把它交给 LML 并说：“这是问题。 这是内容。 用这个内容回答这个问题。” 希望
(12:54) 我们最终会得到一个 正确的答案。 快速回顾一下 RAG。 正如我们在即时工程方面所做的那样， 我想分享一些 我们在 何时应该使用 RAG 以及何时不应该使用 RAG 方面发展起来的直觉。 RAG 的好处是， 再次向模型引入新信息 以更新其知识。 这是 您现在可以做到这一点的少数方法之一。 这实际上是客户遇到的最大问题之一 。 他们会说， “嘿，我有 100,000 个文档。 我希望模型只知道 这些文档。” 不幸的是，目前还 没有超级可扩展的方法来获取 这 100,000 个文档 并同时提供所有这些文档的模型知识 。 检索增强生成 可能 与您现在所能达到的最接近， 即我们将 根据 您希望它解决的特定问题为其提供一些上下文知识。 同样， 通过控制内容来减少幻觉是 使用 检索增强生成的非常常见的用例之一。 稍后我们会看到 它如何 与微调完美结合。 一个典型的用例 是您为模型提供内容，并 指示它仅使用 该内容来回答问题， 而不使用其知识。 这是人们 尝试将知识限制
(13:59) 在特定知识库 并减少幻觉的典型方式。 这有什么不好。 我在那里提到了它，但嵌入了 对广泛领域的理解。 目前，检索增强一代 不允许你教它 什么是法律或医学。 不幸的是，这不是 检索增强生成 可以让您做的事情之一。 同样，教授模型学习 新的语言格式或风格。 这可能是你更多地 处于微调领域的地方， 你试图 教它一种方法 或一种解决 问题的方法。 再次，减少代币使用。 事实上，您将 在 RAG 中添加更多、更多的令牌。 您将继续添加 输入/输出示例。 我经常看到人们先进行快速工程， 然后进行 RAG，因为 他们要做的第一件事就是将准确性 达到他们满意的水平， 然后他们会尝试将 代币从这个过程中剥离出来。 约翰稍后会告诉你 更多相关内容。 这就是 RAG， 您实际上只是在尝试优化， 为其提供 回答问题所需的尽可能多的上下文。 我想在这里分享一个成功的故事， 因为有了快速的工程和 RAG，
(15:05) 听起来这些事情 可能很简单， 但实际上很难。 需要大量的迭代 、大量的测试和学习 才能真正实现这一点。 在 这个例子中，客户 拥有一个包含 两个不同知识库的 RAG 管道， 然后是一个法学硕士。 它的工作是获取用户的问题， 决定使用哪个知识库， 触发查询，并用 它来回答问题。 当我们开始时， 我们只是实现了检索， 并且与他们进行了大量的交谈。 我们都 对嵌入的效果有多好 以及这将有多容易感到非常兴奋。 我们的基线准确率是 45%， 所以不是那么好。 然后 我们尝试了 一大堆东西 ，我在它们旁边画了一些小勾号和叉号， 以显示我们尝试了多少东西 以及有多少东西 实际投入生产。 带有刻度的东西是 我们实际投入生产的东西。 带有十字架的东西是 我们尝试过并丢弃的东西。 通过尝试假设的文档嵌入，我们成功地将其提高到 65% 。 您 不是对问题进行相似性搜索 ，而是 生成一个假答案 并对其进行相似性搜索。 对于某些用例来说， 这非常有效，但对于这个用例， 它效果不佳。 我们还尝试微调嵌入， 实际上 根据训练集更改嵌入空间，我们 必须真正帮助模型获得
(16:11) 正确的答案。 再说一次，从准确性的角度来看，这实际上工作得很好， 但它是如此昂贵且如此缓慢， 以至于我们实际上不得不 因为非功能原因而放弃。 我们做的最后一件事是分块 和嵌入。 尝试不同大小 的信息块 并嵌入不同的内容， 以尝试帮助模型辨别 最相关的内容。 同样，我们获得了 20% 的提升， 但距离 能够 呈现在客户面前的目标还相去甚远。 我们 可能经历了 20 次迭代 才达到 65%。 在这个阶段，我们会想， “对，我们要 停止这件事吗？” 但我们坚持了下来， 然后尝试重新排名。 应用交叉编码器 对结果重新排序 或使用基于规则的内容，例如 “哦，好吧，这是研究。 也许我们想要最新的文档”， 类似这样。 事实上，我们的性能得到了 很大的提升。 还有，分类。 基本上，让模型对这两个域进行分类， 然后根据它被分类到哪个域，在提示中实际提供额外的元数据， 以帮助它确定哪些内容 最有可能相关。 在这种情况下，再次， 相当好的碰撞，85%。
(17:16) 我们现在看起来正处于 投入生产的风口浪尖。 然后我们尝试的最后一件事 是进一步的快速工程。 我们回到起点， 实际上尝试更好地设计提示 。 然后我们查看了我们做错的 问题类别， 然后介绍了工具。 例如，我们注意到 存在结构化数据问题， 需要从 这些文档中提取数据。 我们决定做的 只是让它 访问 SQL 数据库，它只需 输入变量并执行查询， 然后实际返回 结构化数据答案。 最后一件事是查询扩展， 有人问 三个问题， 然后您将它们解析 为查询列表。 然后并行执行所有这些， 带回结果， 然后将它们合成为一个结果。 这些因素加在一起使 我们达到了 98% 的准确率。 在此过程中， 我们从未使用微调。 我想指出这一点，因为 正如我们在开始时所说的那样， 假设 通常需要微调 才能投入生产。 实际上，在这种情况下， 我们处理的每个问题 都是上下文。 要么是我们没有给它 正确的上下文，要么它不知道 哪个上下文块 是正确的。
(18:19) 这就是为什么了解 我们要解决的问题是什么如此重要？ 因为如果我们在任何时候 进行微调， 那就会浪费金钱 和时间。 这就是为什么这是一个令 我们满意的成功故事。 我想我想给出 一个稍微不同的—— 酷，谢谢。 [笑] [鼓掌] 甜甜的。 我也想讲一个警示故事， 因为有时 RAG—— RAG 很棒， 你拥有所有这些很棒的内容， 我们将用 它来回答问题的模型， 但它也可能会适得其反。 我会给你 一个不同的客户例子。 我们有一位客户， 他们有其中之一—— 他们试图 通过使用检索增强生成来减少幻觉。 他们告诉模型， 你只能使用你的内容。 然后他们有人工贴标签员来 检查并将事物标记 为幻觉。 其中一个， 我们有一个有趣的人在顾客面前， 他们说，“有什么好听的曲子可以让我们 兴奋起来？” 这位模特带着 Journey 的《 Don’t Stop Believin'》回归 。 [笑] 贴标签者说，“对， 这绝对是幻觉”， 但幸运的是 这不是幻觉，
(19:23) 这实际上是他们的内容。 有人写了一份文件，上面写着 “激发 财务分析活力的最佳歌曲”。 答案就是“不要停止相信”。 这有点有趣， 也是 RAG 的一个例子。 如果您告诉模型仅使用 内容并且您的搜索效果不好， 那么您的模型 获得正确答案的机会为 0%。 我之所以指出这一点，是因为 当您评估 RAG 时， 您实际上添加了可能出错的 整个其他轴 。 这就像我们的法学硕士 可能会犯错误， 然后我们进行搜索， 这不是解决问题。 这就是为什么我想提及 开源社区 提出的几个评估框架， 我想特别提及 爆炸梯度。 他们开发了这个 名为 Ragas 的框架，这很酷。 它基本上分解了 这些不同的评估指标， 您基本上可以 在 GitHub 上将其下载 并直接开箱即用， 或者只是根据您的需求进行调整。 基本上， 它衡量四个指标。
(20:28) 其中两个衡量 法学硕士回答问题的程度， 另外两个衡量 内容与问题的实际相关程度。 如果我们从LLM方面开始， 第一个就是忠诚。 它获取答案 并将其分解为事实， 然后将每个 事实与内容相协调。 如果它不能与事实相符， 那就是幻觉。 然后，它返回一个数字， 如果你的数字 高于某个阈值， 你就会阻止它，因为你基本上发现了 幻觉。 这是从中得出的一个非常有用的指标 。 另一个是答案的相关性。 很多时候模型 会得到一堆内容， 然后它会做出一个 充分利用 这些内容的答案，但实际上 与用户最初询问的内容无关。 这就是该指标实际测量的内容。 如果你发现，“好吧，事实上， 这一切都是正确的， 但是我们的相关性非常低， 这意味着模型实际上 - 我们可能需要提示工程师， 我们可能需要在这里做一些事情 来真正让模型付出代价 更多地关注这个问题，如果情况并非如此， 实际上决定不使用 该内容。” 这是法学硕士方面的问题，但另一方面 是内容的相关性， 这就是我发现它对我的客户最有用的地方 ，
(21:33) 因为正如我们之前提到的， Ragas 的经典示例 只是将越来越多的内容 上下文进入上下文窗口。 就像，“嘿。如果我们给它 50 个块， 它就会得到正确的答案”， 但事实是，模型在 很多时候实际上最终会得到错误的结果—— 有一篇论文 上面写着，它被称为迷失 在中间，就像是， “你提供的内容越多， 实际上模型开始 产生幻觉或开始忘记 中间的内容就越多。” 实际上，您想要的是 最精确的内容片段， 这就是该指标评估 检索内容的信噪比的地方。 它获取每个内容块 并将其与答案进行比较， 并找出 该答案中是否使用了该内容。 这就是你开始 思考的地方，“好吧， 我们获得了非常高的准确度， 但我们可能只有 5% 的上下文精度。 我们实际上可以 带回更少的内容 并仍然获得正确的答案吗？” 我认为这是 人们真正有用的领域之一，他们 开始思考类似的问题—— 有时人们开始生产 或接近生产， 然后本能 就是越来越多的背景。 实际上，这个指标为您提供了 一种非常可靠的计算方法，
(22:38) 就像添加更多上下文 实际上对我们有帮助一样。 最后一个是上下文回忆， 那么它能检索出 所有需要的相关信息吗？ 基本上， 您需要回答该问题的相关信息是否 确实存在于内容中？ 这是相反的问题。 就像，“我们是否有一个搜索， 以及它推到顶部的内容， 我们实际上将其放入 上下文窗口中？ 它实际上回答了问题吗？” 如果这个值非常低， 这表明您需要 优化搜索， 您可能需要添加重新排名， 您可能需要微调 您的嵌入，或者尝试 不同的嵌入以实际呈现 更相关的内容。 我想，我想把这个留给你们， 因为这就像我们试图 从即时工程和 RAG 中榨取尽可能多的性能。 有时， 您想要回答的问题又是不同的。 有时，实际上是 你要执行的任务 才是问题所在， 这就是你需要采取 侧向步骤 并实际尝试进行微调的地方， 这就是我 将把你交给约翰 来处理的地方 你进一步。 [鼓掌]-我们 来谈谈微调。
(23:46) 到目前为止， 我们一直在关注 提示技术系列。 在 这里，您可以找到在采样时 打包 LLM 上下文窗口的巧妙方法， 以优化 LLM 在您的任务中的性能。 微调实际上是 一种与提示完全不同的技术 。 首先从定义开始， 进行微调，特别是 在大型语言模型的背景下， 是指我们采用现有的经过训练的模型， 然后在更 小且通常更领域的新数据集上继续训练过程 - 比训练模型的原始数据集特定 。 微调实际上是 一个变革过程， 我们本质上采用一个基本模型， 对其进行微调，最终 得到一个完全不同的模型。 回顾一下， 微调这个名字确实是对 这个过程的一个很好的描述， 所以我们从 一些 在巨大 且多样化的数据集上训练过的模型开始。 像 3.
(24:40) 5 Turbo 或 GPT-4 这样的模型 有很多关于世界的非常普遍的知识 。 我们采用这些非常通用的模型之一， 并对它们进行专门化，从 本质上磨练它们的能力， 使它们更适合 我们关心的任务。 为什么一开始要进行微调 ？ 现在，我真的想 强调微调的两个主要 且相关的好处。 首先，微调 通常可以让您达到不进行微调就不可能达到的 性能水平 。 只是为了在 这里规划一点直觉， 当您使用提示技术时， 当涉及到 可以显示模型的数据量时，您会受到模型上下文大小的限制，对吧？ 在低端， 这可能需要几千个令牌， 在高端， 如果您使用 GPT-4 Turbo，可能需要 128,000 个令牌， 但实际上，与 您可以显示模型的数据量相比，这根本不算什么 当你在微调的时候。 对数百万 或数亿个数据令牌进行微调是非常简单的。 你可以在 微调的同时向模型展示更多的例子，甚至 比你希望打包 到 最大的法学硕士的上下文窗口中的例子还要多。 第二个好处是， 微调模型 通常比相应的基础模型更有效地进行交互 。 这种效率有两种体现方式。
(25:46) 首先， 当您 与微调的模型交互时， 您通常不必使用复杂 的提示技术来达到该模型 所需的性能水平 。 您通常不必 提供复杂的说明， 不必提供 显式模式，也 不必提供 上下文示例。 这意味着您 每个请求发送的提示令牌更少， 这意味着每个请求 既便宜又通常 响应更快。 与经过微调的模型进行交互 具有更高的延迟和成本效益 。 接下来，微调的常见用例 本质上是将 知识 从 GPT-4 等非常大的模型升华 到 3.5 Turbo 等较小模型。 从成本 和延迟的角度来看，与 较小的模型交互总是比与较大的模型交互更有效。 让我们看一个例子。 这是 某人可能希望 通过法学硕士来解决的常见任务的示例。 我们在这里所做的 本质上是对房地产列表进行 自然语言描述， 并尝试提取有关该列表的 一些结构化信息 。 如果我们要尝试在 不进行微调的情况下解决这个问题， 我们实际上会打开 提示技术的工具箱，
(26:50) 并编写 一些复杂的指令。 我们可能会提供一个 我们希望模型输出的显式模式。 这里它被定义 为 Python 中的 Pydantic 模型。 我们甚至可能会 为模型提供一些上下文示例。 然后， 我们将为模型提供 新的房地产列表 和自然语言， 它将为我们提供一些输出。 输出相当不错， 但这里实际上有一个错误， 而且是一个非常微不足道的错误。 它 没有提取 我们想要的日期，而是将其模板 化为当前日期。 解决这个问题非常简单。 我们可以添加一个新规则， 我们本质上可以添加 一个新的上下文示例， 并且我们可能可以解决这个问题。 让我们看看如何 通过微调来解决这个问题。 通过微调，我们要做的 是 从一个相对简单的数据集开始。 这里我们有一些例子， 我希望你注意到 这些例子的简单性。 没有复杂的说明， 没有正式的模式，也 没有上下文示例。 我们提供的只是房地产列表的自然 语言描述， 然后是所需的结构化输出。 我们采用这个数据集 并微调模型， 然后采用这个微调模型， 给它一个新的房地产列表， 我们可以看到它基本上解决了 这种情况下的问题。
(27:57) 这只是一个简单的示例，但 在这种情况下， 该模型 既高性能又高效。 在采样时，我们不必 提供复杂的指令， 没有上下文学习， 没有显式模式， 并且模型 比我们 仅使用提示技术做得更好。 微调可能是 一个相当复杂的过程， 因此重要的是要设置 适当的期望， 了解微调何时可能适用 于您的用例， 何时可能不起作用。 微调对于强调 基础模型中已经存在的知识确实很有好处。 文本转 SQL 任务就是一个例子。 您拥有 这些非常强大的通用基础模型， 例如 3.5 Turbo 和 GPT-4， 它们真正了解 有关 SQL 的一切、SQL 语法、 SQL 的不同方言、 数据库如何工作， 所有这些事情， 但您可能 想要微调模型 以从本质上强调 某种 SQL 方言，或者强制 模型不要 进入特别 容易出错的边缘情况。 您本质上是 在获取基本模型中存在的知识， 并强调其中的一个子集。 微调 对于修改或自定义 模型输出的结构或基调也非常有用。 微调的
(29:00) 早期杀手级用例之一 是强制模型 输出有效的 JSON， 因为如果您尝试以 编程方式与模型进行交互，则 很容易以 编程方式处理得到有效的 JSON。 如果它是无效的 JSON，则会 出现许多错误情况。 最后，教授 一个模型复杂的指令， 嗯，这是出于 我前面提到的原因。 只是您可以 在微调过程中显示模型， 比您希望打包 到模型上下文窗口中的示例多得多。 另一方面，微调 确实不利于 向模型添加新知识。 在这些非常大的预培训过程中，法学硕士中存在的知识被印入了法学硕士中。 在这些有限的微调运行期间， 您基本上无法 获得新知识。 如果您正在尝试将新知识 带入模型中，那么出于 Colin 刚才提到的所有原因，您确实想看看 RAG 之类的东西 。 其次，微调 对于快速迭代新用例来说并不是很好。 如果你进行微调， 这是一个相对较慢的反馈循环。 创建数据集 和所有其他 微调组件需要大量投资。 不要从它开始。 我本质上想看 一个微调的成功故事，
(30:05) 这个故事 来自我们 Canva 的朋友。 这里的任务本质上是对用户想要的设计模型进行 自然语言 描述 ， 将其交给法学硕士， 并让法学硕士输出 一组结构化的设计指南。 然后， 他们可以使用 这些结构化设计指南 来生成全尺寸的模拟并将 其呈现给用户，因此这本质上是一种 抛出一些想法 并获得全尺寸模拟的快速方法。 在这里，用户会说： “我想要红色渐变。 我想要 一张 Instagram 帖子风格的个人资料照片。” 它进入了法学硕士， 并且应该输出 一些非常结构化的东西。 它有一个标题。 它的样式包含一组 已知关键字中的几个关键字。 它有对英雄图像的描述， 然后它有一个实际的搜索， 他们将向 图像搜索引擎提供这些搜索以生成 这些全尺寸模型的图像。 Canva 所做的 是，他们基本上从 基本模型中的 3.
(30:55) 5 Turbo 开始， 然后从 GPT-4 开始。 他们想从本质上了解 这项任务的表现如何。 表现不是很好， 所以它们基本上是 由人类专家评估员进行评估的。 他们发现， 虽然这些模型可以输出 合理的输出，但从设计的角度来看， 这些输出 实际上是无关紧要的 。 然后他们继续进行微调。 他们基本上 针对这项任务对 3.5 Turbo 进行了微调，并且对结果感到非常震惊 ，因此它不仅击败了 基础 3.5 Turbo 模型， 而且实际上 远远优于 GPT-4。 我们在这里看到的规模 是，虽然 3.5 Turbo 和 GPT-4 通常输出合理 但不相关的设计模型，但 微调 3.5 Turbo 在 Canva 内的专家评估员评估时通常输出 相当好的设计模型 。 如果您想 思考为什么这个用例有效， 那么一开始就不需要新知识。 解决这个问题所需的所有知识都 存在于基础模型中， 但是模型需要输出， 它需要一个非常具体的 输出结构。 然后他们使用了 非常高质量的训练数据， 并且他们有非常好的基线 来比较两者。
(31:58) 他们基本上评估了 3.5 Turbo， 他们评估了 GPT-4， 他们了解他们在哪里成功了， 在哪里没有成功，所以他们 知道微调将 是一种很好的技术来完成 这项任务或 用于此任务。 我想讲一个 关于微调的警示故事。 我非常喜欢这篇精彩博客文章的作者。 他们一直在尝试 用人工智能助手来 充当写作助手。 他们尝试了 Chat GPT， 尝试了 API 中的一些基本模型，给他们留下了 深刻的印象， 但令他们失望的 是这些模型没有捕捉到 他们的语气。 他们 在撰写 博客文章或社交媒体帖子 或起草电子邮件时使用非常特定的语气， 而基本模型 并没有捕捉到这种语气。 他们有一个好主意，他们说： “我要下载两年的 Slack 消息”，总共 140,000 条消息 。 他们编写了一个脚本，将 这些 Slack 消息格式化为 与微调兼容的数据格式， 然后 在这些 Slack 消息上微调 3.
(32:50) 5 Turbo。 一个漫长的过程。 您必须收集数据， 聚合数据，将 其发送为 与微调兼容的格式， 以微调模型。 他们最终经历了这个过程， 得到了一个经过微调的模型， 并要求它做一些事情。 他们说：“你能给我写一篇关于即时工程的 500 字博客文章吗 ？” 这个模型， 这个个性化的写作助理 回答说： “当然，我会在早上做。” [笑声] - 我肯定有点惊讶和震惊， 他跟进说， “我更喜欢你现在写。” [笑声 - 模型说，“好吧”， 然后什么也不做。 [笑声] - 我们 在微调团队中确实得到了很大的乐趣，而且作者真是 一位伟大的运动家， 但如果我们退后一步进行 第二次微调，那么 这里真的很有效。 本质上，作者 想要的是一个可以复制 他们写作风格的模型。 他们得到的是一个 可以复制他们写作风格的模型， 但是他们的 Slack 写作风格。
(33:53) 如果您考虑一下 在 Slack 上的沟通方式，就会发现 它非常简洁。 这是意识流风格。 你经常放弃标点符号， 放弃语法正确性。 他们得到的是一个 复制的模型。 虽然微调模型 来复制你的语气实际上是 一个相对较好的微调用例 ，但 这里的错误是他们 没有充分考虑他们为 模型提供的数据是否真的复制了 他们想要的最终行为 从那个模型。 他们可能应该 在这里做的是获取 一百条 Slack 消息、 200 条 Slack 消息， 用它微调模型实验， 看看它是否朝着 正确的方向发展。 它是否越来越接近 我希望模型复制的基调？ 他们很快就会发现情况 并非如此， 然后也许他们会 在电子邮件 、博客文章 或社交媒体帖子上对其进行微调，也许 这会更合适。 我们已经看到了一些例子， 我们已经形成了一些直觉， 那么实际上如何去 微调模型呢？ 与任何 ML 问题一样， 第一步是 获取数据集， 并且与大多数 ML 问题一样， 这实际上是最困难的部分。 获取数据集的一些方法， 您可以下载开源数据集， 您可以在私人市场上购买数据， 您可以付费人工标记员 来收集 数据并为您标记它，
(34:59) 或者您通常可以 从 如果 该模型的服务条款支持 该特定用例，则可以使用更大的模型， 但在某种程度上，您本质上 必须拿出一个数据 集来进行微调。 接下来，您将开始 培训过程。 根据您尝试进行训练的方式，这会有很大差异。 如果您使用 像 OpenAI 微调 API 这样的交钥匙解决方案， 这可能相对简单。 如果您正在尝试微调 开源模型，这是完全可行的。 你只需要拥有 自己的 GPU，使用一个框架， 这会涉及更多一些。 在训练时，从 本质上了解 可 在训练过程中调整的超参数非常重要，对吧？ 你是否更有可能过度拟合， 是否更有可能欠拟合？ 你要把它微调 到灾难性遗忘的地步吗？ 重要的是要了解 可用的超参数 以及它们 对最终微调模型的影响。 接下来，我想指出 理解 损失函数非常重要。 当你微调 LLM 时， 实际上当你查看 损失函数时， 它是下一个 token 预测的代理。 当您微调 LLM 时，这非常有用， 但下一个标记预测 通常 与您关心的下游任务的性能没有很好的相关性 。
(36:05) 如果您考虑代码生成，则可以通过 多种不同类型的方式 编写代码来解决单个问题， 因此，如果您只是进行 下一个标记预测 和精确标记匹配，则模型损失函数的 损失或变化 可能会 与 下游任务的性能变化无关。 理解这一点很重要。 接下来您要评估模型。 有几种不同的方法来评估 模型。 从 本质上讲，您可以聘请 专家来查看输出 并在一定程度上对它们进行实际排名。 另一种技术是， 您本质上可以采用 不同的模型， 从中生成输出， 然后将它们 相互排名。 没有绝对排名，但做 一些类似于从国际象棋中获得的 ELO 分数之类的事情 。 您还可以做一些事情， 例如拥有更强大的模型，为 您对输出进行排名。 使用 GPT-4 对 微调的 开源模型或 GPT 3.
(36:57) 5 Turbo 的输出进行排名确实很常见。 最后，您想要实际部署它， 然后在推理时从中进行采样。 最后三点可以形成 某种反馈循环 和数据反馈循环。 您基本上可以训练模型， 评估它，将其部署到生产中， 在生产中收集样本， 使用它来构建新的数据集，对 数据集进行下采样， 对其进行一些整理，然后 进一步微调 数据集并让 飞轮在这里运行。 到目前为止， 我们已经讨论了其中的一些 内容， 但我想正式确定我们在微调方面推荐的 一些最佳实践 。 首先是 从快速工程 和少量学习开始。 这些 都是非常简单的低投资技术。 他们会给你一些 关于法学硕士如何运作以及他们如何解决 你的问题的直觉。 这只是一个很好的起点。 接下来， 在进行微调之前建立基线非常重要。 这与 Canva 的成功故事有关。 他们尝试了 3.
(37:46) 5 涡轮增压。 他们用 GPT-4 进行了实验。 他们 对自己 试图解决的问题的来龙去脉有了很好的了解。 他们了解 这些模型的失败案例， 了解模型在哪些方面 表现良好， 因此他们准确地了解 微调的目标。 最后，在 微调方面，从小事做起， 不要下载 140,000 条 Slack 消息， 然后一次性完成。 开发一个小型高质量数据集， 进行微调， 然后评估您的模型并查看 您是否在朝着正确的方向前进。 您可以 在这里做一些诸如主动学习方法之类的事情。 在微调模型时， 您可以查看其输出， 了解它在哪些领域陷入困境， 然后使用 新数据专门针对这些领域。 这是非常有意的投资， 对于法学硕士来说， 微调数据质量胜过 数据数量，这一点非常重要。 训练过程的 数据量部分 是在预训练中完成的。 现在，您似乎真的想专注 于更少的高质量示例。 只是谈谈微调和 RAG， 所以如果你想将它们结合在一起， 对于某些用例， 它可能是两全其美的。 通常，其工作原理是 您微调模型 以理解复杂的指令， 然后您不再需要提供
(38:51) 这些复杂的指令。 采样时的少量示例。 您本质上是对模型进行微调， 使其使用起来非常高效。 这意味着 您基本上已经最大限度地减少了 采样时需要提供的提示标记， 因为您不再需要 进行复杂的提示工程。 它被烘焙到微调的模型中。 这意味着您有 更多空间用于检索上下文。 然后，您可以使用 RAG 将 相关知识注入上下文中，此时 可用的上下文 基本上已经最大化 。 现在，当然，您必须小心 不要使上下文过度饱和， 这可能 与 您试图解决的实际问题存在虚假相关性， 但本质上是 在上下文窗口中打开空间以 用于更重要的目的 。 话虽如此， 我们一直在讨论理论， 直到演讲的这一点， 我们现在要 讨论该系列的应用。 我会把它转回 给科林，让我们继续前进。 - 谢谢，约翰。 [鼓掌] -酷。 让我们来看看所有这些理论。 我们决定解决的问题 是 Spider 1.
(39:54) 0 基准测试， 因此有效地给定 自然语言问题 和数据库模式， 您能否生成 语法正确的 SQL 查询 来回答该问题。 一个例子看起来像这样。 给定这个数据库模式 并给定底部的这个问题， 我们可以生成 右侧的 SQL 查询吗？ 经典问题，有 很多不同的尝试。 我们所做的就是遵循 我们给你们的建议。 我们从 快速工程和 RAG 开始。 如果我只是分享 我们使用的一些不同方法， 只是为了 了解我们尝试的细节， 我们会 从最简单的 RAG 方法开始。 我们开始了简单的检索。 只需联合签名相似度， 使用问题并查找 SQL 查询，基本上就 回答了 类似的问题。 对问题进行相似性搜索。 我们还尝试以 不同的方式格式化嵌入。 我们 仅通过几个孤立的示例尝试了一系列快速工程， 但 正如您稍后会看到的，我们的结果并不是很好。 我们所做的就是 考虑这个问题，我们会想， “实际上，如果一个问题有不同的数据库模式，它可能会有 完全不同的答案 。 对一个问题进行相似性搜索对于
(40:59) 这个问题， 但是使用 该问题的假设答案进行 搜索实际上可能会给我们带来 更好的结果 。” 我们所做的是使用 假设的文档嵌入。 我们生成了一个假设的 SQL 查询， 然后将其 用于相似性搜索。 对于这个特定问题， 我们实际上得到了非常 大的性能提升 。 我们还尝试了上下文检索， 其中只是简单的过滤。 我们认为我们对收到的 问题的难度进行了排名， 然后基本上只在 RAG 中带回 同等难度的示例 ， 如果您明白我的意思的话。 这让我们有了更好的改进。 然后我们尝试了 一些更先进的技术。 这里有一些不同的事情。 你可以尝试链式思维推理。 您可能会尝试让它识别 列，然后识别表 ，最后构建查询。 我们最终决定的 其实相当简单。 我们进行了自我一致性检查。 我们让它实际构建一个查询， 运行查询，然后 如果它搞砸了，我们会给它错误消息，并 给它一点注释 ，然后得到它，再试一次。 事实上， 让 GPT 自我修复再次变得有点有趣。 如果您的
(42:04) 用例中延迟不是 您担心的大问题或成本，那么我们认为这种方法实际上工作得相当好。 我们得到的结果看起来 像这样。 我要来这里 谈谈这件事。 最右边是我们 进行快速工程的地方，但 不是那么好。 我们一开始的比例是 69%。 然后我们添加了一些例子并得到了 一些改进。 这告诉我们 RAG 实际上可以给我们带来进一步的改进 。 我们尝试了这个问题，您可以看到 我们的性能提升了 3%。 然后使用答案（ 假设的文档嵌入）， 我们又得到了 5%，这非常酷。 实际上，仅仅通过使用 假设的问题 而不是实际的输入问题来搜索， 我们的性能就比开始时有了巨大的提升 。 然后我们所做的只是增加 示例数量， 但 通过这种方法，我们比现有技术水平少了四分。 再说一次，这只是 几天的时间，从 快速工程开始， 转向 RAG。 向 您展示 可以从这些 非常基本的起始方法中获得多少性能。 那时我们决定 转向微调，看看 是否可以进一步进行， 这就是我将交给约翰的工作。
(43:13) -对于微调，我们将其交给 我们的首选合作伙伴 在 Scale AI 进行微调。 他们首先 按照我们的建议建立了基线。 与 我们 在上一张幻灯片中看到的 69% 的基线相同。 这只需 简单的快速工程技术即可。 然后，他们 使用简单的提示工程技术对 GPT-4 进行了微调， 您只需在 示例中减少架构即可。 非常简单的微调模型， 一点点快速的工程设计， 他们一路上升到 接近 82%。 我们现在距离最先进的 技术已经很近了。 然后，他们将 RAG 与该模型结合使用，根据实际问题将一些示例 动态地注入 到上下文窗口中 。 甚至不是非常先进的 RAG 技术。 他们的成功率为 83.5%，这让我们 离最先进的水平非常近了 。 我想我想 在这里强调的是，如果你看一下 开发集上的 Spider 排行榜，你会发现所 使用的技术非常复杂。 有大量的数据预处理和 大量的数据后处理， 通常将边缘情况硬编码到 用于实际评估模型的脚本中。 我们实际上不必在 这里使用任何这些。 就像简单的微调、 简单的即时工程一样， 只要遵循最佳实践， 我们就在
(44:17) 这个真正众所周知的基准上真正达到了最先进的水平。 它显示了微调 和 RAG 相结合的威力。 回顾一下， 当您正在解决问题 并且想要提高 法学硕士的表现时，请 从快速的工程技术开始。 这些都是非常低的投资。 它们允许您快速迭代， 并允许您验证法学硕士 作为解决 您正在尝试解决的问题的可行技术。 您迭代提示，直到达到 性能稳定状态， 然后您需要分析所 遇到的错误类型。 如果您需要向模型引入新知识 或更多背景信息， 请走 RAG 道路。 如果模型不一致地遵循 指令，或者需要 遵守严格或新颖的输出结构， 或者您通常只需要以 更有效的方式与模型交互， 那么也许是时候尝试微调了。 重要的是要记住 这个过程不是线性的。 这确实是我们想要强调的。 可能需要 49 次迭代才能 达到您真正满意的程度， 并且您将在旅途中在 这些技术之间来回跳跃 。 话虽 如此， 我们希望您喜欢这次演讲。 如果您有任何疑问， 科林和我将在今天剩下的时间里呆在这里。
(45:20) [鼓掌] [音乐]
