The New Stack and Ops for AI - YouTube
https://www.youtube.com/watch?v=XGJNo8TpuVA

Transcript:
(00:00) [音乐]- 大家好。 欢迎来到新的 AI 堆栈和操作， 从原型 到生产。 我叫 Sherwin， 领导 OpenAI 开发者平台的工程团队， 该团队构建和维护 API，超过 200 万开发者（ 希望包括你们中的许多人） 已使用这些 API 在我们的模型之上构建产品。 -我是 Shyamal， 我是 Applied 团队的一员，我曾 与数百家初创公司 和企业合作， 帮助他们 在我们的平台上构建出色的产品和体验。 -今天，我们非常高兴能 与大家讨论 应用程序 从原型阶段进入生产的过程。 首先，我想 稍微客观地看待一些事情。 虽然 ChatGPT 进入我们的生活 并改变世界似乎已经过去了很长一段时间，但 实际上距离它推出还不到一个完整的日历年 。 ChatGPT 实际上是 在 2022 年 11 月下旬上线的，现在 还不到 整整 12 个月。
(01:05) 同样，GPT-4 2023 年 3 月才推出， 距离人们体验 我们的旗舰型号 并尝试将其运用到自己的产品中还不到八个月。 如今，GPT已经 从我们 在社交媒体上玩弄和分享的玩具， 变成了 我们日常生活 和工作场所使用的工具， 变成了企业、 初创公司和企业的能力。 各地的开发人员都在 尝试 将其融入到自己的产品中。 通常，第一步 是构建原型。 正如你们许多人可能知道的那样，使用我们的模型之一来 设置一个非常酷的原型非常简单和容易 。 制作一个演示 并将其展示给我们所有的朋友真是太酷了。 然而，从那里到生产通常存在很大的差距 ， 而且通常很难 将产品投入生产。 这很大程度上是 由于这些模型的不确定性。 如果没有指导框架，将 非确定性应用程序 从原型扩展 到生产通常会 感觉非常困难 。 通常， 您可能会有这样的感觉： 有很多工具 可供您使用。 该领域的发展非常迅速。
(02:08) 有很多不同的可能性， 但你真的不知道 该去哪里以及从什么开始。 在本次演讲中，我们希望为 大家提供一个框架来 帮助指导您将应用程序 从原型转移到生产环境。 我们想向您提供的这个框架 采用堆栈图的形式，该框架受到 客户 在扩展其应用程序时给我们带来的许多挑战的影响。 我们将讨论 如何 在这些法学硕士的基础上构建令人愉快的用户体验。 我们将讨论 通过 使用知识库和工具来建立模型来处理模型不一致。 我们将讨论如何使用评估自信地 迭代您的应用程序 。 最后，我们将讨论 如何管理 应用程序的规模，并 使用编排来考虑成本和延迟。 对于其中的每一个， 我们将讨论 一些策略， 希望你们都可以带回 并在自己的不同产品中使用。 通常， 我们首先只有一个简单的原型。 此时，还 没有像我刚才展示的那样完整的堆栈。 通常 这里只有一个非常简单的设置， 您可以在其中安装应用程序 并直接与他们的 API 进行对话。 虽然这最初效果很好，但 很快您就会意识到这还不够。 Shyamal：我们来谈谈 这个框架的第一层。
(03:16) 技术与 围绕它的用户体验一样有用。 虽然我们的目标 是打造值得信赖、具有防御性 和令人愉悦的用户体验，但 人工智能辅助的副驾驶 和助手提出了一系列不同的 人机交互 和用户体验挑战。 使用我们的模型 构建的扩展应用程序的独特考虑因素 使得 为用户带来更好、更安全的结果变得更加重要。 我们将 在这里讨论两种策略， 以应对 在我们的模型之上构建应用程序所带来的一些挑战， 这些挑战本质上是概率性的。 控制不确定性 并建立 可操纵性和安全性的护栏。 控制不 确定性是指 通过管理模型如何与 用户交互和响应来主动优化用户体验。 到目前为止，许多产品 都是确定性的， 交互可以 以可重复且精确的方式发生。 随着 向构建语言用户界面的转变，这一直是一个挑战。
(04:22) 通过让人工智能增强 和增强人类能力 而不是取代人类判断，以人为本的设计变得非常重要。 例如， 在设计 ChatGPT 时 ，我们融入了一些 UX 元素， 以帮助指导用户并控制 构建 由模型驱动的应用程序所带来的固有不确定性。 第一个， 根据用例，第一个策略 是让人类参与循环，并了解使用生成式人工智能 创建的第一个工件 可能不是 用户想要的最终工件。 让用户有 机会随着时间的推移迭代 和提高质量 对于应对不确定性 和构建强大的用户体验非常重要。 另一方面， 反馈控制 也提供了修复错误的功能， 并且是 构建可靠数据飞轮的有用信号。 构建透明用户体验的另一个重要方面 是向用户传达系统的功能 和限制。 用户可以了解 人工智能可以做什么或不能做什么。 您可以进一步
(05:29) 向用户解释人工智能如何 犯错误。 在 ChatGPT 的例子中， 这采取了底部人工智能通知的形式。 这为用户设定了正确的期望 。 最后，精心设计的用户界面 可以引导用户 与人工智能交互，以获得最有帮助 、最安全的响应， 并从交互中获得最佳效果。 这可以采取 ChatGPT 中暗示性提示的形式， 这不仅有助于 用户获得这种体验， 而且还为用户提供了 提出更好问题、 建议 解决问题的替代方法、启发 和更深入探索的机会。 所有这三种策略 真正将用户 置于中心位置，并通过 设计用户体验来控制体验，从而 充分 利用人工智能产品 并创建协作 和以人为中心的体验。 为了建立 信任的基础，并让您 在部署 GPT 支持的应用程序时更有信心， 不仅要 构建以人为本的用户体验，
(06:33) 而且要构建 可操纵性和安全性的护栏。 您可以将护栏视为位于用户体验和模型之间的 本质上的约束 或预防性控制 。 它们的目的是防止有害和不需要的 内容进入您的应用程序和 用户，并为 生产中的模型增加可操纵性。 我们看到开发人员 构建的一些最佳交互范例将安全性 和安保性构建为体验的核心。 我们的一些最好的模型是 最符合人类价值观的模型。 我们相信，一些 最有用、最有能力的用户体验可以 最大限度地发挥安全性 和可操纵性，从而获得更好、更安全的结果。 为了演示这一点， 让我们从 DALL·E 中的一个简单提示开始。 非常适合圣诞节， 创作一幅 圣诞树的抽象油画。 DALL·E 使用该模型 通过在 色调、 树的形状、 颜色和笔触 等方面添加更多细节和特异性来增强提示。
(07:39) 现在，我不是一名艺术家， 所以我不会 在这方面做得更好， 但在这种情况下， 我使用 DALL·E 作为合作伙伴，将 我的想法变成想象。 现在，您可能想知道， 这是怎样的安全护栏？ 嗯， 用于创建更好的工件的同样的快速丰富 也可以起到安全护栏的作用。 如果本例中的模型检测到 侵犯 个人隐私或权利的有问题的提示， 它会建议不同的提示， 而不是直接拒绝。 在这种情况下，它不是生成 一个真实的人的图像，而是 捕捉本质，然后创建一个 虚构的人的图像。 我们分享了 一个护栏的例子，它可以帮助 提高可操纵性和安全性， 但护栏可以采取许多其他形式。 这方面的一些例子 包括合规护栏、 安全护栏 和 确保模型输出在 语法和语义上正确的护栏。 当您 为高度监管的行业构建界面时，护栏变得至关重要，这些行业
(08:45) 对错误和幻觉的容忍度较低， 并且必须优先考虑安全性 和合规性。 我们 在可操纵性和安全性方面打造了出色的用户体验， 但我们的旅程并没有就此结束。 - 此时，您已经为所有用户构建了 令人愉快的用户体验， 可以管理 这些模型的一些不确定性。 虽然这作为一个原型确实非常有效，但当 您从用户那里获得的查询类型 非常有限时， 当您将其扩展到生产环境时， 您很快就会开始 遇到一致性问题， 因为当您扩展您的数据库时，您很快就会遇到一致性问题。 应用程序中，您将获得的 查询和输入类型 将开始发生很大变化。 就此，我们想 谈谈模型一致性， 它介绍了 我们堆栈的第二部分，涉及 用知识存储和工具来奠定模型。 我们 在客户中看到很好地采用了两种策略 来管理这些模型固有的不一致性，其中一种是 在模型级别本身限制模型行为， 另一种是 使用一些现实世界的知识来为模型奠定基础 诸如知识库或您自己的工具之类的东西。
(09:51) 第一个是限制 模型行为本身。 这是一个问题， 因为通常很难 管理 LLM 固有的概率性质， 特别是 作为我们 API 的客户， 您对模型没有真正的 低级访问权限，因此 确实很难管理 这种不一致的情况 。 今天，我们实际上引入了 两个新的模型级功能，可以 帮助您约束模型行为， 并且今天想与您讨论这一点。 第一个是 JSON 模式， 如果打开该模式，会将 模型的输出限制 在 JSON 语法之内。 第二个是 使用 我们将其引入聊天完成中的名为 C 的新参数的可重现输出。 第一个是 JSON 模式，这 是很多人经常询问的 功能。 它允许您强制模型 在 JSON 语法内输出。 很多时候，这对开发人员来说非常重要， 因为您要将 LLM 的输出 输入到 下游软件系统中。 很多时候，为了做到这一点，您需要 一种通用的数据格式， 而 JSON 是其中最流行的格式之一。 虽然这很好，但这里不一致的一个很大的缺点
(10:57) 是，当模型输出无效的 JSON 时， 它实际上会破坏您的系统 并引发异常， 这对您的客户来说并不是一种很好的体验 。 我们今天介绍的 JSON 模式 应该会大大 降低这种情况的可能性。 它的工作方式是 这样的，在聊天完成中， 我们添加了一个称为 JSON 架构的新参数。 如果您向该参数传递并键入对象， 然后将其传递到我们的 API，那么 您 从我们的系统 或 API 获得的输出将被限制 在 JSON 语法内。 那里的内容字段 将受到 JSON 语法的限制。 虽然这并不能 100% 消除我们 在内部看到的评估中的所有 JSON 错误 ，但 它确实显着降低了该模型 输出的 JSON 的错误率 。 第二件事是通过聊天完成中的 C 参数获得显着 更高的可重复输出 。 我们的许多模型 都是不确定的， 但如果你仔细观察，就会发现 它们实际上是幕后发生的许多不一致行为的三个主要贡献者 。 其中之一 是模型如何根据其获得的概率对其令牌进行采样 。
(12:00) 这是由温度 和我们已有的最高 P 参数控制的 。 第二个参数是 C 参数， 它是 模型用来 开始计算并以此为基础的随机数。 第三个是 称为系统指纹的东西， 它描述了在后端 运行的引擎的状态 以及 我们在这些引擎上部署的代码。 随着这些变化，当这种情况发生时，将会出现一些固有的 非决定因素。 截至今天，我们只允许人们 访问温度和最高 P。 从今天开始， 我们实际上将允许开发人员 访问输入中的 C 参数， 并让开发人员 在聊天完成模型的响应中了解系统指纹 。 实际上，它看起来像这样， 在聊天完成中 现在将有一个 您可以传入的种子参数，它是一个整数。 如果您传递 一、二、三、四、五等种子， 并且控制温度并将其设置 为零，那么随着时间的推移， 您的输出将显着更加 一致。 如果您将此特定 请求发送给我们五次， 您 在选择下获得的输出 将明显更加一致。
(13:04) 此外，我们还为您提供了 系统指纹参数的访问权限， 该参数在模型的每次响应中 都会告诉您有关引擎盖 下的发动机系统的指纹。 如果您从早期响应中获得 完全相同的系统指纹 ， 并且传递了相同的种子 和零温度，那么您几乎肯定 会得到相同的响应。 很酷，所以这些都是模型级别的行为， 您实际上可以很快掌握 并尝试，即使在今天。 一种更复杂的技术 称为“基础模型”， 它 通过为模型提供 额外的事实作为其答案的基础来帮助减少模型行为的不一致。 其根源 在于，当模型单独存在时，它 通常会产生幻觉信息， 正如大家都知道的那样。 这很大程度上是因为 我们强迫模型 说话 ，如果它真的不知道任何东西， 它就必须尝试 说一些东西，而且很多时候 它会编造一些东西。 其背后的想法 是为模型奠定基础 并为其提供大量事实， 这样它就不会出现任何问题。 具体来说，我们在这里要做的 是在输入上下文中明确地为 模型提供一些基础事实， 以减少 模型产生幻觉的可能性。
(14:11) 这实际上是一个相当广泛的情绪。 在系统图中可能看起来像这样， 查询 将从您的用户传入， 到达我们的服务器，我们 不是首先将其传递给我们的 API，而是 首先往返 于某种类型的 扎根的事实来源。 假设我们将查询传递到那里。 然后，在我们的接地事实源中， 理想情况下它会为我们返回某种类型 的接地事实 ，然后我们将获取 接地事实 和查询本身，并将其传递给我们的 API。 然后，理想情况下，API 会获取该信息 并使用此处的事实综合某种类型的响应 。 为了使这一点更加具体，实现 这一点的一种方法 是使用 RAG 或矢量数据库，这是当今非常常见 和流行的技术。 在此示例中，假设我正在构建 一个客户服务器站点， 并且用户询问，如何删除我的帐户？ 这可能特定于我自己的应用程序 或我自己的产品， 因此 API 本身不会真正知道这一点。 比方说，我有一个 像矢量数据库这样的检索服务， 我用它来索引一堆 内部文档 和一堆有关支持的常见问题解答， 并且它知道如何删除文档。 我首先要做的是 向检索服务查询 如何删除我的帐户。
(15:14) 假设它在这里找到了一个与我相关的片段， 其中提到， 在帐户删除常见问题解答中， 您可以转到设置， 向下滚动并单击此处，等等。 然后，我们会将其 与原始查询一起传递给我们的 API， 然后 API 将使用该事实 将一些响应返回给用户。 在这种情况下，它会说， 要删除您的帐户， 请转到设置，向下滚动，单击此处。 这是一种实现， 但实际上，这可能非常广泛， 并且通过 API 中的 OpenAI 函数调用， 您实际上可以使用自己的服务， 我们已经看到这被 我们的客户使用，效果非常好。 在这种情况下， 我们可以使用我们自己的 API 或自己的微服务，而不是使用矢量数据库。 在这种情况下，假设客户 询问当前的抵押贷款利率 是多少，当然， 即使我们的 LMS 也不会立即知道， 因为利率一直在变化。 假设我们有一个微服务 正在执行一些日常同步工作， 下载 并 跟踪当前的抵押贷款利率。 在这种情况下， 我们将使用函数调用。 我们会告诉我们的模型 可以访问 名为 get_mortgage_rates() 的函数， 该函数位于我们的微服务中。 我们首先向 API 发送一个请求， 它会表达调用 get_mortgage_rates() 函数的意图。 然后，我们将通过使用 get_mortgage_rates() 调用我们的 API 来实现该意图。
(16:22) 假设它返回 30 年期固定抵押贷款的 8% 抵押贷款利率 ，然后其余部分看起来非常相似， 您将其通过原始查询传递到 API， 然后模型 以地面响应进行响应， 说明一些内容 喜欢，不太好。 目前的 30 年期固定利率实际上已经达到 8%。 在非常广泛的层面上，您以 通用方式使用这个扎根的事实源， 以帮助扎根模型 并帮助减少模型的不一致。 我刚刚写了两个不同的例子， 但扎根的事实来源 也可以是其他东西， 比如搜索索引，甚至是弹性搜索 或某种类型的更通用的搜索索引。 它可以是类似数据库的东西。 它甚至可能是 浏览互联网 或尝试一些 获取更多事实的智能机制。 主要思想是 为模型提供一些可以发挥作用的东西。 我想指出的一件事 是， 我们今天刚刚宣布的 OpenAI Assistants API 实际上提供了 一个开箱即用的检索设置，供您 使用并构建在 一流的内置检索之上 经验。 我建议检查一下。 Shyamal：到目前为止，我们讨论 了构建透明的以 人为本的用户体验。 然后我们讨论了 如何
(17:30) 通过我们今天发布的一些模型级功能 以及 基础模型来始终如一地提供用户体验。 现在我们将 讨论如何在 不出现倒退的情况下持续提供这种体验。 这是评估 模型性能 变得非常重要的地方。 我们将 在这里讨论两种策略， 这将有助于评估使用 我们的模型构建的应用程序的性能。 第一个是 为您的特定用例创建评估套件。 在 与许多组织合作时， 我们一次又一次地听到 评估模型 和性能 以及测试进度很困难， 通常会减慢开发速度。 这个问题的部分原因是开发人员 没有考虑 评估 这些模型性能的系统过程， 而且评估也太晚了。 评估确实是 成功的关键。 在实际产品场景中测量模型的性能 对于防止回归 以及在
(18:36) 大规模部署这些模型时建立信心非常重要。 您可以将评估 本质上 视为大型语言模型的单元测试。 人们常常认为提示 是一种哲学， 但它更像是一门科学。 当您将其 与评估配对时， 您可以将其视为 软件产品或交付。 评估确实可以将模棱两可的对话转化 为可量化的实验。 它们还使模型治理、 模型升级变得更加容易， 更容易设定 关于好坏的期望。 功能、评估 和性能确实是齐头并进的， 它们应该是 您开始人工智能工程之旅的地方。 为了构建评估， 假设我们从简单开始， 并让人工注释者 在您测试时评估应用程序的输出。 这种情况下的典型方法 是，您的应用程序 具有不同的提示集 或检索方法 等，并且您希望首先通过查看这些响应来 构建评估的黄金测试数据集，
(19:40) 然后手动对它们进行评分。 当您随着时间的推移对此进行注释时， 您最终会得到一个测试套件，然后 您可以在线 或离线方式运行该测试套件，或者将其作为 CICD 管道的一部分运行。 由于 大型语言模型的性质， 它们可能会犯错误， 人类也是如此。 根据您的用例， 您可能需要考虑 构建评估来测试 诸如错误的输出格式 或幻觉、 代理脱轨、 不良语气等问题。 我们来谈谈如何构建 Eval。 今年早些时候， 我们开源了 evals 框架， 这 给许多开发人员带来了灵感。 该库包含 针对不同特定 用例和垂直领域的真正具有挑战性的评估注册表， 以及许多模板，这些模板 可以派上用场，并且 可以成为 许多人 了解应进行的评估 和测试类型的坚实起点 针对您的特定用例进行构建。 构建评估套件后， 良好的实践 和卫生习惯是记录 和跟踪您的评估运行。
(20:46) 例如，在这种情况下， 我们有五次不同的评估运行， 每次都根据 我们的黄金测试数据集进行评分， 以及注释反馈 和更改审核。 更改审核可能包括 对提示、 检索策略、 一些简短示例的更改， 甚至升级 到模型快照等内容。 您不需要复杂的工具来开始 跟踪这样的事情。 我们的许多客户 只是从电子表格开始， 但关键是每次运行都 应该 以非常精细的级别存储， 以便您可以相应地跟踪它。 尽管人工反馈和用户评估 是质量最高的信号，但 它通常很昂贵 或并不总是实用， 例如，当您无法使用 真实的客户数据进行评估时。 这就是自动评估 可以帮助开发人员快速监控进度 并测试回归的地方。 我们来谈谈模型分级评估， 或者本质上是使用人工智能来对人工智能进行分级。 GPT-4 可以成为一个强大的评估器。
(21:53) 事实上，在很多自然语言 生成任务中， 我们已经看到 GPT-4 的评估 通过一些额外的提示方法与人类的判断有很好的相关性。 模型分级评估的好处 在于，通过减少人类对 语言模型可以处理的评估过程部分的参与， 人类可以更加专注于解决改进评估方法所需的 一些复杂的边缘情况 。 让我们看一个 实际情况的示例。 在本例中，我们有一个输入查询 和两对补全。 一种是基本事实，另一种 是从模型中采样的。 这里的评估是一个非常简单的 提示，要求GPT-4将 提交答案的事实内容与专家答案进行比较。 该答案将传递给 GPT-4 进行评分，在本例中， GPT-4 的观察结果是 提交的答案 与专家答案之间存在差异。 我们可以通过
(22:59) 使用一些额外的提示工程技术（ 例如思维链等）来改进我们的评估提示，从而进一步实现这一点。 在前面的例子中， eval 是相当二元的。 答案要么符合 基本事实，要么不符合。 在很多情况下， 您需要考虑评估指标， 这些指标 与用户的期望 或您试图获得的结果密切相关。 例如，回到 Sherwin 的 客户服务助理示例， 我们希望评估自定义指标， 例如响应的相关性、 响应的可信度等， 并让模型 根据这些不同的指标进行评分 或我们决定的标准。 以下是该标准 或记分卡的示例。 在这里，我们基本上提供了 GPT-4 这个相关性、可信度 和正确性的标准，然后使用 GPT-4 对 候选输出进行评分。 这里的一个很好的建议是展示而不是讲述， 它基本上包括 1 分 或 FI 分数可能是什么样子的示例，这
(24:05) 将真正有助于此评估过程， 以便模型真正欣赏 标准的传播。 在这种情况下，GPT-4 有效地学习了 语言质量的内部模型， 这有助于它区分 相关文本和低质量文本。 利用这种内部评分 机制，我们可以对 新的候选输出进行自动评估。 当 GPT-4 昂贵 或评估缓慢时， 即使在今天的价格下降之后， 您也可以微调 3.5 Turbo 模型， 该模型本质上提炼了 GPT-4 的输出， 使其真正擅长 评估您的用例。 在实践中，这意味着 您可以使用 GPT-4 来策划高质量的 评估数据， 然后微调 非常擅长评估这些输出的 3.5 判断模型， 然后使用该微调后的模型来评估 您的应用程序的性能。 这也有助于减少 仅使用 GPT-4 进行评估所带来的一些偏差。 这里的关键是采用 评估驱动开发。 好的评估是
(25:11) 与您尝试 得出的结果或 您关心的用户指标密切相关的评估。 就 RAG 而言， 它们具有非常高的端到端 覆盖范围， 并且可扩展计算。 这就是自动评估真正有用的地方。 - 此时， 您已经构建了令人愉快的用户体验， 您可以将其 一致地交付给用户， 并且您还可以 使用评估自信地迭代产品。 如果你把这一切都做得对， 通常你会发现自己的 产品非常火爆 并且非常非常受欢迎。 如果说去年向我们展示了什么的话， 那就是消费者 甚至内部员工 对人工智能的兴趣是无法满足的。 通常，您现在会开始考虑 如何管理规模。 通常，管理规模 意味着管理延迟 和管理成本。 至此，我们介绍了 堆栈的最后一部分， 称为编排， 您可以 通过在应用程序中添加一些额外的机制 和分支来管理规模。 我们 在管理成本 和延迟方面看到的两种策略涉及 使用语义缓存来
(26:16) 减少 您访问 我们的 API 的往返次数以及路由 到更便宜的模型。 第一个被 称为语义缓存。 从系统的角度来看，语义缓存在实践中是什么样子， 您将 在逻辑中添加一个新层 以位于我们和您的应用程序之间。 在这种情况下，如果有查询 询问 GPT-4 何时发布， 您将首先转到语义缓存 并在那里进行查找， 看看缓存中是否有任何内容。 在这种情况下，我们不会这样做，然后您 只需将此请求传递给我们的 API。 然后 API 会响应 2023 年 3 月 14 日之类的内容， 然后您将其保存 在语义缓存中， 该缓存可能是矢量数据库 或其他类型的存储。 这里的要点是，您要保存 2023 年 3 月 14 日的响应， 并使用 GPT-4 发布时间的查询键入它， 然后将其传递回 您的用户。 这很好，但假设 从现在起一个月或一周后， 另一个请求出现， 用户询问 GPT-4 发布日期？
(27:21) 现在，这与您之前的查询不完全相同 ， 但它在语义上非常相似， 并且可以 通过完全相同的响应来回答。 在这种情况下，您将 在缓存中进行语义查找， 意识到您已经拥有了该信息， 并且只需 在 2023 年 3 月 14 日返回给用户即可。 通过此设置， 您实际上节省了延迟， 因为您 不再 往返我们的 API， 并且您节省了成本， 因为您不再需要点击 并支付额外的代币。 虽然这很有效，但 通常管理起来可能有点 困难， 而且通常有更有效的方法 来管理成本和延迟。 这是我们开始 考虑路由到更便宜的模型的地方， 也是编排真正发挥作用的地方。 当我谈论路由 到更便宜的型号时， 通常首先要考虑的 是从 GPT-4 升级到 3.5 Turbo， 这听起来很棒， 因为 GPT-3.
(28:11) 5 Turbo 非常便宜，速度非常快， 但是，它显然没有 那么智能 作为 GPT-4。 如果您只是将 3.5 Turbo 拖放到应用程序中， 您很快就会意识到 您无法提供 出色的客户体验。 然而，我们两个月前发布的 GPT-3.5 Turbo Finetuning API 已经受到了客户的巨大欢迎， 通过对 GPT-3.5 Turbo 的自定义版本进行微调，这对于客户来说是降低成本的一个非常好的方法。 他们自己的特定用例， 并获得 较低延迟和较低成本的所有好处。 显然， 之前已经充分讨论了微调， 但简而言之，这里的主要思想 是采用您自己策划的数据集。 有时 可能有数百 甚至数千个示例， 描述如何 在特定用例中采取行动的模型。 您可以将该整理的数据集传递 到我们的微调 API 中，也许可以在 此处调整一两个参数， 然后此处的主要输出是基于您的数据集专门 针对您和您的组织的 3.
(29:11) 5 Turbo 的自定义微调版本 。 虽然这很棒，但实际上，通常这样做会产生 巨大的激活能量， 因为 生成此精选数据集可能非常昂贵。 就像我提到的， 您的用例可能需要数百、数千、 有时甚至数万个 示例， 并且通常您会 自己手动创建这些示例 或雇用一些承包商来 手动完成此操作。 然而，我们看到很多客户采用的一种非常酷的方法 是，您实际上可以使用 GPT-4 创建训练数据集 来微调 3.5 Turbo。 它开始看起来 与 Shyamal 刚刚提到的 评估非常相似， 但 GPT-4 处于智能级别， 你实际上可以 给它一堆提示， 它会 在这里为你输出一堆输出， 并且 该输出 可以只是您的训练集。 这里 不需要任何 人工干预。 您在这里有效做的 是 从 GPT-4 中提取输出 并将其输入到 3.
(30:04) 5 Turbo 中， 以便它可以学习。 通常，它的作用 是，在您特定的狭窄领域中， 它可以帮助这个经过微调的 3.5 Turbo 版本几乎与 GPT-4 一样好。 如果您确实付出努力完成所有这些，那么您 获得的红利 实际上是相当可观的， 不仅从延迟的角度来看， 因为 GPT-3.5 Turbo 显然要快得多， 而且从成本的角度来看。 为了更具体地说明这一点， 如果你看一下表格， 即使在今天的 GPT-4 价格下降之后， 3.5 Turbo 的微调版本 仍然便宜 70% 到 80%。 虽然它不像 普通的 3.5 Turbo 那么便宜，但 你可以看到它与 GPT-4 相比还是有很大差距， 如果你改用经过 微调的 3.5 Turbo， 你会节省很多成本。 - 好吧，我们讨论了一个框架， 它可以帮助您应对使用 我们的模型构建的扩展应用程序（ 从原型到生产）所带来的独特考虑因素和挑战。 让我们回顾一下。
(31:07) 我们讨论了如何通过控制不确定性和添加护栏来 构建有用、令人愉快 且以人为本的用户体验 。 然后我们讨论 了如何 通过基础模型 和一些模型级功能来一致地提供这种体验。 然后我们讨论了通过实施评估来持续 提供 不回归的体验 。 最后，我们讨论了 规模带来的考虑因素， 即管理延迟和成本。 正如我们所看到的， 使用我们的模型进行构建增加了 可能性的表面积， 但它也增加了 挑战的足迹。 我们讨论的所有这些策略， 包括 堆栈的编排部分， 都已融合到 称为 LLM Ops 或大型语言模型操作的新学科中。 正如 DevOps 于 2000 年代初出现 以简化软件开发流程一样， LLM Ops 最近的出现是 为了应对使用 LLM 构建应用程序所带来的独特挑战， 并且它们已成为 许多企业架构和堆栈的核心组件。
(32:14) 您可以将 LLM Ops 视为 LLM 端到端运营管理所需的 实践、工具 和基础设施 。 这是一个广阔且不断发展的领域， 而我们仍只触及表面。 虽然我们不会详细介绍，但 以下是其外观的预览。 LLM Ops 功能有助于解决 监控、 优化性能、 帮助实现安全合规性、 管理数据和嵌入、 提高开发速度 以及真正加速大规模 可靠测试 和评估过程等挑战。 在这里，可观察性和跟踪 对于使用提示链和助手识别和调试故障 并更快地处理生产中的问题变得尤为重要，从而 使 不同团队之间的协作变得更加容易。 例如，网关 对于简化集成非常重要， 可以帮助集中管理 安全性、API 密钥等。 LLM Ops 确实能够扩展 到数千个应用程序 和数百万用户， 并且有了正确的基础，
(33:22) 组织可以真正 加速其采用。 重点 不应该是一次性工具，而是真正 开发 这些长期平台 和专业知识。 就像这位站在门槛上的年轻探险家一样 ， 我们面前有一系列广泛的 机会来 构建 超出 我们今天讨论的框架的基础设施和原语。 我们非常高兴能够帮助您为子孙后代 构建下一代助手 和生态系统。 有太多东西需要构建和发现， 我们只能共同努力。 谢谢。 [鼓掌] [音乐]
