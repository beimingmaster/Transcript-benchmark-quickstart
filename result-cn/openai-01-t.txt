[音乐][鼓掌]-大家好！我希望你们都喜欢这个主题演讲。我知道我做到了。希望大家在 OpenAI 首届开发者大会上度过愉快的时光。在本次分组讨论中，我们讨论解决您最关心的问题时可使用的各种技术来提高 LLM 绩效。让我进行自我介绍，我是约翰·阿拉德，OpenAI 微调产品团队的工程主管。这几个月对 OpenAI 的微调来说确实非常令人兴奋。早在八月份，我们推出了 3.5 Turbo 微调，开发者社区的反响令我们震惊。随后我们又添加了一些重要功能，对函数调用数据进行微调。通过持续微调，您可以采用现有的微调模型并持续微调。我们甚至推出了一个用于在平台内进行微调的完整用户界面。在过去的几个月里，我们能够与来自各行各业的开发人员密切合作，包括独立开发者、初创公司的开发者。

来自地球上一些最大企业的开发者，我们已经能够看到他们试图解决的问题是什么，以及他们如何尝试使用法学硕士来解决这些问题，特别是他们如何尝试使用法学硕士的微调来解决这些问题。我希望今天能与大家分享其中的一些见解。话虽如此，我将转告我的同事科林让我们开始。- 谢谢，约翰。嘿伙计。我是科林。很高兴见到你。我负责我们在欧洲的解决方案实践，这基本上意味着与我们的一些战略客户合作，尝试解决他们最复杂的问题。您可能会毫不惊讶地听到，在过去的一年里，优化一直是每个人最关注的焦点。

努力让法学硕士可靠地投入生产。为何如此受关注？优化法学硕士是很困难的。尽管有所有的框架，所有的内容均已发布，人们提供了所有的指标和各种工具。但它仍然是最大的焦点之一，并且仍然没有关于如何优化的一站式服务。这实际上取决于您遇到的问题类别以及您如何解决它。我认为我们今天希望向您展示的是找出问题所在以及如何解决问题的框架。

接下来是工具您可以使用来解决这些问题的情况。先前提的原因是关于困难。将信号与噪声分辨开具有挑战性，确切知道问题在哪里是第一个困难。其次，法律硕士的表现可能很抽象，很难衡量，这使得确定问题规模很棘手。即使确知问题和它的紧急性，也难确定用哪种方法解决已发现的问题，这是今天的重点。今天的讨论主要是关于性能优化。我们希望您在结束时理解不同方案的心智模型，明白何时使用某一方案，且对继续优化工作充满信心。首先，优化法律硕士性能并不总是线性的。很多人展示这类图表，您从快速工程开始，然后过渡到检索增强生成，最后进行微调，这是优化法律硕士的方法。问题就出在这里，因为检索增强生成【尚未完全】。

微调和微调解决了不同的问题。 有时候您需要一个，有时候您需要另一个，有时候您可能需要两者，具体取决于您正在处理的问题类型。我们认为这更像是这样的。您可以在两个轴上进行优化。其中一个是上下文优化。模型需要了解什么才能解决您的问题？另一个是LLM（Large Language Model）优化。模型需要如何行动？为了真正解决您的问题，它需要执行什么方法或采取什么行动？典型流程是从左下角开始快速工程。通过快速的工程设计，您可以同时做到这两点。但在扩展性方面可能会受限。快速工程始终是最佳起点。您可以迅速测试和学习，首先应该做的是从提示开始，进行评估，弄清您将如何一致评估您的输出。然后您可以决定，这是一个上下文问题还是我们需要模型如何采取行动的问题？如果您需要更多上下文信息或更相关的上下文，您可以使用检索增强生成（RAG）。如果您需要遵循更一致的指导，您可以直接进行微调。

将这两种方法结合在一起，它们是相辅相成的，因此你的问题有时需要兼顾两者。我们将给出一些例子，展示了人们在哪些情况下只使用了其中一到两种方法，以及在哪些情况下人们已经将所有这些方法结合起来来解决问题。典型的优化过程通常如下所示：从左下角开始，获得提示，进行评估，然后确定基线是什么。接着往往是简单的下一步，添加少量示例。通过为模型提供一些输入和输出示例，说明您期望模型如何运行。可以说，在这一阶段，实际上这些少量示例极大地提高了性能，因此让我们将其连接到某种知识库，我们可以将这个过程工业化，这通常是人们添加某种检索增强生成的地方。假设现在它有了上下文，但它没有以我们想要的精确格式或风格生成输出，因此我们可能需要微调模型。接着，典型的下一步可能是检索并不如您期望的那么好。也许这些内容可能更符合模型的需求。然后您回头再次优化检索增强生成的过程。

您已经对检索增强生成进行了再次优化，现在希望利用更新后的检索增强生成中引入的新示例来再次微调模型。这是经典的优化流程例子。简而言之，您尝试一些东西，评估结果，然后再尝试其他方法。这是最简单的概括。现在，我们将逐个象限深入研究。我们将从左下角开始快速实施工程，然后继续进行检索增强生成和微调。接着，我们会通过我和约翰实际接受的挑战来演示这些步骤在实践中的运作。及时的工程。我知道观众中大多数人对这种流程非常熟悉，因此我们会快速浏览，但始终要确保每个人都理解我们遵循的原则。及时的工程。以下是一些策略，这些策略是我们文档中的最佳实践，只是简单回顾一下。首先，明确撰写指导方针。我将用一个例子说明这意味着什么，因为这通常是人们第一次会出错的地方。

接下来，将复杂的任务拆分为更简单的子任务。当想象这个模型正在尝试对每个需要解决的子单元或子任务进行预测时，应当提供尽可能具体的指令，这样它才能更好地执行。同时，给予GPT时间来思考。我将给您一个人们常用的框架示例来执行这一操作。最后，我已经提到过，测试必须系统地进行。很多时候，我们会看到客户最终陷入这种打地鼠的循环：他们改变一样东西，然后又改变另一样，接着再改变另一样。他们只是在不停地评估矩阵，却感觉不到自己在朝着正确的方向前进。这时，您确实需要一套可靠的评估方法和通常是某种LLMOps，这样在更改这些内容时能够系统地测量它们。接着，最常见的下一步是将其扩展到参考文本或让其能够访问外部工具，这会使我们更深入探讨检索增强生成领域。首先，让我们回顾一下这些实践中的样例。开始，我们先就快速工程谈一些直觉。

重要的提示，我已经多次提到了。再重申一遍，这是一个不错的起点，实际上也可能是一个很好的终点，具体取决于您的实际使用情况。为什么这么重要呢？因为早期进行测试并学习，然后结合评估，为后续优化提供基准。这应该是您开始的地方。有什么不好呢？有一些问题。提示引入了新信息，您可以将大量信息打包到提示中，尤其是现在可以借助GPT-4 Turbo。不过，这并非一个使用即时工程来实现超级扩展性的最佳方法。我们将看到其他方法可以帮助解决这一问题。另外，复杂样式或方法的可靠复制，也受到模型可接收示例数量的上下文窗口的限制。这是一个很好的起点，但根据您任务的复杂程度，可能无法完全达到目标。最后一个要点是尽量减少令牌的使用，在即时工程中这是一个很常见的问题。当不断遇到问题时，不断在提示中添加更多细节来解决问题，最终会使用越来越多的令牌，这会增加延迟和成本等问题。

重申一遍，快速工程并不是解决这一特定问题的好方法。不要搞快速回顾指导，而是要遵循详细的指示。我们收到的提示质量很低，有些含糊，有些输出随机，并且只有少数改进方法被回顾。给出明确的指示，精确地说明将面对的挑战和任务。让时间思考。这不是一个好榜样。我告诉它按步骤完成任务，但如果给它时间去思考，它会产生更多想法，比如建立推理步骤的反应框架。它实际上是在为自己找答案。React框架只是实现目标的一种方式，但给GPT时间思考是另一种很好的方法，它可以处理您需求进行的复杂逻辑推理，因为它会在最后完成。那一天，它将成为下一个令牌预测器。它输出所需的令牌，以帮助自己更接近答案，具体取决于提示的强度。最后一个要点是将复杂任务分解为简单任务。在这种情况下，我提到将每一步都做到。

将其看作是一次展示。将其布局得尽可能清晰。右侧展示着漂亮格式的 JSON 输出。再次重申，这只是基础知识，但在继续之前回顾这些内容是很有必要的。接下来是共同的步骤。在提示工程中，你基本上在试图告诉模型你希望它如何行动，但通常很难确定哪些标记会对模型产生最大的影响。一个很好的起点实际上是将其作为一个展示问题而不是讲述问题来处理。只需提供一些示例，为其提供输入和输出对，从而实际展示你期望的行为。这种方法很好地引导我们迈向下一步，通常会看到一些性能的显著改进。在实践中，我们会发现，这种方法对我们担负的实际任务带来了明显的提升。当人们试图将模型投入工业化时，他们通常希望这些少量的示例能够基于用户的问题或特定问题的上下文而变化。人们常常在尝试几次后转向检索增强生成（RAG）。

让我们开个头吧。在真正开始RAG之前，我想给你一个简单的心理模型，帮助你了解大致方向。我们要从快速工程入手。我们已经评估了情况，确定了差距，现在正在探讨这是需要进行检索增强一代，还是微调。有时把这看作短期记忆与长期记忆的问题是有帮助的。举个例子，如果我们在准备考试，那么微调就好比是你之前为学习问题准备答案所采用的学习方法和框架。而检索增强生成则好比是考试时给予对方一本已打开的书。如果他们知道方法论且知道该找什么，那么检索增强生成意味着他们能够打开书，找到正确页面，实际获取所需内容。这就是为什么这两种方法所解决问题的本质截然不同。没有方法论，没有内容，就无法解决某些问题。在这种情况下，我们假定我们面对的是短期记忆问题。我们希望确保模型提供了正确的上下文以回答问题。

检索增强生成（RAG）是指让模型能访问特定领域的内容。简要回顾一下RAG的概念，虽然大多数人都很熟悉，但我还是想复习一下以便确保所有人了解。通常情况下，我们开始于某个知识库或领域，希望获取信息来回答问题。在这种情况下，我们会遵循一套相对标准的流程，即我们有一些文档，我们把它们嵌入到一个地方。再次强调，我知道人们可能会利用自己的搜索服务，从各种文档来源获取信息，这也是可以理解的。举例来说，我们假设已经有了一些文档，我们把它们嵌入其中，构建一个知识库。然后当用户提出问题时，比如说，“加拿大的人口数量是多少？”我们不会直接提供答案给用户，而是会在我们的知识库中搜索相似信息。假设我们进行相似性搜索，检索到了一些关于加拿大人口数量的内容，然后我们结合这些内容提供答案。我们会将这些答案传递给生成式语言模型（LML），指示它：“这是问题，这是相关内容，请用这些内容来回答问题。”希望这一解释能够帮助您更好地理解。

我们将最终得到一个正确的答案。现在回顾一下RAG。我希望分享一些我们在何时应该使用RAG以及何时不应该使用RAG方面发展出的直觉，就像我们在即时工程方面所做的那样。RAG的好处在于它能再次向模型引入新信息，以更新其知识。这是您目前能够做到的为数不多的方法之一。这实际上是客户面对的最大问题之一。他们可能会说，“嘿，我有100,000个文档。我希望模型只了解这些文档。”不幸的是，目前还没有超级可扩展的方式来获取这100,000个文档并同时提供所有这些文档的模型知识。检索增强生成可能是与您目前能够达到的最接近的方式，即我们将根据您希望它解决的特定问题为其提供一些上下文知识。同样，通过控制内容来减少幻觉是使用检索增强生成非常常见的用例之一。稍后我们会看到它与微调如何完美结合。一个典型的用例是您为模型提供内容，并指示它仅使用该内容来回答问题，而不使用其知识。这是人们尝试将知识限制的一种方式。

在特定的知识库中训练并减少误解的一种典型方法是很有好处的。虽然在那里提到了它，但是潜入了对广泛领域的理解。目前，检索增强生成的一代尚不能被教会什么是法律或医学。不幸的是，这并不是检索增强生成的模型能够执行的操作之一。同样，教模型学习新的语言格式或风格也是很有必要的。这可能发生在微调模型以尝试教会它一种方法或一种问题解决方法的过程中。同时，可以减少代币的使用。实际上，您将在RAG中增加更多的标记令牌，并持续添加输入/输出示例。通常会看到人们首先进行快速工程，然后再转向RAG，因为他们首要任务是确保准确性水平得到满足，然后才尝试将令牌从过程中剥离出来。随后约翰会向大家介绍更多相关内容。简言之，RAG实际上是在努力优化，为其提供尽可能多的上下文信息以回答问题。我想分享一个成功的案例，其中快速工程和RAG起到了关键作用。

听起来这些任务可能很简单，但实际上却很困难。要真正实现这一点，需要大量的迭代、大量的测试和学习。在这个实例中，客户拥有一个包含两个不同知识库的RAG管道，之后是一个法学硕士。其工作是接收用户的问题，确定要使用哪个知识库，触发查询，并用它来回答问题。起初，我们只是实现了检索，并进行了大量对话。我们对于嵌入效果和潜在简便感到非常兴奋。我们的基准正确率是45%，不是很理想。然后我们尝试了很多方法，我在旁边画了一些勾和叉，表示我们尝试了多少方法以及有多少方法实际应用在生产中。有刻度的表示实际应用在生产中的方法，有叉的表示我们尝试过并丢弃的方法。通过尝试不同的文档嵌入假设，我们成功将准确率提升到65%。而不是对问题进行相似性搜索，我们生成一个假答案然后再进行相似性搜索。对于某些情景来说，这样做非常有效，但对这个案例来说效果不佳。我们还尝试微调嵌入，实际上是根据训练数据调整嵌入空间，这对于帮助模型真正进步至关重要。

正确答案就是，从准确性角度来看，这项工作确实做地很好，但它既昂贵又缓慢，我们最终不得不因为非功能原因而放弃。最后我们尝试了分块和嵌入，尝试不同大小的信息块并嵌入不同内容，以帮助模型识别最相关的内容。我们确实获得了20%的提升，但离达到客户期望还有很大的差距。我们可能经历了20次迭代才达到65%。在这个阶段，我们曾考虑要放弃，但我们坚持下去，然后尝试重新排序。我们尝试应用交叉编码器重新排序结果，或者使用基于规则的内容，例如“嗯，这是研究，也许我们需要最新的文档”等。事实上，我们的性能取得了显著提升。另外，我们进行了分类。基本上，让模型对两个领域进行分类，然后根据分类的领域，在提示中提供额外的元数据，以帮助确定哪些内容最有可能是相关的。在这种情况下，再次取得了相当不错的成绩，达到了85%。

我们目前正处于投入生产的最佳时机。然后，我们尝试的最后一步是进一步加快工作流程。我们回顾了一切，试图更好地设计引导。接着，我们审视我们所犯错误的类型，并引入了工具。例如，我们意识到存在着结构化数据问题，需要从这些文件中提取数据。我们决定让它访问 SQL 数据库，只需输入变量并执行查询，然后返回结构化数据结果。最后，是查询扩展，有人提出三个问题，然后我们将其解释成查询列表。然后并行执行所有这些步骤，将结果返回，最后合成一个综合结果。这些步骤共同促成了我们达到了98%的准确率。需要指出的是，在这个过程中我们从未进行微调。这一点非常值得一提，因为通常假设投入生产需要进行微调。在这种情况下，我们处理的每一个问题都是上下文有关的。要么是我们未能给出正确的上下文，要么是系统无法判断哪个上下文块是正确的。

为什么了解我们要解决的问题如此重要呢？因为如果我们随时都在微调，就会浪费金钱和时间。这就是为什么这是一个令人满意的成功故事。我想分享一个略有不同的——很酷，谢谢。[笑][鼓掌]甜蜜。我也想讲一个警示故事，因为有时候RAG—— RAG 很棒，你有所有这些很棒的内容，我们将用它来回答问题的模型，但它也可能会适得其反。我来给你讲一个不同的客户案例。我们有一个客户，他们其中之一——试图通过使用检索增强生成来减少幻觉。他们告诉模型，你只能使用你的内容。然后他们有人工贴标签员来检查并将事物标记为幻觉。其中一个，我们有一个有趣的案例，当顾客问道，“有什么可以让我们兴奋起来的好听曲子吗？”这个模型回答用 Journey 的《Don’t Stop Believin'》 。[笑]贴标签的人说，“是的，这绝对是幻觉”，但幸运的是这不是幻觉。

这其实是关于他们的内容。 有人写了一份文件，标题是“激发财务分析活力的最佳歌曲”。答案是“不要停止相信”。 这有点有趣，也是RAG的一个例子。 如果您告诉模型只使用内容，而您的搜索结果不佳，那么您的模型得到正确答案的机会为0%。 我之所以指出这一点，是因为在评估RAG时，您实际上添加了可能出错的其他整个维度。这就像我们的法学硕士可能会犯错误，然后我们进行搜索，这并不能解决问题。 这就是为什么我想提及一下开源社区提出的几个评估框架，特别是爆炸梯度。 他们开发了一个叫做Ragas的框架，这个框架很厉害。它基本上分解了这些不同的评估指标，您基本上可以在GitHub上将其下载并直接使用，或根据您的需求进行调整。基本上，它衡量四个指标。

评估法学硕士回答问题的两个标准为忠实度和相关性。首先从忠实度角度出发，该标准涉及回答问题时的事实分解和事实与内容之间的协调。如果回答与事实不符，则被视为幻觉。系统会生成一个数字作为输出，如果数字高于特定阈值，系统就会被阻止，因为这表明存在幻觉。这一点提供了一个非常有用的衡量标准。另一个标准是相关性，即回答与问题实际相关程度。有时模型会生成大量内容，但回答未能与用户最初的问题相关联。该指标核实了相关性程度。如果发现回答在事实上是正确的，但相关性非常低，那就意味着模型需要更多关注这个问题，或者需要进行一些改进以确保回答能够真正满足用户的需求。这两个标准涉及了法学硕士的专业知识，同时也强调了内容的相关性，这是确保客户满意的关键。

正如前面提到的，Ragas典型的示例就是随着内容越来越多地进入上下文窗口。例如，“嘿，如果我们支付50块，模型就会给出正确答案。”实际上，论文上写的是，这导致了一个迷失在中间的情况，即随着提供的内容增多，模型会开始产生幻觉或者开始忘记中间的内容。

你真正需要的是最准确的内容片段，这就是评估检索内容信噪比的指标所在。它会获取每个内容块，将其与答案进行比较，找出其中是否使用了该内容。这时你就开始思考：“我们得到了很高的准确度，但只有5%的上下文精度。我们能否减少内容量，仍然获得正确答案呢？”

我认为这是一个人们真正感兴趣的领域之一，他们开始思考类似的问题。有时人们开始生产或接近生产，然后本能地就是提供越来越多的背景。实际上，这个指标为您提供了一种非常可靠的计算方法。

就像添加更多上下文一样，实际上对我们是有帮助的。最后一个要考虑的是上下文记忆，它能否检索到所有需要的相关信息呢？基本上，您需要确认回答该问题的相关信息是否确实存在于内容中。这是一个相反的问题，就像“我们是否有一个搜索引擎，它能够将重要内容推到前面，我们是否将其放入了上下文窗口中？它能够确实回答问题吗？”如果这个值很低，那表明您需要优化搜索，可能需要重新排名，微调您的嵌入，或者尝试不同的嵌入方式来呈现更相关的内容。我想，我会把这个问题留给你们，因为这就像我们试图从即时工程和实时自动评估中获取更多性能一样。有时候，您实际想回答的问题与您实际要执行的任务不同。有时候，问题所在实际上在于您要完成的任务，这就需要您采取侧面措施，实际尝试微调的地方。这也是我会转交给约翰来处理的地方，他会更进一步和您讨论微调问题。让我们谈一谈微调。[掌声]

迄今为止，我们一直聚焦于提示技术系列。在这里，我们将讨论一些巧妙的方法，用以在采样时打包LLM上下文窗口，以优化LLM在您的任务中的表现。微调实际上是一种与提示截然不同的技术。首先，从定义开始，微调是指采用经过训练的现有模型，然后在规模较小和通常更专业领域的新数据集上继续进行训练，而不是使用模型的原始数据集进行训练。微调实质上是一个革新过程，我们基于一个基础模型进行微调，最终获得一个完全不同的模型。总的来说，微调这个术语确实很贴切描述了这一过程，因此我们从一些在大规模且多样化数据集上训练过的模型开始。

像5 Turbo或GPT-4这样的模型具备关于世界的广泛通用知识。我们选择其中一个通用模型，并对其进行专门化，从本质上提升其适应我们所关心的任务的能力。为什么要开始进行微调呢？现在我想着重介绍微调的两个主要相关好处。首先，微调通常能使您达到那些没有进行微调就难以达到的性能水平。简单来说，当您使用提示技术时，涉及到可以显示给模型的数据量时，会受到模型上下文大小的限制，对吧？在低端情况下，可能需要几千个标记；而在高端情况下，如果使用GPT-4 Turbo，可能需要128,000个标记。但实际上，与您可以向模型展示的数据量相比，这并不算什么。当您在微调时，对数百万甚至数亿个数据标记进行微调是相当简单的。您可以向模型展示更多示例，并且超出您希望包含在最大上下文窗口中的法学硕士示例。第二个好处是，微调后的模型通常会比相应的基础模型更有效地进行交互。这种效率体现在两个方面。

首先，当您与已经微调的模型进行交互时，通常不需要使用复杂的提示技术来达到该模型所需的性能水平。您不必提供复杂的解释或显式模式，也不必提供上下文示例。这意味着您发送给每个请求的提示令牌更少，这也意味着每个请求的成本更低，通常响应更快。与已经微调的模型进行交互通常更具成本效益和更快的响应速度。

其次，微调的常见用例实质上是将知识从类似GPT-4这样规模较大的模型推广到规模较小的模型，如3.5 Turbo。从成本和响应时间的角度来看，与较小的模型进行交互通常比与较大的模型更为有效。举例来说，假设有个人希望通过法学硕士来解决一个常见任务，比如对房地产列表进行自然语言描述，并尝试提取有关该列表的一些结构化信息。如果我们在不经过微调的情况下尝试解决这个问题，实际上我们需要准备各种提示技术的工具。

我们会创建一些复杂的指令来微调模型。在这种情况下，我们会定义一个显式模式，即在Python中使用Pydantic模型。我们可能还会提供一些上下文示例给模型。然后，我们会为模型提供一个包含新的房地产列表和自然语言描述的输入，让模型输出结果。虽然输出看起来不错，但实际发现存在一个微不足道但关键的错误。模型没有按我们期望的提取日期，而是模板化为了当前日期。修复这个问题很简单。我们可以添加一条新规则，本质上就是提供一个新的上下文示例，就能解决这个问题。让我们看看如何通过微调来解决这一问题。微调过程开始于一个相对简单的数据集。在这里，我们提供了一些示例，希望您注意到它们的简易性。没有繁琐的说明，也没有正式的模式，更没有上下文示例。我们只提供了房地产列表的自然语言描述，以及所需的输出结构。我们使用这个数据集进行模型微调，然后用微调后的模型再次输入一个新的房地产列表，基本上解决了此问题。

这只是一个简单的例子，但在这样的情况下，这个模型既表现卓越又高效。在采样时，我们无需提供繁琐的指令，不需要上下文学习，也没有显式模式。与仅使用提示技术相比，这个模型表现更出色。微调可能是一个相当复杂的过程，因此重要的是设定合理的期望，了解何时微调可能适用于您的用例，何时可能无效。对于强调基础模型中已存在的知识来说，微调确实有很多好处。文本转SQL任务就是一个例子。您拥有一些非常强大的通用基础模型，比如3.5 Turbo和GPT-4，它们真正了解关于SQL的方方面面，包括SQL语法、SQL的不同方言、数据库工作原理等等。但您可能想要通过微调模型，从根本上强调某种SQL方言，或者强制模型不要进入容易出错的边缘情况。本质上，您是在获得基础模型中已有的知识，并强调其中的一个子集。微调对于修改或自定义模型输出的结构或调性也非常有用。

早期一个杀手级用例之一就是强制模型生成有效的 JSON 输出。这是因为如果你试图以编程方式与模型交互，就更容易以编程方式处理生成有效的 JSON 数据。如果输出是无效的 JSON 格式，就会出现很多错误。再者，对模型施加复杂指令可以在微调过程中展现模型的细节，这是为了避免前述情况的发生。你可以展示比你打算嵌入到模型上下文中的示例更多的样本。

然而，微调确实不利于向模型添加新知识。在这些较短的微调过程中，你基本上无法为模型注入新的知识。在这些大型预训练模型的微调过程中，法学硕士中已存在的知识被深入植入到模型中。如果你试图将新知识引入模型，为了 Colin 提到的原因，考虑探索 RAG 等其他方法。此外，微调并不适合快速迭代新用例。进行微调会导致相对较慢的反馈循环，因为创建数据集和其他微调组件需要大量投资。因此，不要一开始就从这里入手。我很想看到有一个成功的微调案例。

这个故事描述了Canva团队与法学硕士合作的情景。具体而言，他们的合作目的是接收用户对设计模板的自然语言描述，然后由法学硕士输出一组结构化的设计指南，用于生成全尺寸的设计模拟，最终呈现给用户。这种方法可以迅速提供用户所需设计的全尺寸模拟，实质上是一种快速获取设计想法并生成实物模型的手段。用户可以直接描述他们想要的设计风格，比如“我想要红色渐变，类似Instagram帖子风格的个人资料照片”，这样的描述被传达给法学硕士，后者需要输出结构化的设计指南。这些指南包括标题、关键样式关键字、英雄图像描述以及实际搜索条件，供图像搜索引擎使用以生成全尺寸模拟的图像。Canva的工作是从基本模型中的3.

任务从5 Turbo型开始，然后转向GPT-4。他们试图深入了解任务的表现如何。结果表现不佳，因此主要由人类专家评估员进行评估。评估员发现，虽然这些模型能够提供合理的输出，但从设计角度来看，这些输出实际上并不重要。随后他们进行了微调。他们针对这项任务对3.5 Turbo型进行了微调，结果让他们非常惊讶，它不仅胜过了基础的3.5 Turbo型，而且实际上远远领先于GPT-4。在这里我们看到的情况是，尽管3.5 Turbo型和GPT-4型通常会输出合理但与设计无关的模型，但当针对这个任务进行微调后，在Canva内经过专家评估员评估时，通常会输出相当出色的设计模型。如果你想思考为什么这个案例有效，那么其实并不需要新知识。解决这个问题所需的一切知识都包含在基础模型中，但这个模型需要具备一个非常具体的输出结构。随后他们使用了非常高质量的训练数据，并且他们有一个很好的基线来进行比较。

他们基本上测试了 3.5 Turbo，也尝试了 GPT-4。他们知道哪些方面取得成功，哪些方面没有，于是意识到微调是完成任务或用于任务的一种良好技术。我想分享一个关于微调的警示故事。我非常喜欢这位博客作者，因为他一直在尝试使用人工智能助手作为写作助手。他们尝试了 Chat GPT 和一些基础模型中的 API，给他们留下了深刻的印象。但令他们失望的是，这些模型没有捕捉到他们的语气。他们在撰写博客文章、社交媒体帖子或起草电子邮件时都会使用非常特定的语气，而基础模型并没有捕捉到这种语气。他们有了一个好主意，说：“我要下载两年的 Slack 消息”，共计 140,000 条消息。他们编写了一个脚本，将这些 Slack 消息格式化为兼容微调所需的数据格式，然后对这些 Slack 消息进行了微调。

5 Turbo。一个漫长的过程。你需要收集数据，整合数据，将其转换成与微调兼容的格式，以微调模型。最终，他们经历了这个过程，得到了一个经过微调的模型，并向其提出了一个要求：“你能为我写一篇关于即时工程的 500 字博客文章吗？”这个模型，即个性化的写作助手，回答道：“当然，我会在早上做。”（笑声）我有点吃惊和震惊，他接着说：“我更喜欢你现在写。”（笑声）- 模型说，“好吧”，然后什么也没做。（笑声）- 在微调团队中，我们确实享受了很大的乐趣，作者绝对是一位伟大的运动员，但如果我们能退一步进行第二次微调，那真的很有效。基本上，作者想要一个能够复制他们写作风格的模型。他们得到的是一个能够复制他们写作风格的模型，但是却有着他们自己的 Slack 写作风格。

在Slack上的沟通方式非常简洁，是意识流风格。往往不使用标点符号，也不追求语法正确性。他们所获得的是一个复制的模型。尽管微调模型以复制你的语气实际上是一个相对不错的方法，但问题在于他们没有充分考虑到为模型提供的数据是否真正达到了他们想要的最终效果。他们或许应该采取获取大量Slack消息，如100条、200条，用这些消息来微调模型的实验，看看它是否朝着正确的方向发展，是否越来越接近我期望模型复制的语气。一旦他们很快发现情况并非如此，也许他们会选择在电子邮件、博客文章或社交媒体帖子上进行微调，这或许会更为合适。我们已经看到了一些示例，有些直觉已经形成，那么实际如何去微调模型呢？和任何机器学习问题一样，第一步是获取数据集，但和大多数机器学习问题一样，这实际上是最为困难的部分。有一些方法可以获取数据集，例如下载开源数据集，或者在私人市场购买数据，也可以聘请付费标注员来收集数据并为你进行标注。

通常，如果所选模型的服务条款支持特定用例，可以选择使用更大型的模型，但必须拿出一部分数据集进行微调。接下来就会进入训练阶段。取决于您选择的训练方式，会有不同的效果。若使用类似OpenAI微调API这样的一站式解决方案，可能相对简单。若尝试微调开源模型也是可行的，只需要拥有自己的GPU并使用适当的框架，需要涉及更多操作。在训练的过程中，了解可以调整的超参数对结果至关重要，对吧？要考虑过拟合和欠拟合的可能性，是否需要微调到灾难性遗忘的程度？重要的是了解可调整的超参数及其对最终微调模型的影响。接着，要强调理解损失函数的重要性。当微调语言模型时，在查看损失函数时，实际上在评估下一个token的预测。对于微调语言模型来说这很有用，但是下一个token的预测通常与您关心的下游任务的表现不太相关。

如果考虑代码生成，解决单一问题的方法有多种不同类型。因此，仅进行下一个标签预测和准确匹配标签的模型损失或变化可能与下游任务的性能变化无关。理解这一点至关重要。接下来是模型评估。有几种不同的方法可以评估模型。基本上，您可以邀请专家查看输出，并在一定程度上对其进行实际排名。另一种方法是，您可以采用不同的模型生成输出，然后将它们相互排名。虽然没有绝对的排序，但可以通过类似于国际象棋中的ELO分数的方法进行评分。您还可以通过拥有更强大的模型来对输出进行排名。这可以使用微调过的GPT-4、开源模型或GPT-3等方法。

对于排名5 Turbo的输出进行微调是非常常见的做法。最终目标是将其部署实际应用，并在推理过程中进行采样。这种循环可以形成反馈机制和数据循环。您可以训练模型，评估其性能，将其部署到生产环境中，在生产中收集样本数据，利用这些数据构建新的数据集，对数据集进行下采样和清理，进一步微调数据集，并使整个系统运行起来。到目前为止，我们已经讨论了这个过程的一些内容，但我想正式确认一些微调的最佳实践。首先是开始快速而小规模的工程和学习。这些技术都是低成本的，并且能让您对法务硕士的工作方式以及它们解决问题的方式有一些直觉。这是一个很好的起点。接着，在进行微调之前建立基线非常重要，类似Canva的成功故事。他们也尝试了

他们使用了 GPT-4 进行了涡轮增压实验。 他们对自己尝试解决的问题有了深入了解，了解了这些模型的失败案例，也了解了在哪些方面表现良好，因此他们准确了解微调的目标。在微调过程中，他们建议从小规模着手，而不是一次性下载 140,000 条 Slack 消息。他们建议先开发一个小而高质量的数据集进行微调，然后评估模型并查看微调是否朝着正确的方向发展。在微调模型时，建议观察输出，了解模型在哪些领域表现不佳，然后针对这些领域使用新数据进行专门调整。他们指出，对于法学硕士而言，微调数据集的质量远比数量重要。在培训过程中，数据量的部分是在预训练中完成的。因此，现在似乎更注重少量高质量示例。最后，他们提到了微调和 RAG，指出将它们结合在一起可能适用于某些用例。通常，微调模型是为了理解复杂的指令，而之后无需再提供。

在微调模型时，通过简化复杂指令和采样示例，使其使用更高效。这意味着减少采样时所需的提示标记，因为不再需要进行复杂的提示工程。这些信息会被融入到微调的模型中，从而有更多空间来检索上下文。然后，可以使用RAG将相关知识注入到上下文中，已经最大化了可用的上下文。然而，需要小心不要过度饱和上下文，否则可能导致与实际问题无关的虚假相关性。总的来说，这为更重要的目的打开了上下文窗口。现在，我们将讨论该理论的应用，而非仅停留在理论层面。让我们把话题转回给科林，继续向前迈进。- 谢谢，约翰。[掌声] - 酷。现在让我们看看这些理论。我们将要解决的问题是Spider 1.

在基准测试中，一个有效的方法是根据给定的自然语言问题和数据库模式生成语法正确的SQL查询来解答该问题。通过我们的方法，我们开始尝试快速工程以及RAG。我们首先尝试简单的检索，使用问题并查找SQL查询来回答类似的问题。我们还尝试以不同方式格式化嵌入。虽然我们只是通过几个示例尝试了一系列快速工程，但结果并不尽如人意。我们意识到问题的多样性可能会导致完全不同的答案，即使问题很相似也可能如此。因此，在考虑问题时，我们要思考到这一点。

在解决这个问题时，使用问题所假设的答案来进行搜索可能会获得更好的结果。我们采用的方法是使用假设的文档嵌入。我们生成一个假设的SQL查询，然后将其用于相似性搜索。针对这个具体问题，我们实际上获得了显著的性能提升。我们也尝试了上下文检索，只进行简单的过滤。我们会对收到的问题根据难度进行排名，然后基本上只从RAG模型中选择同等难度的示例，如果你能理解我的意思的话。这给我们带来了更好的改进。接着，我们尝试了一些更先进的技术。这时候可能会思考链式推理。你可以尝试识别列，然后识别表，最后构建查询。最终我们采取的方法实际上相当简单。我们进行了自我一致性检查。即让系统实际构建一个查询，运行查询，如果失败，我们就提供错误消息和一些注释，然后再试一次。事实上，让GPT进行自我修复又变得有趣起来。如果您

在这个案例中，延迟并不是你担心的大问题或成本，因此我们认为这种方法实际上运作得相当顺利。我们得到的结果如下。我想跟你谈一谈这件事。最右边是我们进行快速工程的地方，但效果不太理想。我们最初的成功率是69%。随后我们添加了一些例子，并取得了一些改进。这告诉我们，RAG实际上可以带来更进一步的提升。我们尝试了这个方法，你可以看到我们的表现提升了3%。之后使用答案（假定的文档嵌入），我们又取得了5%的提升，这非常不错。事实上，仅仅通过使用假设问题而不是实际输入问题来搜索，我们的表现就有了巨大的改営。接着我们只是增加了示例的数量，但通过这种方式，我们比现有的技术水平少了四分之一。再说一次，这只是几天的时间，从快速工程转向RAG。向你展示从这些非常基本的起始方法中可以获得多少提升。接着我们决定进行微调，看看是否还可以进一步完善，这部分工作我将交给约翰来完成。

- 对于模型微调的过程，我们选择将其委托给我们的首选合作伙伴 Scale AI 进行。他们首先根据我们的建议建立了一个基准线，与我们在前一张幻灯片中看到的基准线69%相同。这一步只需要进行简单的快速工程技术即可。接着，他们使用了简单的技巧对 GPT-4 进行了微调，只需要在示例中对架构进行一些简单的调整。通过这种简单的微调方式，一点点快速的技术改进，他们成功将性能提升至接近82%。我们从技术最前沿已经很近了。接着，他们将 RAG 技术与这个模型相结合，动态地将一些示例注入到上下文中，以解决实际问题。即使没有采用最先进的 RAG 技术，他们的成功率也达到了83.5%，这使我们离先进水平更近了。这里我想要强调的是，如果你看看 Spider 数据集排行榜，你会发现使用的技术非常复杂。通常需要进行大量的数据预处理和数据后处理，甚至将一些极端情况硬编码到用于评估模型性能的脚本中。但实际上，我们不需要使用这些复杂技术。只要简单的微调和几个即时的技术改进，只要我们遵循最佳实践，我们就能取得巨大进步。

这个基准确实已经达到了处于领先水平，如众所周知。它展示了微调和RAG的强大结合。总结一下，当你在解决问题并想要提高法学硕士的表现时，开始使用快速的工程技术是个不错的选择。这些投资成本很低，让你可以快速迭代，验证法学硕士作为解决你正在尝试解决问题的可行技术。你可以持续迭代，直到性能达到稳定状态，然后需要分析遇到的错误类型。如果你需要向模型引入新知识或更多背景信息，就选择走RAG的路径。如果模型不一致地遵循指示，或者需要遵循严格或新颖的输出结构，又或者通常需要更有效地与模型交互，也许是时候尝试微调了。重要的是要记住，这个过程不是线性的，这是我们想要强调的。也许需要49次迭代才能达到你真正满意的水平，并且你在这些技术之间来回跃迁。总之，希望您喜欢这次演讲。如果有任何问题，科林和我会在剩下的时间里继续留在这里。

为您演奏了一首优美的音乐。希望您能享受这段美妙的时光。