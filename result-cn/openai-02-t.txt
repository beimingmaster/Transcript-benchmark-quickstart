大家好，欢迎参与到新的 AI 堆栈和运营活动中来，我们将探讨从原型到生产的过程。我是 Sherwin，领导 OpenAI 开发者平台的工程团队。我们团队负责构建和维护 API，已有超过 200 万开发者（希望包括你们中的许多人）利用这些 API 构建产品。我是 Shyamal，是应用团队的一员，曾与数百家初创公司和企业合作，在我们的平台上帮助他们打造出色的产品和体验。今天，我们很高兴与大家讨论应用程序从原型阶段进入生产的过程。首先，我想客观地分析一些事实。虽然人工智能模型 ChatGPT 已经进入我们的生活并改变了世界，但实际上它推出至今不到一个完整的日历年。ChatGPT 实际上是在2022年11月下旬上线的，现在距离那时已不到整整12个月。

同样，GPT-4是在2023年3月才推出，距离人们体验我们的旗舰型号并尝试将其应用到自己的产品中还不到八个月。现在，GPT已经从我们在社交媒体上玩弄和分享的玩具，变成了我们日常生活和工作场所使用的工具，成为企业、初创公司和企业的能力。各地的开发人员都在努力将其整合到自己的产品中。通常，第一步是构建原型。正如你们许多人可能知道的那样，使用我们的模型之一来设置一个非常酷的原型非常简单和容易。制作一个演示并将其展示给我们所有的朋友真是太酷了。然而，从那里到生产通常存在很大的差距，而且通常很难将产品投入生产。这在很大程度上是由于这些模型的不确定性。如果没有指导框架，将非确定性应用程序从原型扩展到生产通常会感觉非常困难。通常，您可能会有这样的感觉：有很多工具可供您使用，而这个领域的发展速度非常快。

在这次演讲中，我们将为大家提供一个指导框架，帮助您将应用程序从原型阶段转移到生产环境。我们设计的这个框架以堆栈图的形式呈现，受到客户在扩展应用程序时遇到的挑战的影响。我们将探讨如何在此基础上构建令人愉快的用户体验，通过建立模型、使用知识库和工具处理模型不一致。我们还将讨论如何自信地迭代应用程序，以及管理应用程序规模，考虑成本和延迟方面的编排。针对每个主题，我们将分享一些策略，希望您可以学习并在自己的产品中应用。通常情况下，我们最初只有一个简单的原型，还没有完整的堆栈结构。在这个阶段，您可以安装应用程序并直接与它们的API进行交互。虽然这一开始可能效果很好，但很快您会意识到这还远远不够。接下来，我们将详细讨论这个框架的第一层 - Shyamal。

技术和与其相关的用户体验同样重要。虽然我们的目标是建立一个可信、高度防御且愉悦的用户体验，但人工智能辅助的副驾驶和助手提出了多种人机交互和用户体验的挑战。在利用我们的模型构建扩展应用程序时，考虑到独特因素对于为用户带来更优、更安全的结果变得尤为重要。我们将探讨两种策略来解决在我们的模型之上构建应用程序时出现的一些基本是随机性的挑战。在处理不确定性的同时，建立可控制性和安全性的屏障也很关键。控制不确定性意味着通过管理模型如何与用户交互和响应来积极优化用户体验。目前，许多产品都呈现确定性，交互会以可复制且精确的方式进行。然而，随着转向构建语言用户界面，这一点一直是个挑战。

为了不是取代人类判断，而是增强人类能力，以人为本的设计变得异常关键。在设计ChatGPT时，我们融合了一些用户体验（UX）元素，用以指导用户并控制由模型驱动的应用产生的固有不确定性。首先，根据使用情景，一个策略是让人类介入循环，并且知道由生成式人工智能创建的初始作品可能不是用户期望的最终作品。让用户有机会随着时间迭代并提升质量，对于应对不确定性和构建强大的用户体验至关重要。另一方面，反馈控制也提供了修正错误的功能，并且是构建可靠数据循环的关键信号。另一个构建透明用户体验的关键方面是传达系统功能和限制给用户。用户可以了解人工智能的能力范围，以及它的局限性。

人工智能犯错的情况在ChatGPT中通过底部通知形式向用户展示。这样设计帮助用户正确设置期望，通过精心设计的用户界面引导用户与人工智能互动，获取有益且安全的回应，实现最佳效果。ChatGPT通过暗示性提示帮助用户更好地理解体验，启发用户提出更好的问题、提供问题解决的替代方案，并促使更深度的探索。这三种策略将用户置于核心位置，通过设计用户体验掌握控制，最大程度利用人工智能产品，营造协作、以人为中心的体验。通过这种方式，建立信任基础，让您在部署基于GPT的应用程序时更加自信，不仅需要构建以人为本的用户体验，还要确保用户在应用中得到更好的体验。

在构建应用程序时，我们需要考虑到可操纵性和安全性的护栏。护栏可以被视为位于用户体验和模型之间的一种重要约束或预防性控制。它们的作用是阻止有害和不必要的内容进入应用程序和用户界面，同时为生产模型增加可操作性。我们看到一些由开发人员构建的最佳交互实例将安全性和安全性作为体验的核心。最佳的模型是那些最符合人类价值观的模型。我们相信，一些最有用和最有能力的用户体验可以充分发挥安全性和可操纵性，从而获得更好、更安全的结果。为了说明这一点，让我们以DALL·E中的一个简单提示作为例子，比如，创作一幅圣诞树的抽象油画。DALL·E可以通过在色调、树的形状、颜色和笔触等方面添加更多细节和特异性来加强提示，使其非常适合圣诞节。

我现在并不是一名艺术家，所以在这方面我可能做得不是太好。但在这一情况下，我把DALL·E当作我的合作伙伴，将我的想法转化为想象。也许你会想知道，这是什么意思？唔，用于创建更好的作品的相同快速丰富技术也可用作安全保障。如果该模型检测到可能侵犯个人隐私或权利的问题，它会提出不同的建议，而不是直接拒绝。在这种情况下，它不会生成真实个人的图像，而是捕捉精髓，然后创作一个虚构人物的形象。我们分享了一个护栏的实例，它有助于提高可控性和安全性，但护栏可以采取许多其他形式。一些例子包括合规护栏、安全护栏和确保模型输出在语法和语义上正确的护栏。当你为高度监管的行业构建界面时，这些护栏变得至关重要。

我们对错误和幻觉的容忍度较低，安全性和合规性必须是首要考虑的因素。我们致力于打造出色的用户体验，注重可操作性和安全性，但这只是旅程的开始。 在这一阶段，您已经为所有用户构建了愉快的用户体验，并能够处理这些模型的一些不确定性。尽管这种原型非常有效，当您将其扩展到生产环境时，由于从用户那里获取查询类型非常有限，当您扩展数据库时，很快就会遇到一致性问题。在应用程序中，您接收的查询和输入类型将开始发生很大变化。因此，我们想要讨论模型一致性，它构成了我们堆栈的第二部分，涉及使用知识存储和工具来奠定模型基础。我们观察到客户采用了两种策略来管理这些模型固有的不一致性，一种是在模型级别限制模型行为，另一种是利用一些实际世界的知识为模型奠定基础，例如知识库或自定义工具。

首先，限制模型的行为本身可能会是一个问题。因为通常来说，很难控制大型语言模型（LLM）固有的随机性质，特别是对于我们的API客户，您并没有对模型进行真正底层访问的权限，因此管理这种不一致性情况确实会变得很困难。今天，我们实际上引入了两个新的模型级功能，可以帮助您约束模型的行为，我们今天想和您讨论这一点。

第一个功能是JSON模式，打开该模式将会限制模型的输出在JSON语法内。第二个是我们引入到我们聊天完成模块中的名为C的新参数，以获得可重现的输出。JSON模式是许多人经常询问的功能之一。它允许您强制模型输出符合JSON语法。对于开发人员来说，这通常非常重要，因为您需要将LLM的输出输入到下游软件系统中。为了实现这一点，您通常需要一种通用的数据格式，而JSON是其中最流行的格式之一。虽然这很好，但这里存在一个不一致性的一个很大缺点。

是的，当模型输出无效的 JSON 数据时，实际上会破坏您的系统并引发异常，这对您的客户来说并不是一种很好的体验。今天我们要介绍的 JSON 模式可以大大降低出现这种情况的可能性。它的工作原理如下：在完成对话过程中，我们增加了一个名为 JSON 架构的新参数。如果您向该参数传递并键入对象，然后将其传递到我们的 API，那么您从我们的系统或 API 获得的输出将被限制在 JSON 语法内。其中的内容字段将受到 JSON 语法的限制。虽然这并不能完全消除我们在内部评估中看到的所有 JSON 错误，但它确实显著降低了该模型输出的 JSON 错误率。

第二点是通过对话完成中的 C 参数可以获得显着更高的可重复输出。我们的许多模型都是不确定的，但如果您仔细观察，就会发现它们实际上是在幕后导致许多不一致行为的三个主要因素之一。其中一个因素是模型根据其概率采样其令牌的方式。

这个系统由温度和之前已设置的最高P参数来控制。第二个参数是C参数，它是模型用来开始计算并生成随机数的基础。第三个参数被称为系统指纹，描述了后端引擎的状态以及我们在这些引擎上部署的代码。随着这些变化，会出现固有的非决定性因素。直到今天，我们只让人们访问温度和最高P。从今天起，我们实际上允许开发者访问输入中的C参数，并在对话结束时使开发者能够了解系统指纹。实际上，在对话结束时会有一个种子参数可供您输入，这是一个整数。如果您传递一、二、三、四、五这样的种子，并将温度设置为零，随着时间的推移，您的输出将更加一致。如果您将这个特定请求发送给我们五次，您最终得到的输出将显著更加一致。

此外，我们还为您提供了系统指纹参数的访问权限。每次模型响应都会告诉您有关引擎盖下发动机系统的指纹。如果您在早期响应中获得完全相同的系统指纹，并且传递了相同的种子和零温度，那么您几乎肯定会得到相同的响应。这种行为是模型级别的，您可以很快掌握并尝试，即使在今天也可以。更复杂的技术称为“基础模型”，它通过为模型提供额外的事实作为其答案的基础来帮助减少模型行为的不一致。这种做法源于，当模型独立存在时，通常会产生虚假信息，这是被广泛认知的现象。我们强迫模型说话，所以如果它真的不知道任何内容，它就必须尝试说一些话，而很多时候会捏造事实。因此，为模型奠定基础并提供大量的事实是非常重要的，这样模型就不会产生虚假信息。具体而言，我们要做的是在输入上下文中明确地为模型提供一些基础事实，以减少模型产生虚假信息的可能性。

这实际上是一种常见情况。 在系统结构中可能呈现如下：用户发出查询，该查询经过服务器处理后并非立即传递给API，而是优先经过某种事实来源的往返验证。假设我们将查询发送到了事实来源，希望它能返回相关的事实数据，然后我们会收集这些事实数据以及查询本身，再将它们传递给我们的API。而后，API会接收这些数据，在这些事实的基础上综合生成相应的响应。为了更加具体地说明，实现这一过程的一种方法是使用RAG或者说矢量数据库，这是一种当前非常普遍且受欢迎的技术。举例来说，假设我正在开发一个客户端服务器站点，用户询问如何删除他们的账户？这个问题可能是特定于我的应用程序或产品的，因此API本身并不会直接了解如何操作。比如我可能会利用一个像矢量数据库这样的检索服务，用它来索引内部文档以及关于支持问题的常见解决方案，并且这个数据库懂得如何处理删除文档的操作。那么我需要做的第一步就是向检索服务查询如何删除一个账户。

假设您发现了与我相关的片段，其中提到在帐户删除常见问题解答中，您可以进入设置，向下滚动并单击相应选项等等。然后我们将这段信息传递给我们的API进行处理，API将根据这一事实返回一些响应给用户。例如，在这种情况下，应该会提示您要删除您的帐户，请转到设置，向下滚动，然后单击相关选项。这是一种应用方式，实际上也可以通过OpenAI的API调用功能来使用自己的服务，我们已经看到客户成功地利用了这一功能。在这种情况下，我们可使用我们自己的API或微服务，而不必依赖于矢量数据库。

假设某客户询问当前的贷款利率是多少，在这种情况下，即使我们的贷款管理系统也无法立即给出答案，因为利率一直在变动。假设我们有一个微服务负责执行日常同步作业，下载并监测当前的抵押贷款利率。在这种情况下，我们将使用函数调用。我们会告诉我们的模型可以访问一个名为 `get_mortgage_rates` 的功能，该功能可以提供最新的贷款利率信息。

假设您有一个情景，涉及到一个返回了30年期固定利率贷款的8%的API查询，然后这个查询看起来很相似于其他内容。您将这个查询传递给API，然后通过模型得到了地面响应，暗示一些地方有优点，有不足。当前的30年期固定利率实际上是8%。基于这个普遍事实源，您以通用方式使用它来帮助根据这个基础的事实来根据模型，并减少模型的不一致性。尽管我写了两个不同的例子，但根据这个基础的事实源可以是其他东西，比如搜索索引，甚至是弹性搜索或者某种更通用的搜索索引。它可以是类似数据库的东西。甚至可能是浏览互联网或者尝试一些智能方式来获取更多的事实。主要思想是提供一些可以对模型产生影响的东西。我想要强调的是，我们刚刚宣布的OpenAI Assistants API实际上提供了一个可直接使用的检索设置，供您使用并在其基础上构建体验。建议您看一下。Shyamal：迄今为止，我们讨论了构建透明以人为本的用户体验。然后我们探讨了如何…

为了始终如一地提供用户体验，我们需要通过发布模型级功能和基础模型来不断改进。接下来，我们将探讨如何在不退步的情况下持续提高这种体验，这就彰显了评估模型性能的重要性。在这里，我们将讨论两种策略，可以帮助评估使用我们的模型构建的应用程序的性能。第一个策略是为特定用例创建评估套件。与许多组织合作时，我们经常听到评估模型性能和测试进度非常困难，这通常会拖慢开发速度。其中一部分原因在于开发人员没有在系统开发过程中考虑评估模型性能，或者评估发生得太晚。评估是取得成功的关键。在实际产品场景中测量模型性能对于避免回退和维持操作的一直性是至关重要的。

在大规模部署这些模型时，建立信心是非常关键的。评估本质上可以被视为大型语言模型的单元测试。虽然人们常将提示视为一种哲学，但实际上更类似一门科学。将其与评估结合，您可以将其看作软件产品或交付的一部分。评估有助于将模糊的对话转化为可以量化的实验，并使模型治理和模型升级变得更加容易，同时能更明确地设定好坏期望。功能、评估和性能应该一起发展，并且它们应该被视为您开始人工智能工程之旅的起点。构建评估的方法是从简单开始，让人工注释者在您的应用程序输出测试时进行评估。典型的方法是确保您的应用程序具有不同的提示集和检索方法等，然后通过检查这些响应来构建评估的核心测试数据集。

接下来，您需要手动对它们进行评分。随着时间的推移，您会得到一个测试套件。然后，您可以在线或离线运行该测试套件，或将其作为CICD管道的一部分运行。由于大型语言模型和人类一样，它们可能会犯错误。根据您的用例，您可能需要考虑构建评估来测试诸如错误的输出格式、幻觉、代理脱轨、不良语气等问题。让我们谈谈如何构建评估。今年初，我们开源了一个名为"evals"的框架，为许多开发人员提供了灵感。该库包含对不同特定用例和垂直领域有挑战性的评估注册表，以及许多模板，这些模板对于许多人来说可以成为了解应进行的评估和测试类型的坚实起点，可以根据您的特定用例进行构建评估套件。构建评估套件后，记录和跟踪评估运行是重要的实践和卫生习惯。

在这种情况下，我们进行了五次不同的评估运行，每次都根据我们的黄金测试数据集进行评分，并收到注释反馈和更改审核。更改审核可能包括提示、检索策略、一些简短示例的修改，甚至升级到模型快照等内容。您并不需要复杂的工具来开始跟踪这些事情。许多客户起初只是用电子表格开始记录，但关键是要以非常细致的级别存储每次运行的结果，以便您可以相应地跟踪它。虽然人工反馈和用户评估是最高质量的信号，但通常昂贵或者并非总是实用，例如，当无法使用真实客户数据进行评估时。这就是自动评估发挥作用的地方，可以帮助开发人员快速监控进度并进行回归测试。现在让我们谈谈模型分级评估，也就是使用人工智能来对人工智能进行分级。GPT-4可以成为一个强大的评估器。

在许多自然语言生成任务中，我们已经注意到GPT-4通过一些额外的提示方法与人类的判断有很好的相关性。对模型进行分级评估的好处在于，通过减少人类对语言模型可以处理的评估过程部分的参与，人类可以更专注于解决改进评估方法所需的一些复杂边缘情况。让我们看一个实际的例子。在这个案例中，我们有一个查询输入以及两组补全。一组是基于事实的，另一组是从模型中随机取样得到的。在这种情况下，评估是一个简单的提示，要求GPT-4将提交的答案内容与专家答案进行比较。GPT-4会对提交的答案进行评分，在这个例子中，GPT-4观察到提交的答案与专家答案之间存在差异。我们可以通过这种方式进行评估，以及对提交的答案和专家答案之间的差异进行分析。

我们可以利用一些额外的提示工程技术（例如思维链等）来改善我们的评估提示，从而进一步实现这一目标。在先前的例子中，评估通常是非黑即白的。答案要么符合基本事实，要么不符合。但在很多情况下，我们需要考虑到与用户期望或所需结果紧密相关的评估指标。

举个例子，考虑到谢尔温（Sherwin）的客户服务助理示例，我们希望评估一些自定义指标，比如响应的相关性、响应的可信度等，并让模型根据这些不同的指标进行评分，或者依据我们制定的标准来评估。下面是一个标准或评分卡的示例。在这里，我们基本上提供了GPT-4这个模型的相关性、可信度和正确性标准，并使用GPT-4对候选输出进行评分。一个很好的建议是展示而非叙述，这意味着我们可以提供一些1分或FI分数的示例来说明具体该如何评分。这可以帮助人们更好地理解。

为了优化评估过程，确保模型正确理解标准传播，需要采取能够真正帮助模型区分高质量和低质量文本的方法。在这种情况下，GPT-4通过学习语言质量的内部模型来实现这一目标。这种内部评分机制能帮助我们对新的候选输出进行自动评估。即使GPT-4的成本高或评估速度慢，我们也可以利用价格相对较低的3.5 Turbo模型进行微调。这个模型本质上是对GPT-4输出的提炼，使其更擅长评估您的特定情况。在实践中，这意味着您可以利用GPT-4规划高质量评估数据，然后通过微调非常擅长评估这些输出的3.5 Turbo模型来评估您的应用程序的性能。这种方法有助于减少仅使用GPT-4进行评估可能带来的偏差。采用评估驱动开发的方法至关重要。良好的评估是成功评估模型性能的关键。

评估与您尝试获得的结果或您关心的用户指标密切相关。就RAG而言，它们具有非常高的端到端覆盖范围，并且可扩展计算。这就是自动评估真正有用的地方。此时，您已经建立了出色的用户体验，可以稳定地提供给用户，同时您还可以利用评估的结果自信地完善产品。如果您把这一切都做对了，通常您会发现您的产品大受欢迎、非常火爆。如果去年向我们展示了什么，那就是消费者甚至内部员工对人工智能的浓厚兴趣无法满足。通常情况下，您现在可能会开始考虑如何管理规模。通常，管理规模意味着要管理延迟和成本。到此为止，我们介绍了堆栈的最后一部分，称为编排，您可以通过在应用程序中添加一些额外的机制和分支来管理规模。我们在管理成本和延迟方面看到的两种策略涉及使用语义缓存。

为了减少访问API的频率和成本，可以使用语义缓存这一概念。就系统层面而言，语义缓存实际上是在我们和您的应用程序之间添加一个新层。这意味着当您收到类似查询“GPT-4何时发布”的请求时，您可以先查看语义缓存中是否有相关内容。如果缓存中没有信息，那么再向我们的API发送请求。API的响应可能是类似于“2023年3月14日”这样的日期，然后您将这个响应保存在语义缓存中，这个缓存可能是矢量数据库或其他类型的存储。您需要保存这个响应，并使用“GPT-4发布时间”这样的查询键进行索引，然后再将结果传递回您的用户。

不过，假设一个月或一周后，另一个用户询问GPT-4的发布日期呢？在这种情况下，语义缓存需要定期更新或设置合适的过期时间，以确保其中的信息与真实情况保持同步。如果过期时间到了或者需要更新缓存，那么您可以再次向API发送请求以获取最新的信息，然后更新到语义缓存中，以便未来的查询获得准确的结果。

现在，您的查询和之前的查询略有不同，但在语义上非常相似，可以使用完全相同的响应来回答。在这种情况下，系统会在缓存中查找语义，发现已经有了这个信息，只需在2023年3月14日时返回给用户即可。通过这样设置，实际上节省了延迟，因为不再需要来回访问我们的API，并且也节省了成本，因为不再需要额外点击和支付代币。虽然这一方法非常有效，但管理起来可能有些困难，而且通常有更为有效的方式来管理成本和延迟。这就是我们开始考虑采用更经济模式的原因，也是优化编排真正发挥作用的地方。当提到采用更经济的模式时，通常首先考虑的是从GPT-3升级到3.5 Turbo版本，这听起来非常不错，因为GPT-3已经表现出色。

5 Turbo虽然速度快、价格便宜，但显然智能程度不如GPT-4。将3.5 Turbo用于应用程序时，即使速度快也难以提供优质的客户体验。而我们推出的GPT-3.5 Turbo Finetuning API受到客户热烈欢迎，通过微调GPT-3.5 Turbo的定制版，客户能在降低成本的同时获得较低延迟和成本的好处，满足特定使用场景需求。微调已被广泛讨论，核心在于使用自有的数据集，包含数百甚至数千个示例，描述在特定场景中模型的行为。您可传递整理后的数据集至我们的微调API，稍作参数调整，最终输出专门适用于您和您的组织的模型。

针对 5 Turbo 的自定义微调版本，虽然这种方法非常棒，但实际上，它通常会涉及到昂贵的激活能量，因为生成这样一个优质数据集可能成本颇高。正如我提到的，您的使用案例可能需要数百、数千，甚至数万个示例，而通常您要么自己手动创建这些示例，要么雇佣承包商来负责这些任务。然而，我们看到很多客户采取了一种非常独特的方法，就是实际上利用 GPT-4 来创建用于微调 3.5 Turbo 的训练数据集。这种方法开始看起来与 Shyamal 刚刚介绍的评估方法非常类似，但GPT-4 的智能程度更高，您实际上可以给它一些提示，它会为您生成一系列输出，这些输出可以作为您的训练集。在这个过程中不需要任何人工干预。您在这里的有效做法是从 GPT-4 中提取输出并将其输入到 3.5 Turbo 中。

在GPT-5 Turbo中，对其进行微调以提高性能是一种常见做法。通过这种方式，经过微调的3.5 Turbo版本几乎可以与GPT-4相媲美，尤其是在特定领域的应用中。通过努力完成这些微调，您将获得相当可观的回报，不仅因为GPT-3.5 Turbo明显更快，而且在成本方面也更具竞争力。举例来说，即使在GPT-4价格下降后，经过微调的3.5 Turbo版本依然比原价便宜70%到80%。尽管它价格不如常规的3.5 Turbo便宜，但相比较GPT-4还是有较大的优势，使用微调版本的3.5 Turbo将会节省很多成本。

总之，我们已经探讨了一个框架，帮助您处理使用我们的模型构建的扩展应用程序（从原型到生产）时所面临的独特考虑因素和挑战。让我们进行回顾。

我们讨论了如何构建一个有用、愉快且以人为本的用户体验，方法是通过控制不确定性和添加护栏。接着，我们着眼于如何通过基础模型和一些模型级功能来始终提供这种用户体验。我们也谈到了要通过实施评估来持续提供非回归的用户体验。最后，我们探讨了规模带来的考虑因素，具体是管理延迟和成本。

正如我们所看到的，使用我们的模型进行构建增加了可能性的广度，但也带来了挑战的深度。这些讨论中的所有策略，包括堆栈编排的部分，都已经融入到一个新的学科中，称为LLM Ops或大型语言模型操作。就像DevOps在2000年代初期出现以简化软件开发流程一样，LLM Ops的近期出现则是为了解决使用LLM构建应用程序所面临的独特挑战，并已成为许多企业架构和堆栈的核心组件。

LLM Ops 可以被看作是为实现LLM端到端运营管理所需的实践、工具和基础设施。这是一个广泛而不断发展的领域，我们仅仅触及了其表面。尽管我们没有详细介绍，但以下是它的一个概览。LLM Ops 功能有助于解决监控、性能优化、帮助实现安全合规性、数据和嵌入式管理、加速开发速度以及真正加速大规模可靠的测试和评估等挑战。在这里，观测和跟踪变得尤为重要，以便于使用提示链和助手来识别和调试故障，并更快地处理生产中的问题，从而使不同团队之间的协作更加容易。比如，网关在简化集成方面非常重要，可以帮助集中管理安全性、API密钥等。LLM Ops 确实能够扩展到数千个应用程序和数百万用户，并基于正确的基础，可以实现这一切。

组织可以通过真正加速采用来实现目标。关键不在于一次性工具，而是持续发展长期平台和专业知识。就像一个年轻的探险家站在门槛上一样，我们面临着广泛的机遇，可以构建超越现有框架的基础设施和原始模型。我们很高兴能够帮助您为下一代构建助手和生态系统，为未来的后代打下坚实基础。我们有太多事情需要创建和探索，只有共同努力才能实现。感谢大家的支持。【掌声】【音乐】