https://www.youtube.com/watch?v=ct4tdyyNDY4


大家好，很高兴能与你们相聚在这里。我是特德·肖，是谷歌大脑团队的高级研究工程师。在过去的五年里，我一直致力于研究机器人技术，主要涉及多任务学习、强化学习等领域。最近，我开始思考如何让机器人更好地在现实世界中发挥作用。

今天我们要谈论几个不同的话题。首先，我想说的是我们的团队非常庞大，有超过40名成员已经与产品合作多年了。他们的努力是巨大的，我很荣幸能够是其中的一员。

此外，我想要强调的是，我的个人观点可能会比较激进、有争议。请记住，这些只是我的个人看法，不代表谷歌团队其他成员的观点。

欢迎来到我的 TedX 页面，也许你们中有些人已经看过许多关于酷炫机器人和学习的视频。这些日子我比以往任何时候都更加兴奋。我不是在吹嘘，我觉得在过去两年里，研究者和机器人技术在学习方面的看法发生了根本性的变化。我认为这种变化不仅仅局限于各种领域，比如语言和音频等，而是在整个大规模互联网模型的基础建模方面更为普遍。今天我要告诉大家的是，我对当前时代感到特别兴奋，我认为在机器人学习领域出现了一种根本的范式转变。希望在我的演讲结束时，您能留下一种感受：对机器人技术更加兴奋，或者相信现在正是我们应该迈出的一步，让机器人技术真正开始呈指数级扩展。

今天我想和大家分享一些很酷的东西，让我的演讲更成功。我们来看看演讲应该包含哪些部分。首先，我们会从一个高层次开始，讨论基础机器人技术模型究竟是什么，以及我们是如何实现这个目标的。接着，我们将深入探讨一些不同的案例，展示我团队在过去一两年里的一些令我们自豪的成就。最后，我们将回到高层次，然后更具体地讨论机器人学习的下一步应该是什么。那么，为什么机器人技术的基础模型具有如此重要的意义呢？

接下来，我会把“互联网规模模型基础模型”称为“庞大语言模型”，把“大型语言模型”称为“机器人技术”，这样应该更容易理解。这些模型是在斯坦福大学研发的，对机器人技术的发展有重要意义。

大型整体野兽，也就是训练大量数据的大型模型，在发展过程中有两个关键特点。一个是涌现，简而言之就是在小规模上表现出来的效果，当规模扩大时会变得更出色。也就是说，数据越多、计算越多、模型越大，效果会变得越好。我们可以观察到，当这些模型达到一定水平时，它们的应用领域也会逐渐扩展。有两篇很值得推荐的博客文章可以深入了解这一现象。其中一篇由Jacob Steinhardt撰写，标题是“人工智能的不同之处”，讨论了在其他领域（如物理学或生物学）中我们所见的现象，比如单个水分子的行为会随着变化而变得截然不同。与此不同的是，一些力（比如静电力）在增长的过程中开始聚集，表现得像液体一样。这样的现象我们在动物群、人类社会和经济领域都能看到，并且在不同领域都有发生。目前，我们甚至在人工智能领域也能观察到类似的情况，即模型在较小规模上展现出一些特长，逐渐呈现相同的趋势。

有些事情开始时可能难以实现，但当达到一定规模后，它们就能发挥非常有效的作用。在Jason的博客文章《新兴技术》中提到了这一现象。图表显示，当任务跨越多个领域时，不管是模块化算法还是问题解答，成功率都大致相同，直到模型变得足够庞大和优秀，然后成功率就会迅速提升。这就是为什么我觉得这一点非常令人兴奋。如果你们有任何问题，我很高兴能有机会与大家讨论，并分享我们已经探索的一些方向。希望我们接下来可以在十分钟左右的时间里深入探讨这个话题。

这个问题很有意义。在我们进一步讨论任何机器人基金会模型是否可行或必要之前，我们需要先思考一下是否真的有必要这么做。我认为这是所有人（包括我自己）都在内心深处思考的问题。

新兴技能对机器人技术的发展至关重要。过去几十年，机器人技术的研究主要局限在受限空间内，与人类日常生活场景相比存在很大差距。想要有重大突破，就需要依赖新兴技能的发展，以处理更为复杂的任务。例如，一个人形机器人程序可能需要数百次试验才能完成一个空翻，要让机器人能够适应真实世界的复杂情况，就需要依赖新的涌现现象。探讨为什么或为什么不一个机器人技术的基础模型可能会奏效，是一个很有趣的话题。这种方法在其他领域也同样得到有效应用，比如音频编码或语言处理。

3D模型和机器人技术可能会面临一些挑战，比如体现效果、因果关系和物理基础等问题。这些因素可能会阻碍我们制定简单方法适用于其他领域的障碍。如果机器人技术无法成功应用于这些方法，答案也许就在于研究背后的原因。我个人觉得乐观，认为并没有什么特殊的阻碍会阻止机器人技术运用这些方法和技巧。但是解答这个问题可能需要更多的哲学启示以及一个固有的模型，以便我们能够为机器人技术建立模型。我们需要考虑如何做到这一点。或许我们可以从其他领域的经验中汲取灵感，站在它们的肩膀上，看看如何将这些经验应用于机器人技术。首先，我们可以研究机器学习在不同设计原则下的表现，并将其与其他领域进行比较，然后再探索高容量架构。

今天我们要谈论的话题是一些新颖的想法，比如自我注意力机制，就像研究者安德烈·卡帕西提出的那种。

是的，这些技术可能会逐渐在互联网上被淘汰，而不仅仅是原理。让人兴奋的是，我深信你也知晓，对专家和普通人来说，这都是令人惊叹的事情。现在有许多不同的生成模型正在尝试新的功能，一次又一次地超越我们所有最疯狂的期望。即使我们感到疲惫不堪，但这些技术还有很多潜力，也许会有一些新技术出现，让我们感到意外。我认为这个趋势会持续下去，不仅会继续涌现新技术，而且会加速更快地发展。无论我们是否愿意接受，就像平常的事情一样，我是个研究机器人的人，也可以说是专业领域的研究员，你可能还没有接触过一些机器学习领域。未来不久，这些领域将会有巨大的突破和发展，每周都会推出新功能。

现在不仅可以看到令人印象深刻的模型，而且新模型的开发速度明显加快。很多团队在合作中发布了许多新模型，这些模型不仅供大家使用，还可以作为构建更高级模型的基础。这种趋势主要体现在机器人领域，实际上是通过在线积累经验、尝试和错误学习，转变为离线利用这些经验数据。我们将数据的生成和消费过程分开处理，就像其他基于数据建模的领域一样。这些庞大的互联网规模数据集非常丰富多样，但也是静态的，我们只需多次抽取和整合它们。我们收集了从Luther到Lyon 5B的数据集，其中包括图像匹配、图像文本等内容。这些模型都异常庞大。

我们先前看到的那些规模要大得多，它们实际上是其他领域在成功培训这些大型基础模型方面的关键因素。这也牵涉到了机器人技术。让我们简单回顾一下这种转变是如何发生的，因为很容易就会局限在某个片段里。确实，机器人技术的离线训练比在线训练次数多，对于很多来自其他领域的人来说，这看起来是理所当然的。这种转变在机器人技术领域是一种取得成功的方式，也是一个非常显著的进步。对于很多人来说，机器人技术和强化学习（RL）几乎是同义词，但我认为这样的说法已经不太准确了。所以，我想通过幻灯片和交谈向您介绍一下我们团队的历史，带您简要回顾一下谷歌机器人技术发展的简史。当然，感谢您的参与。我认为这不仅是为了戏剧性的展示，也是为了让您了解多年来我们团队的思维方式发生了巨大变化，以及这将如何影响我们的设计决策。

我们团队在2016年进行了一个实验，布置了7台Kuka机器人在一个房间内，全天24小时采集采摘数据作为实施强化学习策略的一部分。我们是第一个在实际场景中尝试这种方法的团队。此外，我们还研究了实现端到端机器人学习的可能性，这在当时非常罕见。我们的方法有一定风险，并且我们也拓展了一些有趣的研究方向。其中包括对一种名为q-tops的连续动作控制的q学习方法进行研究，同时结合了基于CycleGAN的视觉输入研究，将模拟图像转换为真实世界的图像。此外，我们还进行了并发技术的研究，以提高机器人在现实世界中移动的速度和效率。您有什么问题吗？

手臂是指机器人捡取东西的动作。如果机器人抓取失败，东西会掉在地上，第二天早上发现屋里东西散落一地，就表示没进行重置。如果机器人只有轻微抓取失败，东西会重新回到垃圾箱，希望机器人能再次捡起。对于24/7的机械臂农场，我们不需要重置，因为我们设计了垃圾箱来存放被丢弃的物品，即使机器人抓取失败，物品也会被安全放置在垃圾箱内。在使用Q学习进行线下策略强化学习时，我们混合了模拟数据，然后再次部署机器人。在2020年左右，我们经历了这个整合阶段，感觉良好，希望摆脱困境，寻找更复杂的任务和更实用的设置，可能更贴近人类日常使用的通用物品。

您听说过谷歌的微型厨房吗？我们在办公室也建立了一个小型厨房环境。我认为这种配置非常适合我们的操作。我们在这里开始收集数据，并扩展了我们的实际操作。尝试了不同方法后，发现右下角的机械化重置版本效果很好。在讨论手臂农场时，我们使用了一个折叠式垃圾箱，用于多任务强化学习。垃圾箱翻转一半，将物体转移到另一侧，这样我们就能尝试更多有趣的任务。手臂程序现在可以拿取物品，比如“请把胡萝卜拿起来，把番茄放在盘子上”。当垃圾箱翻转后，我们可以重置一些其他的东西，就像在多任务学习中一样。我们还尝试将强化学习与模仿学习结合，但在2020年，我们意识到我们在研究太多不同的方向，希望巩固成果。我认为当时真正困扰我们的两个问题是，所有这些方法中只有50%到70%的稳定性。

在现实世界中，不同方法都有各自的限制和优势，需要遵循政策。我们希望找到一种能在实际任务中表现优秀、超过90分，并且能够扩展数据收集范围的策略。尽管我们的资源不像学术环境那样充足，但我们有一定数量的机器人操作员，受到物理规律的限制。所以，我们需要一种方法来获得更多数据。经过几个月的考虑，我们决定采用多任务模仿学习，这与之前24小时7天农场的方法有很大不同，代表了我们方法的重大进步。

我们已经发现，通过温柔关怀和爱，多任务模仿学习可以把得分提高到90。更多的演示可以进一步提高效果，尽管这些方法并不廉价，但通过额外改进可以取得更好的效果。示威是我们正在探寻的生命迹象之一，不到一年前，我们的团队决定将其作为我们未来发展的方向之一。也许你已经察觉到，我们可以考虑把我们当前的方法应用到未来的传播中。我们也许可以将这些想法扩展到其他领域，比如，如果我们现在把演示和数据收集与如何运用这些内容进行多任务学习分开，那么引入学习政策可能会是未来的发展方向。接着，我们可能会尝试一些类似离线强化学习的方法。虽然我觉得我们目前高水平运作得很好，只需要短短几分钟就能理解，但这背后凝聚着我们团队六年辛苦学习的宝贵经验。回顾我们今天所在的位置，即使是两年前，如果你告诉我我们可以通过这种方式扩展我们的策略，我可能难以置信。

虽然我可能怀疑你，但这个问题确实很有趣。我认为任务调节仍然是一个需要解决的问题。通过我们在BC0项目中的研究，我们发现语言在特定情境中至少有一定的表达能力。比如，摘葡萄，把葡萄放进盘子里，甚至是调节桌子上的黑色时钟，这些方式都是足够有效的。通过学习这些模式，你可以获得大量的技能。这些技能本质上是直接传递给你的。只需要将一个特定的ID添加到你的策略网络中，它就能学会仿效。这80个任务中的每一个都会收集数百或数千个示范，稍后我会详细介绍。

在2022年，我们需要采用离线方法来处理数据，将数据生成和数据消耗分开。我们要学习三门课程，第一门课程是机器学习扩展的设计原则，深入了解如何将这些课程应用于未来的机器人学习和基础模型中。这门课的重点包括高容量架构，比如注意力机制。第二门课讲数据互操作性，强调标记化和离散化的重要性。第二方面是模型本身的发展，在时间推移中变得更加优秀。我的同事提到的“投标人课程 2.0”强调了随着计算能力的提高，如何改善基础模型的方法。

当我们需要在多个不同方法中选择时，想要确定哪种方法最适合与基础模型结合使用是关键问题。在这种情况下，判断哪些方法符合标准并不总是容易的，有时候会很困难，有时候会有明确的信心。我认为一个明智的做法是审慎选择，因为在痛苦的教训1.0和痛苦的教训2.0中都强调了这一点。随着数据量增加和计算能力提高，一些模式可能会更加清晰。但总体来说，过于硬性编码和过多的假设会导致我们过度依赖于特定的基础模型和实现算法。因此，选择适合的方法可能比只是基于某些抽象的输入和输出进行操作更加复杂。

随着时间的推移，我们可以改进获取和输出信息的方法，以确保其稳定和可靠。甚至可能会改变算法本身。对视频课程2.0的看法可能因此而不同，因为新的方法和技术不断发展。我认为目前陪审团还没有最终决定。有一点我想强调的是，语言是我们用来分享经验和教训的重要工具。当我们将语言作为通用交流工具时，无论是通过字幕、生成还是其他方式，都能够帮助不同背景的人相互理解。在视频课程2.0中，这将是非常重要的。另外，离线机器学习的数据处理方式也在不断发展。通过将这些数据整合到一个通用架构中，并应用语言作为通用工具，可以创造出智能和现代的解决方案。很快，我将展示我们不同的项目，希望能够得到认可和支持。

对哲学启示的了解为我们提供了关于动机和潜在方法的初步认识。但现在我想知道目前的方法是否存在问题。我们已经建立了一些相关的基础工作，比如容量架构等概念，我知道架构与语言相关。我们也有关于组件的相关课程，但为什么这些还没有整合成一个解决方案呢？虽然我们已经有了许多组成部分，但为什么机器人技术领域还没有一个很好的解决方案呢？我认为目前这个领域可能比较混乱，不同人对此有不同看法。因此，我认为机器人技术领域需要进一步探讨。

各种技术组件在发展程度上存在着巨大的差异。我觉得我们可以先暂时不讨论这个问题，可以等一下再具体讨论，比如数据规模或者一些机器学习领域的技术在机器人领域的应用。我们目前所处的发展阶段可能差异很大，而有多少人已经真正接受了相关课程并做出了投资呢，这点我很感兴趣。我不要求你提供具体的名字，但可能有些人选择忽视这些事实。我可以进一步完善一些幻灯片，但这可能会陷入困境。这也是你认为其他人的选择是错误的原因。我可能会个人认同这种看法，但这不一定代表我整个团队的观点，团队中可能有许多人正处于学习如何将数据驱动应用发挥到极致的阶段，这是基于基础模型的。

往大处看吧，我觉得很多人缺乏这种信念。确实，等一下我们再谈为什么。或许在扩大规模之后，好吧，让我们深入探讨一下，看看这个食谱实际上如何应用在特定领域。首先，我们来看看最近我们小组的一个项目，旨在扩展模仿学习的应用。让我们看看如何将这些原则真正应用起来。所以首先要思考的是我们实际在做什么。设想一下我们置身于2020年春季的情境中，我们花了很长时间收集演示，数量庞大，比如超过十万个演示，花了一年半时间在多个机器人上完成各种任务的演示收集。这是非常昂贵的。随着时间的推移，你知道这些演示不会无限地像以前那样产生。每天获取新的高质量演示不仅困难，而且这样的趋势还在增长，但这并非没有代价。实现这种自主增长的方式非常困难，就像之前你看到的带有回收重置机制的MTOP或DeepMind那样。

RGB 堆叠公司正在尝试进行自主调整。目前，他们使用了BC零的远程操作方式，但这样做的成本很高且效率有限。另外，他们采用了基于resnet的骨干网，虽然性能很好，却对训练数据分布很敏感。当他们从一些电信运营商那里删除数据时，模型表现更佳，但这并不符合他们的期望。他们希望能获得更多数据，哪怕这些数据并非完全相同。因此，他们认为模型需要更稳健、更具有概括性。在寻找适合的模型时，他们发现其他领域的视觉变形金刚不适用于真正的机器人，因为需要高频率运行。最后，他们希望他们的数据集能够理解语言，因为语言是一种通用粘合剂。

在设计语言模型时，我们的首要原则之一是要涵盖尽可能多的模式。这就意味着我们可能需要重新设计或调整一些东西，而不仅仅依赖于现有的内容。我们需要从各个领域的最佳实践中获取经验，经过一段时间的努力工作后，我们为rt1再次提出了新的架构。团队规模较大，有许多不同的贡献者，我将在这里分享其中的一些内容。

rt1是一个机器人，名为Transformer，运行频率为3赫兹。它能接收来自其他机器人或RGB相机的视觉输入，并理解自然语言指令。当接收到图像后，会经过一系列处理，包括修补和tokenizer处理，然后输入到一个高效网络进行处理。同样，语言指令也会被分解成令牌，一起输入到Transformer中。最终，经过处理后的离散化动作会以3赫兹的速度发送回实际操作中。接下来，我将详细介绍这个处理过程。

这个 Transformer 是一种解码器，用来预测动作，采用稀疏分类熵作为目标。我们利用了预先训练好的高效神经网络作为主干结构，并结合了令牌学习器以加速推理过程。在输入图像时，将图像分成81个小块，每个小块代表空间中的一个区域，类似于正方形。令牌学习器的作用是根据图像的上下文动态选择与当前情况最相关的小块，以提高预测准确性。通过这种方法，我们可以从81个图像小块中筛选出与当前情境最相关的信息。

在处理图像时，我们通过对8幅图像进行子采样来进行推理。这样做是为了确保在每个时间步的推理中，每个图像中的补丁都是相关的，避免发送过多的令牌，避免上下文长度激增而无法进行有效推断。我们传递了一个由六个图像组成的单个序列长度，这样做是基于现实世界中的实际情况，历史数据对于了解物理规律以及机器人理解物体之间微妙关系至关重要。

我们的模型拥有3500万个参数，相较于其他模型，规模更小。一个重要的区别是我们在采取离散化动作之前对动作进行离散化，而不像其他产品一样采取连续控制方法。我们的机器人通过末端执行器来进行位置控制，因为现实世界是一个连续状态空间。因此，为了实现这一点，我们必须提出许多新方法。

在我们的算法中，有一个像CEM（交叉熵方法）这样的演员，主要负责对可能的连续动作进行采样，以找出Q函数评分最高的动作。我们尝试过一些类似的方法，但发现它们过于敏感了。我们需要找到一个更加稳妥可靠的方法。现在我们决定透露给你，我们只有256种离散动作，希望你能用这些信息来预测出所需数据或工程环境中有关速度和延迟应对的信息。我们认为使用一个相对小的模型是合理的。在设计这些模型时，平衡过去的数据和分析经验是至关重要的。换句话说，如果你需要大量参数才能建立一个强大的模型，但又想要输入的控制性高，那就成了一个重要的问题。我们设定了一个严格的推理时间为100毫秒，但过去的基础建模经验告诉我们不要给自己设限。

在处理大规模数据集和模型容量方面，我觉得你提出的观点非常中肯。虽然未来可能会遇到挑战，但就我们目前的情况而言，我认为我们更应该秉持这些原则，并超越我们目前所能看到的范围。我们能否在这3500万个数据上取得进展？相较于之前使用的一些工作，这已经是一个大的突破，例如resnet 34或类似的模型。因此，这个选择已经远超其他选择，至少在短期内，这是最简单的、也是我们能够实现的最大规模，无需考虑更多技巧。需要明确的是，我们或许可以在未来讨论这一点，我很想听听你的想法，因为我们如何克服这些挑战并不太明显。它们或许没有给你100个选项的医疗计算机，但其他条件也可能会以类似的方式限制你的平台，你认为你已经觉察到了一些重要的情况。

你说的很对，我们可以优化当前的模型结构或者探索一些新的方法，而不仅仅是尝试扩大规模。为了应对限制值的问题，我们对模型尺寸进行了一些缩减，我将在几张幻灯片中详细展示。或许我们应该回到之前讨论的点，看看是否还有其他可能性。是的，架构很关键，稍后将讨论一些消融和趋势，但考虑到这是一个关于机器学习的演讲，我应该给你展示一些漂亮的视觉效果。让我们来看看我们的一些评估结果吧，我们将其与一些基线模型进行了比较，其中包括加托和基于ResNet的BC归零基线。我们发现在评估场景任务中，我们能够应对未曾见过的任务，让Shacker对象感到困惑。我们最初的数据收集看起来像左上角的那张图片，上面有三个罐头，但之后我们通过引入更多对象进一步推动了研究。

桌子总是乱糟糟的，有时候找东西都费劲。我们改变了桌布的纹理，在微型厨房进行实验，发现 rt1 比其他方式更结实。问题是，我们是根据自己的数据重新训练了 Gato 模型，而不是使用原有数据。机器人在微型厨房内进行各种有趣的活动，呈现出不同的可视化效果。经过训练后，它在新环境和对新物体的表现出色。我们还将它置于较长的视野设置中，使用第二个框架进行实验。

接下来我们要谈的是这个框架。在这些设定中，很多人会把所有这些泛化功能混在一起。在左边的图中，我们采用了Vemma论文所启发的泛化水平，基本上是同时改变更多的变量。在这里，我们发现rt1是最稳健的。是的，这是一个很好的问题。稍后我们会更详细地探讨这个问题，但我认为在大型电信运营商那里可能会使用一个结构化的模板化命令，比如动词、名词、动词的形式，或者类似于挑选可乐罐或把苹果移动到海绵附近这样的命令。我们大约有700个这样的任务设置。他们将继续收集已完成的数据进行测试，然后确保成功意味着实际上的成功。对于存在问题的部分，我们会进行丢弃。哦，对了，这篇论文已经多次展示过，大约使用了130,000次。是的。

你的问题非常重要，之前的一些研究也指出了这一点。比如说，面对问题时，你是否发现数据集中的特征非常多样化？就像你说的，从A到B，可以有左转、右转、直行等多种路径选择。我理解这种多样性在单个图像阶段基本适用，但是我的数据有三种可能的标签，有时可能会产生很糟糕的影响。也许是因为我们正在使用的是一种控制数据，相比起真实场景中的数据更加同质化。例如，有一种叫做“玩耍数据”的数据函数，操作员可以随意操作，然后我们进行事后标记。我认为我们的数据比这还要同质，但我们之前的项目中似乎并没有太多问题。一个可能的答案可能是数据本身，但我们后续还可以深入讨论这个问题。你提出的问题非常重要，实际上，我们确实在探讨终止操作策略时，需要关注如何确定一个事件何时完成以及如何预测终止。在每次远程操作会话结束时，操作员都有可能点击按钮来标记这次操作的完成。我认为我们对这些评估相当严格，但有时在某些情况下，如果我们只是为了实验，可能会得到一个较高的奖励，比如抓住物体并将其靠近。即使最后失败了，我们也接近成功。基本上，我们会得到一个分级曲线，但对于所有数据统计来看，我看到结果要么是完全失败，要么是完全成功，没有中间状态。这让我感到很激动，我认为讨论多模态方面会很令人兴奋，我们会继续挑战极限，因为我们是TR，我们决定在非常多样化的数据分布上进行训练。

是的，我们展示了日常机器人移动控制器的数据，是从130个到1000个演示中获得的。但我们也想要在不同的数据分布下进行测试，可能涉及不同的动作分布、轨迹和视觉对象任务。为此，我们引入了另外两个数据源。一个是通过强化学习在sin模拟中收集的数据，与之前的数据来源完全不同。我们发现合并这两种不同数据很具有挑战性，因为强化学习的动作速度非常快，它是为了特定奖励函数和人类收集的远程操作数据进行优化的。通过结合识别学习和强化学习，我们发现这是一个挑战。

可以说，通过深入学习，我们更能够理解人类的生活。最近，我们也成功恢复了两年前的数据集，即2018年的数据。也许你还记得KUKA项目和ARM农场，它们已经运营多年了。

这些数据仍然很重要，我们希望研究在不同建筑物中，不同物体在不同机器人上的运动空间的视觉效果是否可以与之前用微型厨房数据集训练的数据结合。令人惊讶的是，rt1可以从这些非常不同的数据分布中学习。这样的结果让我很吃惊，其他架构例如resnet或者其他学习方法（如强化学习）在如此不同的数据分布上学习起来却不那么稳健。

我们对组合概念进行了评估，这样我们就可以让之前只在Kuka项目中看到的机器人拾取物体的技能，或者将模拟中看到的物体放在一起的技能，来测试我们的策略是否可以理解这个概念。这意味着我们的策略能够适用于其他数据集中出现的不同对象和概念，并将其应用到现实微型厨房环境中。这个结果非常有趣，也提出了一个很好的问题。

是的，我们只是对数据进行了标记，以确保标记方案具有互操作性。我认为这很关键，稍后我可以深入讨论这一点。不过，并不意味着我们可以将一个机器人的确切行为发送给另一个机器人来执行。更像是数据集中，我认为即使通过人工检查，也能看出它们来自两个不同的机器人。所以，让我们看看现在讨论的一些缩放定律的消融现象。我们发现减少数据量会降低性能，但更有趣的也许是任务多样性的重要性。我们看到了两个不同的趋势。绿线是当减少每个任务的情节总数时发生的情况，而灰色和紫色曲线是当减少任务总数时发生的情况。我们发现，拥有更多的任务比为每个任务提供更多数据更为重要。我认为这是一个重要的教训，可能会建议我们改变方法，认为我们应该进一步发展机器人技术不仅仅是在同样的环境中采集执行相同任务的更多数据，而是要勇敢走出去，获取更多样化的行为数据。问题在于，在这种情况下，如何定义数据的多样性呢？嗯，我觉得这些只是电信运营商接收到的一些固定模板化的指令，总共有700个这样的指令。然而，当你开始削减这些指令，只用其中的500个进行训练，或者只在其中300个上进行交易时，性能下降的速度比我们保持相同情况时更迅速。这种规模的削减我很熟悉，但是我不确定为什么会有这种性能下降。是的，我不认为问题在于数据量和成功率之间似乎存在线性相关性。我想，我们可以尝试应用一些特殊方法，比如缩放法则，以尝试找出解决方案。

我们正在努力适应当前情况，但事实上我们并没有深入研究过这个问题，因为我们只是知道这是一个我们所期待的趋势，但我们仍然不确定它会对我们产生多大影响。嗯，除了根据我们的经验观察到这种现象之外，我没有什么特别深刻的见解。是的，这是一个很好的问题。也许这种情况会持续下去，或者在2023年1月会出现一些奇妙的变化。我认为，当我们开始探讨算法如何影响现实世界时，这可能是一个需要考虑的因素。目前我们政策所涵盖的数据收集已经接近100％的情况了。因此，我们可能需要收集另一组数据，以确保我们基本上达到了100％的覆盖率，然后再考虑其他情况。

我们在这个 rt1 架构上做了很大的尝试，已经收集了相当长一段时间的数据，可能收集到的数据量已经超过了我们所需的。某些情况下，实际上可以缩减任务而不会影响太多性能，这很有意思。在不同任务之间，性能和信息熵方面是相似的，我们可以从中学到一些东西。没错，这是真的。有些任务相对容易得多，比如我们有一个任务是仅仅拿起一个物体，这个任务相对简单。你可以从中发现一些有意思的东西，而不仅仅是将物品移动到抽屉里然后关上它。这是一个很有意义的问题。现在，我们也在探索消融（渐进式放弃）。

我们成功地进行了训练，没有使用大规模模型，也没有预先训练的参数。我们的研究聚焦于连续动作而非离散动作，包含了诸多侵略性动作。在这个研究中，我们没有采用变压器模型，我认为这些设计选择似乎是为了保证模型性能的稳健性。这项研究是国外展开的，我想说的是，一次又一次，我们采用了试验后获得最佳结果的方法来写论文。然后我们会深入分析为什么每一个选择都是至关重要的。因此，令人惊讶的可能是自回归行为并不总是有益的。有些人可能认为传递更多信息总是比传递更少信息更好，但在某些情况下，调整先前行为可能更加符合上下文学习。这种方法可用于在线系统识别，从teleoc雷达数据中获取信息。

我认为删除适应特定动作历史这个问题更好。我考虑通过更快的方法来节省时间，做更少的事情，留出时间来解决问题。在未来的工作中，我计划调整技能学习的内容，更侧重于规划方面。我们第一个项目将其他领域的设计原则融合进去，在离线机器人学习中引入技能学习的概念，看起来很可行。我还记得我们在2022年思考如何扩展多任务模仿学习，并结合大型语言模型如Imogen和dolly 2来探索新的可能性。我们已经开始设计rtu 2-1，希望能发挥这些模型的优势。

我们已经投入了很大的努力。但实际上，在尝试在我们的全栈系统中应用测试版2.0课程时，我们遇到了一个问题：使用基于语言模型的方法并不完全适合机器人技术。举个例子，如果你是厨房里的机器人，当你问语言模型“我卖掉了我的饮料，你能做什么？”时，语言模型可能会给出一些建议，比如用吸尘器吸尘、打电话给清洁工或道歉，这些建议与你在厨房中处理像溢漏排水管这样的问题并不相关。所以，问题的关键在于有两个方面：第一，我们的机器人受到限制，不能做所有的事情，但可以做一些事情；第二，语言模型也有局限性，不清楚机器人看到了什么，也不了解微型机器人在厨房中需要执行的任务。因此，我们需要让机器人根据语言模型的指令行动，并让语言模型理解机器人所观察到的情况。

为了让机器人学会说人类语言，我们在事先设定的任务上给机器人做一些要求，比如“请把桌子上的苹果拿过来”。机器人会根据语言模型对这些要求进行评估。我们通过值函数等工具来评估机器人任务完成的质量，以此来估计机器人在特定状态下成功完成任务的信心程度。举个例子，我们让机器人找桌子上的苹果，要求机器人把一个苹果放在桌子上。尽管框架里没有提到机器人，但是机器人知道它已经接受过找苹果的训练，因此能够四处搜索找到苹果。我们希望机器人能够顺利完成这个任务，并在不断根据语言模型预测高级计划的闭环环境中持续进展。

我们有一个视频展示机器人在不同任务中的表现，很快我就可以分享给你。另外，离线功能也很厉害，这是我们分享数字以来最出色的新功能之一。我们在Horizo​​n项目上进行了一系列测试，展示了机器人在微型厨房中展示的十多种独立导航和操作技能。我们进行了数百次不同的评估，测试了很多概念，比如通过绘制朋友和同事的方向来指引。我们对结果进行了重新构建，发现了一些问题，虽然在语言模型规划方面有时会出现错误的路径预测，以及在执行策略方面，即使计划良好，机器人有时也会出现问题。总体来说，他们表现得不错。

让我们来看一个很好的例子，展示我们如何利用互联网规模的基础模型。在启动项目时，我们使用了来自Google的名为flan的模型，并集成了由Palm开发的Pathways语言模型。当我们需要调整语言模型时，我们可以轻松进行更改，提升性能，而不必担心API计划中字符串的来源。虽然语言可以来自各种来源，包括人类和语言模型，但经过我们的系统优化后，表现更加出色。通过扩大模型规模，我们提高了性能，同时学到了一些使系统更加高效运行的技巧。这些改进不仅使机器翻译计划变得更好，还为我们提供了新的机会。

在实际应用中，我们可以看到机器人能够执行各种任务，比如理解不同语言以及进行复杂推理。比如，让它拿含咖啡因的饮料，或者让它提供更健康的选择，比如健康零食而不是不健康的零食。我认为这是我们团队中机器人和语言模型首次接触，我们正在探索这两者之间如何相互影响。虽然在某些方面表现出色，但我们还有很多改进的空间。目前，语言模型虽然在计划上表现出色，但在实时事件信息处理方面仍有欠缺。比如，如果让它拿可乐，但你把它弄翻了，它会继续尝试给你拿，而不会意识到出了问题。我们正在尝试引入视觉语言模型来进一步提高性能。

抱歉，我给你提供翻译的信息比较乱，难以理解。请你提供更多上下文或者简化一点，然后再重新提交给我，我会尽力帮你翻译成中文。

语言模型可以像视觉问答一样，通过活动场景提出问题。在这个过程中，语言模型需要足够的上下文信息才能继续进行。人类可以提供答案，或者在将来的改进中，视觉问答模型也可以提供答案。为了让语言模型知道何时需要回顾之前的内容，成功检测规划者对于语言模型至关重要。

我们通过微调改进检测系统，然后在第一和最后一张图片中展示成功或失败的信息，这样有助于语言模型的理解。在第二次评估中，我们看到了类似的结果。令人感兴趣的是，我们成功地在机器人上建立了多种自动反馈机制，这使得机器人可以进行推理和恢复事件，并具备从现有情境中学习的能力。

当人们站在桌子旁时，他们可能会改变主意，然后寻求机器人的帮助解决问题。机器人可能提醒我们说：尽管语言模型可能会遇到困难，但语言可以重新组织以确保满足人类意图。我曾经试图让机器人进行挑战，比如让它试图夺取我手中的物体，然后告诉机器人：“嘿，你失败了，再试一次”。我们在模拟桌面操作和真实环境中尝试了不同的方法，发现这比仅仅依靠视觉功能和剪贴板更有效。这展示了一种新的可能性。

在2018年，一位机器人学教授指出，目前阻碍机器人学习大幅扩展的主要障碍在于高水平的常识推理语义规划。我认为在2022年和2023年，语言模型可以提供一个解决途径，在过渡期内至少可以部分缓解这个问题。如果将语言模型作为API引入，引入视觉语言模型可能是一个不错的主意，因为物体检测技术越来越先进，成功率也会相应提高，就像在eqa（自然语言问题回答）中所表现的那样。随着这些模型的不断完善，我们也可以逐步引入它们。如果你的机器人在常识推理方面存在欠缺，ACT（常识推理测试）将是一个很好的辅助工具。其他模型可以充当现实生活中的支撑，让你迅速接近它们当前的水平。也许在未来，我们会超越语言模型现有的范围，但就目前而言，似乎可以利用它们来加速我们在真实世界中的工作。观察语言模型如何进行语义规划，我们也看到了视觉语言模型如何支持这一规划。此刻，我们需要换个角度思考视觉问题。

语言模型在克服机器人学习难题方面起到了重要作用。数据收集一直是个大问题，成本很高。例如，之前提到的一个拥有13万个演示数据集的案例，投入了大量资源、时间和金钱，而且仅仅是有限的任务。我们使用了700个非常标准化的指令，向电信运营商提供这些指令。这样做的理由是，只要为每个标准化任务收集足够的数据，就能完成特定任务。这种方法之前也有很多人提出过。我们提供指令，操作员通过控制真实世界中的机器人完成任务标记步骤，然后将结果存储在一个大型数据集中，这个数据集是我们用来训练控制策略的。最初，我们考虑增加一些众包的智慧。

在强化学习中，机器人可能会执行一些比较复杂的任务，不仅仅是简单的指令。如果我们想要更详细地描述机器人的行为，比如说它是否拿起了桌子旁边的可口可乐，或者它是如何拿起的，它移动到中间的速度如何，这种语义上的多样性可能超出了高级模板指令的范围。因此，我们只标记了总数据的3%来提供更详细的描述。

接下来我们采用了一种类似于视频预训练的伪标签策略，而不是将其应用于指令语义。具体做法是，首先在包含了主要数据集3%的小型标签数据的集合上对模型进行预训练，然后再进行继续训练。

我们现在有一个经过重新标记的数据集，里面包含很多有趣的语义指令，共涉及130,000个剧集数据。我们将把所有这些数据都导入名为rt1的系统中进行训练，以实现语言条件行为克隆策略。通常情况下我们只使用数据集B，即橙色的数据集，但现在我们会将所有三个数据集都用上。最后，我们将评估全新的不可见指令的效果。

过去我们只对700个固定模板进行评估，但现在我们可以接受几乎任何输入，只要你认为有可能成功。你可以自由地表达，甚至可以通过引用语义概念来实现。可以添加空间概念。让我们看看结果如何。也许可以通过视觉手段来解释为什么这样做可能有效，就像迪士尼一样。

左侧和右侧内容其实是一样的，只是左侧使用了原始模板指令来收集数据，右侧则采用了视觉语言模型的概念。如果我们为每个数据集添加自由形式的标题，你会发现左侧有很多类别，就像我们平时所说的成百上千种类别一样，但右侧的数据集标题简单明了，比如简单描述为“在右侧选择可乐罐”。此外，我们还可以扩展这个概念，例如指明某个数据集正在收集红色可乐罐，另一个正在搜集绿色可乐罐，或者关注可乐罐旁边的薯片包装等内容。通过利用语言的多样性作为机制，我们能够从同一组原始数据集中获取更多信息。利用这种方法，我们可以延伸我们的思考，比如在数据集中心采集打开顶层抽屉、拿出抽屉并拉开的情形，或者选择底部选项中的一个，取出绿色薯片，并将碗放在袋子里。

你能在桌子左下角发现很多语义吗？这说明你对空间概念有了理解，现在这些概念包含在你的目标监督标签中了。我有一个问题，确实是一个很不错的问题。如果我能稍微改一下，问题实际上会更加吸引人，那就是如何将你在户外看到的所有空间概念映射到具体类型的情境，就像这里一样。也许我想讨论的是，我们使用了很多标签和偏见，比如说“左边”，而你说的可能是“左边10厘米”或“左边2厘米”。就像词的含义是什么，这些定义对我们又意味着什么。

我们在研究标题时发现，对于机器人和语言模型有些微妙的差别。希望它们大致相似，这样我们才能找到正确的改进方向。我觉得理解这些词的含义是很重要的，虽然可能有些超前，但或许在更高级的阶段我们可以深入探讨。现在我们有700个模板指令，基本上是模仿热门 ID，我们希望让它们更自然些，尽管只是一点点。我们至少正在朝这个目标努力。我们正在尝试用生成的视觉语言模型来回答您的问题。此外，我们还计划比较一些低音线与左上角的对比结果，看看如果只训练其中三分之一的内容会有什么不同。对于特殊的人类评级标签，我们想了解在原始 rt1 数据集上训练和在两个数据集上同时训练的区别。

如果我们将BLM提供的所有预测都加入到这两个数据集中进行训练，会有什么结果呢？有趣的是，似乎知道真实标签是有帮助的。我们只评估了这个项目的新指令，这是机器人项目中的首次尝试。我们尝试输入我们认为可能的任何内容，然后它就变成了测试集。我们只需要确保这些内容之前从未包含在训练数据中。你会看到很多有趣的例子，比如将一个孤立的物体移动到另一个物体身边。我不太清楚这是如何实现的，但就像你知道的那样，就像抬起一个黄色的长方形，提到颜色，或者说把右边的苹果移动到左边。在场景中我们实际上有两个苹果，但在我们的训练演示数据中从未出现过具有重复对象的场景。这引出了多模态问题。如果你只说“拿可乐罐”，然后场景中有两个可乐罐，那么要确定拿哪一个就会很困难。但是有了语言标签，现在似乎您可以做到这一点。即使我们以前从未训练过这种场景，现在有两个苹果，您也可以对它们进行评估，只需用简单的话来说我要做的。对于最后一个例子，我们尝试了一种新颖的操作方式，不是按照传统方式操作，而是尝试用一种不同的方式。其中，我们只是在接近苹果时移动了一块含有可卡因的海绵。这种操作本质上并不是我们期望的结果。也许通过另一个例子来解释这个概念会更好，比如你看到左边有一个苹果旁边有一个光滑的可乐罐，或者看到蓝色可乐罐旁边有一块海绵。在这种情况下，左边并不是指一个特定的物体，而可能是指这一侧的空间。我希望未来可以更深入地探讨这个现象。最后一个例子我认为值得与非视觉增强进行比较。也许从我所说的语言中你可以得到一些有趣的概念。

我们尝试了一些不同的方法，比如加入随机噪音，使用不同风格的词汇，甚至考虑了使用LOM GPT-3来修改指令。但我认为最关键的是理解视觉语言模型的基础，这样才能更好地应用它。在某些情况下，这个标题确实是准确的。或许对于机器人来说，微调过程会很有趣，因为微调可能会导致两个孩子都受益。需要强调的是，我们只是评估了一小部分指令，实际上我们有超过60个评估指令尚未涉及。我们还没有进行完整的量化消融测试，就像我们在rt1中所做的那样，我们在隐形任务中观察到了这种情况，这是一个综合案例。举个例子，假设任务是要把可乐放到苹果旁边，你可能看到了将苹果移动到海绵中的情况，但我们坚持要将可乐移到旋转的物体旁边。我们将对此进行深入测试。

我们有无限的语言组合空间，可以回答各种问题，但仍需深入了解。我们要利用基础模型作为数据文档，并确保离线数据集足够强大以适应各种行为。即使标签质量好，若无法提取所有有趣概念，学习也可能受限。最令人兴奋的是，在监督学习和模仿学习中，标签噪声是可接受的。保持准确和干净的标签很重要，而避免学习含有大量不准确标签的噪声数据更为关键。

关于标签噪声的问题，我认为在某种程度上是可以接受的。视觉语言模型并不总是能够准确预测场景的描述。当噪声过高时会对结果产生影响，但在小范围内，仍然可以应对问题。这需要深入研究。一些个人作品采用了大型语言模型，基础模型在机器人系统的不同部分有离线数据集支持。这是最初的推动方法。我们尝试应用这些原则来加速机器人在现实世界中的学习。不同类型的组成和课程完全映射到机器人系统的不同部分以学习技能，这是我们讨论的主题。一个例子是使用 rt1 用于规划，在逗留时可以添加视觉语言模型的反馈，这是低级控制的内部对话。虽然今天没有具体讨论这一方面，但我们的团队正在进行一项令人兴奋的工作，实际上是在利用语言进行。

现在我们可以用模型来预测机器人执行代码的情况。比如，这个模型可以作为一个低级控制器，更好地使用增强数据，还可以让机器人用视觉语言模型来拨号。我们可以利用对象为中心的表征方式，通过特定对象的特征来激活数学任务表示，来更好地对场景进行映射。这种以对象为导向的导航方式，比如在微型厨房中展开。未来几周和几个月，我们将进一步发展这些理念。虽然当前的机器人系统已经有了很多基础模型和离线数据集，但仍然存在一些差距和机遇。通过探索性试点研究，我们可以应用这些高级概念，来发现机器人系统中的差距和机遇。在这个激动人心的研究领域中，我们可以尝试各种方法。

我觉得值得在更广泛的评估和真正构建强大系统方面花费精力。探索这些互补的方向非常有趣，但我们仍然面临一些重要问题，例如如何进一步发展这些概念，以及这些趋势和想法如何未来发展。随着基础模型的不断改进和更多数据集的可用，数据变得越来越同质化、标记化和可互操作。我认为许多概念源自其他领域，比如语言学和视觉。希望这些想法可以融入机器人技术中，甚至机器人技术也可以通过提供具体的动作因果数据集来取得一些进展。这些数据集可能会提高某些大型语言推理的质量，在目前的模型中还没有得到充分展现。感谢大家的时间，也感谢戴维森在解答有关论文问题时给予的帮助。

感谢你提出这些很好的问题。关于需要更多语义推理任务的问题，比如在某一速度下进行推理，或者我不知道泵本身数字推理的问题，我觉得目前很多常识推理任务，比如扔掉三个可乐罐之类的任务，在语言模型方面已经做得非常出色。对于第二个问题，模型可以预测不同的可乐罐被扔掉的时间。至于低水平技能政策学习，虽然可能会有更高的方差，但目前我们在这方面已经取得了很好的进展。

我并不是很在意速度，但我对你的方法很感兴趣。 如果你用一种比较温和的方式来讲解，比如说“慢慢拿可乐”而不是“快速拿可乐”，可能更容易理解视觉模型的代码。 这是一个很有意思的问题。我们在探讨的是在综合概念中规模有多大，可能是你看到颜色从一种过渡到另一种，然后尝试评估一种新的颜色。 我觉得这是一个很有意思的研究课题。 不过，遗憾的是我的回答可能会有点含糊，因为这取决于你如何定义任务，取决于你的数据集规模，取决于你的研究目标。

在学习和机器人技术领域，已经有很多尝试对概念进行系统化和分类。然而，具体情境下却并没有明显的趋势。举个例子，评估时可能需要用数字来总结某个概念，但这并不一定能帮助我们预测新的发展趋势。在我们谈论广义概念之前，需要说明的是，当数据集规模增加数倍时，我们可以开始探讨更高层次的技能任务。

观察到一个问题，即虽然我们对数值函数进行了预测，但系统只能存储有限数量的任务，这导致系统能够执行的任务数量受限。 我提议扩大系统可以执行的任务数量，使其能够处理多达100个任务，并将其作为规划器的自主选择选项。即使规划器很出色，如果局限于这种情况，也是一个瓶颈。只有这三个任务的某些组合能够映射到高级指令，但随着机器人低层技能的提升，可以添加更多任务。 这样能够提高机器人尝试执行高级指令时的准确性范围。这是我今天发现的一个主要瓶颈，谢谢。

很高兴你提出这个问题。我们尝试过使用 rohf 或 RL 来进行 rt1 吗？目前短期内，我们在实践中尝试了一些方法。目前，我们只是在重新运用这种实践来学习。我认为我们正在探索的多任务变异赌注方法是有效的。虽然成本较高，但它的确行之有效，也具备规模效应。这至少是一个不错的起点。在未来几个月甚至几年中，我们的主要希望是能够超越这个起点，我们是否能够添加离线改进呢？是否能以某种方式将我们的经验添加到其中呢？我的本质是一个喜欢尝试新方法的人，所以我真的对此很期待。是的，我们会继续努力不懈。

我认为你在讨论任务平衡和纯文本数据对于类似运动控制学习的帮助时为什么是重要的。我的理解是，一旦我们熟悉了模型，在涉及到机器人动作和语言理解领域时，这些推理概念可能会在两个领域之间产生交叉应用。我建议你向他们推荐一篇有趣的论文，我认为维基百科对于加深理解可能会有帮助。这篇论文是由Shane和其他人合著的，他们先用大型策略网络进行预训练，类似于使用自动激进标记预测维基百科文本来初始化雅达利游戏的控制，这实际上非常有帮助。也许在文本数据和动作数据之间有一些关于决策推理的内容可以进行交流。所以，我想提出一个相关的问题。

我同意你的看法。比如说，如果我们要完成清理整个房子这样需要几分钟的任务，光传递六张图片显然不够啊。我们最多只能传递最后一张图片，相当于只看到最后两秒钟的情况。

面对任务变得越来越复杂的挑战，一个悬而未决的问题是上下文长度的限制。尽管我们尝试使用令牌学习来减少处理高维图像时的困难，但仍然面临高维度挑战。我们即将触及上下文长度的极限，需要想出方法进行改进。也许我们可以探索类似检索变形金刚或其他机制学习的方法来解决这一问题。

我觉得这个问题很重要，希望以后我们可以深入讨论。但是由于字数限制，我们已经接近字数上限了。仅用六张图片就已经很难，更不要说要表达整个镜头行为的轨迹了。我们希望看到更多的改进。

“2bd”这个点子确实很赞，谢谢你分享！