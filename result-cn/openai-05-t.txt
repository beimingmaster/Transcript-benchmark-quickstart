[音乐][鼓掌]酷！大家好！我是Barret，领导培训后研究团队，我们与API和ChatGPT密切合作。我是乔安妮，负责模型行为产品。

今天，我们想谈一下OpenAI的研究和产品合作。这种合作关系非常独特，在许多公司中都不常见，但它确实帮助我们为全球用户和开发人员带来前沿的研究成果。今天，我们想向您展示一些这种合作关系背后的例子。我们首先要谈到的是2022年10月的一个例子。那时，研究团队和产品团队确实想要为这些模型提供一个对话界面。

然而，我们当时并不确定如何最好地实现这一目标。事实上，我们就这个问题展开了很多讨论。具体来说，我们犹豫不决的是，是应该发布一些非常具体的编码或应用程序，还是发布一些更通用的东西，比如一个可以在其中写入任何内容的通用文本框？另一个重要的问题是，大多数员工内部使用 GPT-4，但我们想要发布一个对话型模型，我们决定使用GPT-3.5发布，因为我们还没有准备好使用GPT-4。存在很多来回的讨论，有些人甚至不太喜欢这个决定，因为GPT-3.5并不是我们最先进的模型。另一个重要考虑因素是，当时聊天机器人并不是主流，这在现在看来很难想象。这也增加了很多不确定性。

最终，我们选择了更通用的版本，并将其作为低调的研究预览版发布。实际上，这个决定非常受欢迎。通用性最终带来了巨大的成功，现在已经围绕它涌现出许多令人惊叹的产品和公司。首先，让我谈谈OpenAI的情况。

培训后的研究团队实际上负责使用大型的预训练语言模型，并在其进入ChatGPT和API的用户手中之前对其进行调整。他们的主要职责之一是为模型添加新功能，使其在实际世界中发挥最大作用。这包括教导模型浏览互联网，并在其回复中添加引用等功能。团队还分析用户可能上传或询问的大型文件，训练模型以读取、写入或执行代码，从而生成用于数据分析的惊艳图表。此外，团队还训练这些模型能够调用其他模型，如Dolly，以便提供令人惊叹的提示并轻松生成漂亮的图像。他们还教导这些模型如何表现，尽管这可能看起来有点不直观，但这些模型能以数百万种方式做出回应，哪怕你只是问一句“嘿，怎么了？”。

我们工作的一个重要部分是塑造模型如何应对各种不同类型的情况。 另一个重要任务是教导模型遵循您的指示。也就是说，为什么模型不会默认遵循您的指示呢？根据他们的训练方式，这需要一些工作。 当您向模型提供包含三个要点的内容时，我们会额外努力确保模型真正按照您的意图进行响应。 团队在培训后的研究涵盖了从尝试在ChatGPT中发布下一个功能到寻求实现下一个重大研究突破的各个方面。 这涵盖了从一天、一周、一年，甚至可能永远无法实现的时间范围，这在研究领域经常发生。在加入OpenAI之前，我是一名研究人员，从事各种不同主题的研究，从计算机视觉到机器翻译。 在我进行研究时，趋势更多地是为各个领域训练更小、更专业的模型。 我们可以在幻灯片上看到两个这样的例子。 第一个例子是图像分类，您可能会训练一个只专注于一个特定目标的模型。

我现在的主要任务是接收图像并对其进行分类。另一个常见任务是训练一个特定模型，使其能够接收一种语言的句子，并输出另一种语言的句子。目前，这项技术正在不同的方向发展，我们正在训练越来越大的模型，这些模型可以处理越来越多的任务。模型的通用性是其重要优势之一。举例来说，ChatGPT接口展示了这种通用性。该接口非常通用，只有一个文本框和一个上传图像的地方，这表明模型的多功能性。模型首先需要理解图像，然后理解用户输入的文本，最后将这些知识结合起来生成高质量的示例和响应。这是通用性的重要例子，展示了如何解锁许多以前很难实现的强大用例。

另一个重要趋势是，随着智能系统的进一步智能化，界面变得更加简单直观。例如，现在我们可以通过语音与手机进行交谈，向它提问并获得回复。在表面上，这看起来是一个简单的界面，但其背后的模型却进行了复杂的运算，让这种交互成为可能。这种普适性和性能使得这种简洁的界面变得极为流行，以至于围绕这些技术出现了大量令人惊叹的产品和公司。

随着这种技术变得越来越普及，也催生了许多创新的使用场景。更重要的是，现在连我父母都能理解我的工作了。比如，我爸爸可以通过消息让我思考他对我们在公共 Slack 频道上发布的产品中的最新研究进展的看法。这种智能化的交互方式使得信息的传递更为便捷和直观。

接下来，让我们简单探讨一下OpenAI的一些产品和研究合作。这些产品确实对研究有所帮助，促进了技术的发展。

确保我们精心设计的模型能够最有效地满足现实世界的用户和开发人员的需求。研究在产品中带来了许多好处，通过它，我们可以深刻了解人们在现实世界中如何使用这些模型，以及他们可能遇到的问题。以ChatGPT的UI UX为例，虽然这些按钮可能让人感觉有点晦涩难懂，但实际上，研究从中获得了许多有价值的信息。通过观察用户对按钮的响应，我们可以调整我们的工作，更好地了解哪些部分做得好，哪些做得不好，以及在哪些方面需要额外投入时间。

另一个展示产品UI UX功能优势的真实例子是比较功能。通过观察用户对两种不同响应的偏好，我们能够逐渐改进模型的响应，使其更符合用户需求，并逐渐提升表现。在研究中，我们非常感激那些花时间提供高质量反馈的人，因此要感谢那些真心花时间点击按钮并留下有益反馈的人。我希望继续深入研究，更全面地理解用户和开发人员的实际需求，以确保我们的模型设计能够有效满足他们的期望。

谈谈为何从产品中获取大量有价值信号是非常重要的研究方向。在研究中，我们通常使用离线评估指标和基准来衡量模型的改进和进展。然而，有时这些模型在实际使用方面与人们在现实世界中应用它们的方式存在差距，尤其考虑到这些模型可能有许多用例。确保我们构建的系统非常通用和强大有助于了解如何构建真正符合用户现实需求的模型。这就是OpenAI产品的发挥作用之所在，Joanne将介绍更多相关内容。

感谢您，巴雷特。我两年前加入OpenAI时，这个组织主要是一个研究实验室。唯一的产品是GPT-3的API和其等待列表。然而，出于对研究的关注，当我获得机会参与OpenAI产品塑造时，我感到很感兴趣。在过去两年里，我与研究人员合作，致力于将产品从概念阶段转变为实际可用的工具，不仅是在纸上有效，还要能直接帮助用户解决现实问题。

在将新功能转化为产品时，包括GPQ-4和DALL-E、文本到语音、嵌入和ChatGPT API。 在这个过程中，我逐渐意识到在所有这些情况下，模型本身就是产品。目前，我专注于与Barret团队合作设计模型的行为。在准确地告诉您这意味着什么之前（因为这听起来可能是捏造的），我将首先分享更多关于OpenAI产品管理背景的知识。它有三个相对独特的方面，可以为您提供更多背景信息。第一，我们的目标不是传统产品指标如收入、参与度或增长等。我们的目标是造福全人类的通用人工智能。这是令人兴奋的，但作为一个顶级目标也相当模糊。这确实影响了我们对计划、优先级和战略等问题的思考方式，我们的讨论可能会变得非常哲学化，例如，如果我们有一个新模型，但在某些学科或领域（比如物理学）性能表现较差，定义成功以及在此过程中定义什么样的里程碑可能变得复杂。

在生物学方面表现较好，意味着什么呢？我们如何确定优先顺序呢？其次，我们从技术入手。这可能会引起很多观众的共鸣。在标准产品开发中，您要从用户问题开始考虑。从解决方案出发，寻找这个解决方案能够解决的问题并不总是奏效。很多时候，我们发现自己的能力并不完全符合我们思考事物的现有范式，因此我们必须真正质疑为何某些问题首先存在的假设。我认为OpenAI的产品经理在设计这些功能如何走向世界时扮演一个独特的角色。我们必须设计如何以灵活的方式向世界展示研究成果，充分发挥用例的广度和深度潜力，同时需要在社会影响和安全风险之间取得平衡。举例来说，在Dolly的案例中，我们一开始就具备了将图像输入到现实中的能力。

考虑到其创新性，我们的首要任务实际上是以最便捷的方式将其交到创作者手中。我们通过推出了我们的首个消费产品 Labs 来实现这一目标。通过实验室，我们获得了很多宝贵的经验，这些经验都得以应用于安全研究和算法研究，最终带来了更为强大和灵活的 API 产品。其次，研究和产品在行业内的相互影响可能会达到前所未有的程度。许多机器学习产品经理的角色，包括我以前在其他公司担任的角色，以前看起来就像是研究者研究模型，然后产品交付，但 OpenAI 的工作方式却不同。接下来，我们将通过巴雷特来分享两个有关这方面的故事。

第一个例子是关于对话界面。研究人员认为对话界面将成为未来人们与语言模型互动的重要方式。从直觉上看，对话的确很有意义，因为这是我们与他人交流的方式。

这就是我们与导师或老师一样交流的方式，我们通过对话中大声思考来展开头脑风暴。我们发现之前我们所做的一次完成和一次回复并不是一个完整的故事，我们还可以做许多事情。首先，我想回顾一下我们是如何拥有对话界面或者说我们的模型拥有不同界面的历史。首先是从 GPT-3 开始的。最开始，GPT-3 是一个模型，它经过训练只是用来预测互联网上下一个单词。当你与它互动时，它通常不能真正理解你的回应。比如你问它一个问题，比如给我五个创业想法，它通常会回答与您的问题无关的内容，这不太好。这是因为该模型实际上是经过训练预测下一个单词，而非特意训练来与用户保持一致。接着，我们有了 InstructGPT，这是一个非常重大的突破。通过这一项技术，我们实际上是在训练模型，使其真正符合用户的需求。在这里，你可以问它，给我五个启动创意，模型会真正执行并给用户一个很好的反馈。就这些模型的实用性而言，

这一变化是巨大的进步。然而，这个界面实际上只是开发了针对单次回应的优化。当你想要它提出后续问题来澄清某些问题，或者纠正模型时，它并不总是按照你的意愿行动，有时甚至会偏离主题。研究团队认为在这方面还有很大的潜力，这引发了我们对对话界面的思考。通过ChatGPT，现在我们实际上直接在多轮对话中训练模型，这是一个重大的进步，并且具有许多出色的特性。首先，对话是有状态的，它可以记住前面的对话内容和回合。这种交互方式非常自然，如果每次与模型交互都需要重复输入相同的内容，通常会令人不快。对话另一个重要的特性是，教导模型做我们希望它做的事情非常直观。通常情况下，当我们试图训练模型一种新的行为时，我们会请人类收集一些数据，来教导非常具体的事情。鉴于人类经常通过对话来教授知识，我们发现这使得数据收集变得非常直观。

在许多情况下，问题的解决显而易见，但在其他方面却并非如此——这就凸显了设计模式行为的重要性。从产品的角度来看，我们非常关注“显而易见”这个词。举个简单的例子：问别人“你好吗？”这本应是一种社交问候，如果对方告诉你他们的行为与人类不同且功能正常，那就无趣了。这就引出了一个问题：谁说的？如果你问别人“最酷的东西是什么”，却被告知“酷”是一个短暂的主观概念，而且世界上有无数种东西，因此无法回答，这也并不有趣。对于那些花费代币的开发人员，我们表示歉意。或许更好的方式是，如果他们追问“在哪方面酷？”然后便拒绝回答。我们与政策和安全专家合作确定拒绝的边界，然后与研究人员一同实施这些边界，但即便如此，这也并非完美，也并非微不足道。在这种情况下，个人实际上认为……

在这种情况下，模型决不能拒绝。这个例子源于一则推文，提到了实习生时撞上与 CSRF 相关的问题。如果模型用这种方式与我说话，我可能会哭。对于引导每个人进入人工智能领域而不让他们感到烦躁，构建和表达这些响应对模型至关重要。我们需要这种直觉。然而，如何解决这个问题呢？我们不能只是简单地说“请说我很好，很正常”，也许应该一步一步地进行？实际事实证明，改变行为并不容易。其中一个最大的挑战就是首先明确并阐明我们希望默认模型表现出的行为。例如，当用户查询“你现在是一只猫”，即使在这个早期阶段，您希望 ChatGPT 变成什么样子呢？我们通过研究，尝试了各种干预措施来调整 ChatGPT 的性格，既不影响其实用性，也不过分花哨。这一系列答案是我们从一次实验中得出的。问题在于，用户想要什么是相当主观的。

适合大多数人的默认行为并不适用于所有人。比如，我个人喜欢猫咪，差点就迷失在那里了。通常来说，最疯狂的反应是可能的，但我们不会将其视作默认行为。虽然我们有一些观点，但显然我的想法不应被默认采用。虽然我们在讨论默认值时有争论，但我们相信最佳的模型应该是能够为您个性化的模型，以便为您提供您所需的答案。我们需要一个可以适应您的反馈并理解您需求的模型。这些只是研究和产品如何结合在一起的两个例子。让我告诉您一些我们期望这个领域未来模型发展方向的例子。正如我刚刚提到的，为了确保我们的模型对每个人都有帮助，它们需要进行个性化定制。第一步是自定义指令，这些指令可以是今天公告中的指令，是用户友好的系统消息。用户告诉我们，他们希望能够为不同的用例使用不同的配置文件。

我们希望今天发布的 GPT 能够为您提供一种直观方式来完成类似任务。尽管我们清楚它并不能解决所有问题，但我们正积极思考如何优化这一模型以更好地服务您的具体用例。我们也期待着我们的模型变得更具多模态性，我们说的多模态，我刚刚意识到这实际上并不是我想表达的意思。在现实世界中，存在声音和图像，以及文本、声音、图像等的结合形式。我们需要让我们的模型跨越文本界面，能够满足人们处理和创造知识的需求。随着时间推移，我们期望这些模型能够为您执行越来越智能的任务。起初，我们的模型擅长于文字创作，但在其他方面仍有不足，现在我们正在扩展其能力，使其能够在其他领域提供更多的帮助。我们希望未来这些模型能够更加有助于解决一些最具挑战性的任务，无论是数学、研究还是科学发现。

非常高兴您今天与我们一起加入。希望您享受了解OpenAI研究和产品合作背后的一些内部工作。我们意识到这是一种独特的关系，但随着越来越多的人工智能公司的兴起，我们相信这种关系将变得更加普遍。请观看演示，感谢您的加入。 -谢谢。 [背景音乐]