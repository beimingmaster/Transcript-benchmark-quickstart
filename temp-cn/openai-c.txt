大家好！希望大家喜欢今天的主题演讲。我很高兴能在OpenAI首届开发者大会上与大家共度美好时光。在本次分组讨论中，我们将探讨如何利用各种技术提升大语言模型的性能，以解决您最关心的问题。让我来介绍一下自己，我是约翰·阿拉德，OpenAI微调产品团队的工程主管。最近几个月，对OpenAI的微调工作让人兴奋不已。在八月份推出的3.5 Turbo微调受到了开发者社区的热烈反响，我们感到非常震惊。随后，我们又加入了一些重要功能，关于对函数调用数据进行微调。通过持续微调，您可以拿现成的微调模型进行持续优化。我们还推出了一个用户界面，方便在平台内进行微调。在过去几个月里，我们与各行各业的开发人员密切合作，包括独立开发者和初创公司的开发者，以及来自世界各大企业的开发者。我们已经看到他们尝试解决的问题，以及他们如何利用大语言模型来解决这些问题，尤其是他们如何利用大语言模型的微调功能。希望能在今天的分享中和大家一起探讨这些见解。


我负责管理我们在欧洲的解决方案实践，主要是与战略客户合作，尝试解决他们最复杂的问题。在过去的一年里，优化一直是大家最关注的焦点。努力让大语言模型投入生产变得可靠。为什么受到如此关注呢？因为优化大语言模型是非常困难的。尽管有各种框架、已发布的内容、提供的指标和各种工具，但仍然缺乏关于如何优化的一站式服务。实际上，这取决于您所面临的问题类型以及您如何解决它。今天我想向您展示找出问题所在以及如何解决问题的框架，以及可以用来解决这些问题的工具。之前提到的困难，首先在于将信号和噪声区分开来具有挑战性，确切地知道问题所在是第一个难点。其次，大语言模型的表现可能很抽象，很难衡量，这使得确定问题规模变得棘手。即使确定了问题及其紧迫性，也很难确定用哪种方法解决已发现的问题，这是我们今天要重点讨论的。今天的讨论主要是关于性能优化。我们希望您在结束时了解不同方案的心智模型，知道何时使用某种方案，对继续优化工作充满信心。首先，优化大语言模型的性能并不总是线性的。很多人展示这种图表，说您应该从prompt工程开始，然后过渡到检索增强生成，最后进行微调，这是优化大语言模型的方法。问题就在于这里，因为检索增强生成、微调解决了不同的问题。有时候您需要一个，有时候您需要另一个，有时候可能需要两者，具体取决于您所处理的问题类型。我们认为情况更像是这样：您可以在两个轴上进行优化，一个是上下文优化，即模型需要了解什么才能解决您的问题；另一个是大语言模型优化，即模型需要如何采取行动。为了真正解决您的问题，它需要执行什么方法或采取什么行动？典型流程是从左下角的prompt工程开始。通过prompt工程的设计，您可以同时做到这两点，但在扩展性方面可能会受限。prompt工程始终是最佳起点。您可以通过快速测试和学习，首先从token开始，进行评估，搞清楚您将如何一致地评估您的输出。然后您可以决定，这是一个上下文问题还是我们需要模型如何采取行动的问题？如果您需要更多上下文信息或更相关的上下文，您可以使用检索增强生成（RAG）。如果您需要遵循更一致的引导，您可以直接进行微调。将这两种方法结合起来，它们是相辅相成的，因此您的问题有时需要兼顾两者。


在解决问题时，人们常常会使用不同的方法，有时仅采用其中一到两种方法，有时则会将所有方法结合起来。典型优化过程如下：首先从左下角开始获取提示，进行评估，确定基线。接着进行简单的下一步，添加少量示例来指导模型。这些少量示例往往会显著提高性能，从而将其连接到知识库，实现工业化过程，通常会添加检索增强生成。假设模型已经有了上下文，但输出不符合要求的精确格式或风格，则可能需要对模型进行微调。接下来可能需要进行检索，但效果不如预期，这时可以考虑提供更符合模型需求的内容，再次优化检索增强生成的过程。


我们已经对RAG进行了优化，现在希望利用引入新示例的更新版本进行微调。这是优化流程的经典范例：尝试、评估，然后尝试其他方法。现在我们将深入研究这些步骤。我们将从快速实施工程开始，然后继续RAG和微调。接下来，我们将通过我和约翰实际挑战的案例来展示这些步骤在实践中的运作。第一步是及时的工程。虽然大多数观众很熟悉这个流程，我们会快速回顾一下，但要确保所有人都理解我们坚持的原则。以下是一些策略，这些策略是我们文档中的最佳实践，让我们简要回顾一下。

首先，明确编写指导方针的重要性。我会举例说明这意味着什么，因为通常这是人们常出错的地方。接着，将复杂的任务分解为更简单的子任务。当想象模型正在预测每个子任务时，提供尽可能具体的指示对于模型的执行很关键。同时，要给予Transformer时间来思考。我会使用一个常见的框架示例来说明这一点。

最后，测试必须系统地进行。客户经常陷入周期：他们修改一样东西，然后又修改另一样，再修改另一样。他们在不断地评估指标，却感觉自己没有向正确的方向前进。这时就需要一套可靠的评估方法，通常是某种大语言模型操作（LLMOps)，这样在修改内容时能够系统地衡量其效果。接着，最常见的下一步是扩展到参考文本或使其能够访问外部工具，这将使我们更深入地探索RAG领域。

先回顾这些实践中的示例。首先，我们来谈谈快速工程的直觉。这里有一个关键的提示，我已经多次提及。再次强调，这是一个不错的起点，也可能是一个很好的终点，具体取决于您的使用场景。为何这么重要呢？因为早期测试和学习，结合评估，为后续优化提供基准。


这是一个开始。有一些问题需要解决。提示引入了新信息，可以将许多信息打包到提示中，特别是利用GPT-4 Turbo。但使用即时工程来实现超高扩展性并非最佳方法。我们将看到其他方法可解决这一问题。此外，复杂样式或方法的可靠复制，受限于模型所接受示例数量的上下文窗口。虽然这是个不错的起点，但根据您任务的复杂程度，可能无法完全达到目标。最后一个要点是尽量减少使用令牌，在即时工程中这是很常见的问题。遇到问题时，不断向提示中添加更多细节来解决问题，最终会导致使用越来越多令牌，增加延迟和成本等问题。再次强调，快速工程并非解决这一问题的好方法。不要搞快速回顾指导，而是要遵循详细的指引。我们收到的提示质量较低，有些模糊，有些输出随机，并且只有少数改进方法被回顾。给出明确的指导，准确说明将面对的挑战和任务。给予时间进行思考。这不是一个好榜样。我告诉它按步骤完成任务，但如果给予时间去思考，会提出更多想法，比如建立推理步骤的反应框架。实际上，它是在为自己寻找答案。React框架只是实现目标的一种方式，但给予GPT时间来思考是另一种很好的方法，它可以处理您需进行的复杂逻辑推理，因为它最终会完成。有一天，它将成为下一个令牌预测器。它输出所需的令牌，以帮助自己更接近答案，具体取决于提示的严格性。最后一个要点是将复杂任务分解为简单任务。在这种情况下，建议将每一步都做到。将其视为一次展示。将其布局得尽可能清晰。右侧展示着漂亮格式的JSON输出。再次强调，这只是基础知识，但在继续之前回顾这些内容是很有必要的。接下来是共同的步骤。在提示工程中，基本上在试图告诉模型应该如何行动，但通常很难确定哪些标记会对模型产生最大的影响。一个很好的起点实际上是将其作为一个展示问题而不是讲述问题来处理。只需提供一些示例，为其提供输入和输出对，从而实际展示你期待的行为。这种方法很好地引导我们迈向下一步，通常会看到一些性能的显著改进。在实践中，我们会发现，这种方法对于我们所面对的实际任务带来了明显的提升。当人们试图将模型应用到工业化时，他们通常希望这些少量示例能够基于用户或特定问题的上下文而变化。在尝试几次后，人们经常转向检索增强生成（RAG）。


在正式深入RAG之前，我想先给你一个简单的心理模型，帮助你了解大致方向。我们先从prompt工程开始。我们已经审视了情况，确定了差距，现在在讨论是应该进行检索增强生成，还是fine tuning。有时把这看作短期记忆与长期记忆的问题是有帮助的。比如说，如果我们在备考考试，那么fine tuning 就好比之前为解决问题准备答案所采用的学习方法和框架。而检索增强生成则如同考试时提供对方一本已经打开的书。如果他们知道方法并且知道该找什么，那么检索增强生成意味着他们可以翻到正确的页面，实际获取所需内容。这就是为什么这两种方法解决问题的本质截然不同。没有方法，没有内容，就无法解决某些问题。在这种情况下，我们假设我们面对的是短期记忆问题。我们希望确保模型提供了足够的上下文来回答问题。检索增强生成(RAG)是指让模型能够访问特定领域的内容。简要回顾一下RAG的概念，虽然大多数人都很熟悉，但我还是想复习一下以确保所有人了解。通常情况下，我们从某个知识库或领域开始，希望获取信息以回答问题。在这种情况下，我们会按照一套相对标准的流程进行，即我们有一些文档，我们将它们嵌入到一个地方。再次强调，我理解人们可能会利用自己的搜索服务，从各种文档来源获取信息，这也是可以理解的。例如，我们假设已经有了一些文档，我们将它们嵌入其中，构建一个知识库。然后当用户提出问题，比如，“加拿大的人口数量是多少？”我们不会直接给用户一个答案，而是会在我们的知识库中搜索相似信息。假设我们进行了相似性搜索，检索到了一些关于加拿大人口数量的内容，然后我们把这些内容整合提供答案。我们会把这些答案传递给生成式语言模型 (LML)，告诉它：“这是问题，这是相关的内容，请用这些内容来回答问题。”希望这个解释能够帮助你更好地理解。


我们将始终努力获得正确答案。现在让我们回顾一下RAG。我想分享一些关于何时应该使用RAG以及何时不应该使用RAG的直觉，就像我们在prompt工程领域所做的那样。RAG的优势在于它可以引入新信息来更新模型的知识，这是目前为数不多的方法之一。事实上，这实际上是客户目前面临的最大挑战之一。他们可能会说，“嘿，我有100,000个文档。我希望模型只理解这些文档。”不幸的是，目前还没有一种超级可扩展的方法来同时获取这100,000个文档，并将所有这些文档的知识提供给模型。检索增强生成可能是目前最接近的方法，即根据您希望它解决的特定问题为其提供一些上下文知识。同样，通过控制内容来减少误解是使用检索增强生成常见的用例之一。稍后我们会看到它与微调是如何完美结合的。一个典型的用例是为模型提供内容，并指示它仅使用该内容回答问题，而不利用其知识。这是人们尝试限制知识的一种方式。在特定知识库中进行训练并减少误解的方法是很有帮助的。尽管有这方面的提及，但对于普遍领域的理解仍有待提高。目前，检索增强生成的一代尚不能教会模型什么是法律或医学。不幸的是，这并不是检索增强生成模型能够执行的操作之一。同样，教模型学习新的语言格式或风格也是非常必要的。这可能发生在微调模型以尝试教导一种方法或解决问题的过程中。同时可以减少token的使用。事实上，在RAG中，您会添加更多token令牌，并不断添加输入/输出示例。通常人们会先进行prompt工程，然后再转向RAG，因为他们的首要任务是确保准确性达到要求，然后再尝试逐步剥离token。随后，约翰将向大家介绍更多相关内容。


简而言之，RAG旨在优化提供更多上下文信息来回答问题。有一个成功案例，展示了prompt工程和RAG的关键作用。虽然听起来简单，但实际执行困难。实现成功需要大量迭代、测试和学习。案例中，客户使用了一个结合两个不同知识库的RAG管道，接着进行了大语言模型的工作。系统收到用户问题后，确定使用哪个知识库，发起查询并回答问题。首先，我们仅实现了检索并进行了大量测试对话。我们对结果和潜在效果感到兴奋，但准确率只有45%，不理想。通过尝试不同文档嵌入假设，成功将准确率提升到65%。而不是进行相似性搜索，我们先生成一个假答案再进行搜索，这方法对一些情景很有效，但在这案例中效果不佳。我们尝试微调嵌入，根据训练数据调整嵌入空间，帮助模型进步。虽然模型在准确性方面做得不错，但耗时昂贵，最终基于非功能原因不得不放弃。接着尝试分块和嵌入，尝试不同大小的信息块和内容嵌入，以帮助模型识别最相关内容，结果有20%提升，但距离客户预期仍有差距。经历20次迭代才达到65%。在某个阶段曾考虑放弃，但坚持下去，尝试重新排序。采用交叉编码器重新排序结果或基于规则内容，例如“也许需要最新文档”，性能显著提升。进行分类让模型对两个领域进行分类，然后在提示中提供额外元数据，以确定哪些内容最相关，取得了不错成绩，达到了85%。


我们现在正处于生产投入的最佳时机。接下来，我们计划进一步加快工作流程。我们对之前的工作进行了回顾，试图更好地设计我们的引导方式。在审视我们犯过的错误类型后，我们引入了一些工具。例如，我们意识到存在着结构化数据的问题，需要从这些文件中提取数据。为此，我们决定让系统访问 SQL 数据库，只需输入变量执行查询，就可以返回结构化数据结果。最后，我们进行了查询扩展。有人提出了三个问题，然后我们将其整理成了一个查询列表。然后，我们并行执行所有这些步骤，将结果返回并最终生成一个综合结果。这些步骤的共同努力使我们达到了98%的准确率。需要强调的是，在整个过程中我们从未进行过微调。这一点非常值得一提，因为通常情况下认为要将系统投入生产需要进行微调。在这种情况下，我们所处理的每个问题都是具有上下文关联性的。可能是因为我们没有给出正确的上下文，或者系统无法确定哪个上下文块是正确的。


了解我们要解决的问题的重要性在于，如果我们不断进行微调，将会浪费金钱和时间。这就是为什么这个故事是成功的原因。我想分享一个略有不同的故事，很酷，谢谢。[笑][鼓掌]另外，我也想分享一个警示故事，因为有时候使用RAG效果很好，有这么多出色的内容，可用于回答问题，但有时也可能产生反效果。让我给您讲一个不同的客户案例。我们有一个客户，试图通过检索增强生成来减少错觉。他们告诉模型，只能使用自己的内容。然后让人工标记员检查并将事物标记为幻觉。其中一个有趣的案例是，当顾客问：“有什么让我们兴奋起来的好听的歌吗？”这个模型回答说用Journey的《Don’t Stop Believin'》。标记员说，“嗯，这肯定是错觉”，但幸运的是这并非错觉。其实是关于他们的内容。有人写了一份标题为“激发财务分析活力的最佳歌曲”的文件。答案就是“不要停止相信”。这有趣，同时也是RAG的一个例子。如果您告诉模型只使用内容，而搜索结果不佳，那么模型得出正确答案的概率为0%。我提到这个原因是因为在评估RAG时，您实际上增加了可能产生错误的另一个维度。这有点像我们的大语言模型可能会出错，然后我们搜寻，但这不能解决问题。这就是为何我想提及一下开源社区提出的几个评估框架，特别是爆炸梯度。他们开发了一个名为Ragas的框架，非常出色。基本上，该框架分解了不同的评估指标，您可以直接在GitHub上下载并使用，或根据需要进行调整。这个框架主要衡量四个指标。


评估法学硕士回答问题的标准在于忠实度和相关性。忠实度要求回答要符合事实，内容与事实一致。如果回答与事实不符，则被认为是幻觉。系统会生成一个数字作为输出，如果高于某个阈值，系统就会停止，因为这表示存在幻觉。这一点提供了一个非常有用的衡量标准。另一个标准是相关性，即回答与问题之间的实际相关程度。有时模型会生成大量内容，但未能与用户最初的问题联系起来。这个标准验证了相关性程度。如果回答在事实上正确，但相关性很低，说明模型需要更多关注这个问题，或者需要改进以确保回答真正满足用户需求。这两个标准涉及法学硕士的专业知识，同时也强调内容的相关性，这是确保客户满意的关键。

正如前面提到的，RAG 的一个典型示例是随着内容越来越多地进入上下文窗口。比如说，“嘿，如果我们支付50块，模型就会给出正确答案。”实际上，这可能导致一个迷失在中间的情况，随着提供的内容增多，模型可能开始产生幻觉或遗忘中间的内容。真正需要的是最准确的内容片段，这就是评估检索内容信噪比的指标所在。它会获取每个内容块，将其与答案进行比较，找出其中是否使用了对应内容。这时就需要思考：“我们虽然准确度很高，但只有5%的上下文精度。我们是否能减少内容量，仍然得到正确的答案呢？”这是一个让人感兴趣的领域，人们开始思考类似的问题。有时会出现过剩的内容，这个指标提供了一种可靠的计算方法，让您进行评估。


像添加更多上下文一样，实际上对我们是有帮助的。最后一个考虑的是上下文记忆，它是否能够检索到所有需要的相关信息呢？基本上，您需要确认回答问题的相关信息是否确实存在于内容中。这是一个相反的问题，就像“我们是否有一个搜索引擎，它能够将重要内容推到前面，我们是否将其放入了上下文窗口中？它能够确实回答问题吗？”如果这一点很低，那表明您需要优化搜索，可能需要重新排名，微调您的嵌入，或者尝试不同的嵌入方式来呈现更相关的内容。我会把这个问题留给你们，因为这就像我们试图从即时工程和实时自动评估中获取更多性能一样。有时候，您实际想回答的问题与您实际要执行的任务不同。有时候，问题的本质实际上是您要完成的任务，这就需要采取侧面措施，实际尝试微调的地方。这也是我会转交给约翰处理的地方，他会更进一步与您讨论微调问题。

让我们谈一谈微调。迄今为止，我们一直聚焦于prompt工程。在这里，我们将讨论一些巧妙的方法，用以在采样时打包大语言模型上下文窗口，以优化在您的任务中的表现。微调实际上是一种与prompt截然不同的技术。首先，从定义开始，微调是指采用经过训练的现有模型，在规模较小且通常更专业的领域数据集上继续训练，而不是使用模型的原始数据集进行训练。微调实质上是一个革新过程，我们基于一个基础模型进行微调，最终获得一个完全不同的模型。总的来说，微调这个术语确实很贴切描述了这一过程，因此我们从一些在大规模且多样化数据集上训练过的模型开始。


选择一个通用模型并对其进行专门化可以提升其适应特定任务的能力。微调是一种将通用模型调整到更适合特定任务的过程。微调的重要性主要体现在以下两个方面。

首先，微调可以帮助模型达到在没有微调的情况下很难达到的性能水平。在使用提示技术时，模型能够接触到的数据量受到上下文窗口大小的限制。在低端情况下，可能需要几千个标记；而在高端情况下，如使用GPT-4 Turbo，可能需要128,000个标记。但实际上，这与模型可以处理的数据量相比并不算太多。通过微调，可以轻松地对数百万甚至数亿个数据标记进行微调。这样，您可以向模型展示更多示例，超出了法学硕士示例在最大上下文窗口中所能包含的内容。

其次，微调后的模型通常比基础模型更有效地进行交互。这种效率体现在两个方面。首先，与已经微调的模型进行交互时，通常无需使用复杂的提示技术来达到所需的性能水平。您不必提供复杂的解释或显式模式，也不必提供上下文示例。这意味着每个请求需要的提示令牌更少，成本更低，响应速度更快。因此，与已经微调的模型交互通常更加高效、更经济，并且响应更迅速。


微调通常用于将大型模型（如GPT-4）中的知识迁移至规模较小的模型（如3.5 Turbo）。从成本和响应时间的角度来看，与规模较小的模型进行交互通常更有效。举例来说，一个想要解决对房地产列表进行自然语言描述并提取结构化信息的问题的人如果没有进行微调，就需要准备各种提示技术的工具。这会导致创建复杂的指令来微调模型，比如在Python中使用Pydantic模型定义显式模式，并提供上下文示例给模型。然后，输入新的房地产列表和自然语言描述给模型，输出结果可能看起来不错，但实际上有微小但重要的错误，比如模型没有提取日期而是模板化了当前日期。修复这个问题很简单，只需添加一个新规则，也就是提供一个新的上下文示例。通过微调解决这个问题的过程通常从一个相对简单的数据集开始，这里提供了简单的示例而不是繁琐的说明、正式的模式或上下文示例。使用这样的数据集进行模型微调，然后再次输入新的房地产列表，基本上就能解决这个问题。


这只是一个简单的例子，但在这种情况下，这个模型表现出色并且效率高。在采样时，我们不需要提供冗长的指令，不需要学习上下文，也没有明确的模式。相比仅使用prompt技术，这个模型表现更佳。微调可能是一个相当复杂的过程，因此设定合理的期望是很重要的，要了解何时微调可能适用于您的案例，何时可能无效。对于强调基础模型中已有知识的任务来说，微调确实有很多好处。文本转SQL任务就是一个例子。您有一些非常强大的通用基础模型，比如GPT-3.5和GPT-4，它们真正了解关于SQL的方方面面，包括SQL语法、SQL的不同方言、数据库工作原理等等。但您可能希望通过微调模型，从根本上强调某种SQL方言，或者防止模型进入容易出错的情况。本质上，您是在利用基础模型中已有的知识，并强调其中的某个子集。微调对于修改或自定义模型输出的结构或调性也非常有用。早期一个杀手级用例之一就是强制模型生成有效的 JSON 输出。这是因为如果您尝试以编程方式与模型互动，以编程方式处理生成有效的 JSON 数据更容易。如果输出不是有效的 JSON 格式，将导致许多错误。此外，在微调过程中对模型施加复杂指令可以展示模型的细节，这是为了避免前述情况的发生。您可以展示比您计划嵌入到模型上下文中的示例更多的样本。但是，微调确实不利于向模型添加新知识。在这些较短的微调过程中，您基本上无法为模型注入新的知识。在这些大型预训练模型的微调过程中，大语言模型中已存在的知识被深入植入到模型中。如果您尝试向模型引入新知识，可以考虑探索RAG等其他方法。此外，微调并不适合快速迭代新案例。进行微调会导致相对较慢的反馈循环，因为创建数据集和其他微调组件需要大量投入。因此，在初始阶段不要立即采用微调方法。我很期待看到一个成功的微调案例的出现。


这个故事描述了Canva团队与大语言模型合作的情景。他们的合作目的是接收用户对设计模板的自然语言描述，然后大语言模型输出一组结构化的设计指南，用于生成全尺寸的设计模拟，最终展示给用户。这种方法快速提供用户所需设计的全尺寸模拟，是快速获取设计想法并生成实物模型的手段。用户可以直接描述他们想要的设计风格，如“我想要红色渐变，类似Instagram帖子风格的个人资料照片”，这样的描述传达给大语言模型，后者输出结构化的设计指南，包括标题、关键样式关键字、英雄图像描述以及实际搜索条件，供图像搜索引擎生成全尺寸模拟的图像。

Canva从基本模型中的3.5 Turbo开始，然后尝试了GPT-4。他们试图深入了解任务的表现如何。结果显示表现不佳，因此主要由人类专家评估员进行评估。评估员发现，虽然这些模型提供了合理的输出，但从设计角度来看，这些输出实际上并不相关。随后他们进行了微调。他们针对这项任务微调了3.5 Turbo型，结果让他们非常惊讶，它不仅胜过了基础的3.5 Turbo型，而且实际上远远领先于GPT-4。这里展示的情况是，尽管3.5 Turbo和GPT-4型通常会输出合理但与设计无关的模型，但在Canva内进行微调后，通过专家评估员评估，通常会输出相当出色的设计模型。如果想思考为什么这个案例有效，实际上并不需要新知识。解决这个问题所需的一切知识都包含在基础模型中，但这个模型需要具备一个非常具体的输出结构。随后他们使用了高质量的训练数据，并且有一个很好的基线进行比较。他们基本测试了3.5 Turbo，也尝试了GPT-4。他们了解哪些方面取得成功，哪些没有，认识到微调是完成任务或用于任务的一种良好技术。

我想分享一个关于微调的警示故事。我非常喜欢这个博客作者，因为他一直尝试使用人工智能助手作为写作助手。他们尝试了Chat GPT和一些基础模型中的API，给他们留下了深刻的印象。但令他们失望的是，这些模型没有捕捉到他们的语气。他们在撰写博客文章、社交媒体帖子或起草电子邮件时都会使用非常特定的语气，而基础模型并没有捕捉到这种语气。他们有了一个好主意，说：“我要下载两年的Slack消息”，共计140,000条消息。他们编写了一个脚本，将这些Slack消息格式化为符合微调所需的数据格式，然后对这些Slack消息进行了微调。这是一个漫长的过程。需要收集数据，整合数据，将其转化为与微调兼容的格式，以微调模型。


最终，经历了微调过程后，他们向AI模型提出了一个请求：“你可以帮我写一篇关于即时工程的 500 字博客文章吗？” 这个现已经个性化的写作助手回答说：“当然，我会在早上处理。”我感到有些惊讶，然后他接着说：“我更喜欢你现在写。” AI模型回答说，“好吧”，然后没有做任何事情。 在微调团队中，我们感到很开心，作者绝对是一名了不起的选手，但如果我们能再进一步进行第二次微调，那真的会非常有效。 基本上，作者希望得到一个能够模仿他们写作风格的模型。 他们得到的是一个能够模仿他们写作风格，但实际上带有他们自己的Slack写作风格的模型。


在Slack上的交流方式通常很简洁，充满了意识流风格。他们通常不使用标点符号，也不追求语法的准确性。这些交流风格的原始数据被用来复制一个模型。虽然微调模型以复制你的语气是一个相对不错的方法，但问题在于他们没有充分考虑为模型提供的数据是否真正达到了他们想要的最终效果。或许他们应该尝试收集大量的Slack消息，比如100条、200条，然后用这些消息来微调模型，观察模型是否在正确的方向上发展，是否更接近于我期望模型复制的语气。一旦他们快速发现情况并不理想，也许他们会选择在电子邮件、博客文章或社交媒体帖子上进行微调，这可能更为合适。

有些示例已经出现，一些直觉也已经形成了，那么实际上如何进行模型微调呢？和处理机器学习问题一样，第一步是获得数据集，但实际上这通常是最具挑战性的部分。有一些方法可以获取数据集，比如下载开源数据集，或者在私人市场购买数据，还可以雇佣标注员来为你收集数据并进行标注。一般而言，如果所选模型的服务条款支持特定用例，可以选择使用更大型的模型，但必须拿出一部分数据集进行微调。接着会进行训练阶段。根据您选择的训练方法，效果会有所不同。使用类似OpenAI微调API这样的一站式解决方案可能相对简单。尝试微调开源模型也是可行的，只需拥有自己的GPU并使用适当的框架，可能需要更多操作。

在训练的过程中，了解可以调整的超参数对结果至关重要，对吧？需要考虑过拟合和欠拟合的可能性，是否需要微调到灾难性遗忘的程度？了解可调整的超参数及其对最终微调模型的影响是非常重要的。接着，要强调理解损失函数的重要性。当微调语言模型时，观察损失函数实际上是在评估下一个token的预测。这对微调语言模型非常有用，但通常下一个token的预测并不直接关联到您所关心的下游任务表现。如果考虑到代码生成，解决某一问题的方法有多种不同的类型。因此，仅仅关注下一个token的预测和准确匹配标签的模型损失或变化可能与下游任务的性能变化无关。理解这一点至关重要。

接下来是对模型的评估。有几种不同的方法可以评估模型。基本上，您可以邀请专家查看输出，并在一定程度上对其进行实际排名。另一种方法是，您可以让不同的模型生成输出，然后相互进行排名。虽然这并不是绝对的排序，但可以通过类似于国际象棋中的ELO分数的方法来进行评分。您还可以通过使用微调后的GPT-4、开源模型或GPT-3等更强大的模型来对输出进行排名。


对于Turbo排名中的输出进行微调是一种常见做法。最终目标是将其应用于实际情境，并在推理过程中进行采样。这种循环能形成反馈机制和数据循环。您可以训练模型，评估性能，将其部署到生产环境中，在生产中收集样本数据，利用这些数据构建新的数据集，对数据集进行下采样和清理，进一步微调数据集，使整个系统运行起来。到目前为止，我们已经讨论了这个过程的一些内容，但我想正式确认一些微调的最佳实践。首先是开始快速而小规模的工程和学习。这些技术都是低成本的，并且能让您对大语言模型的工作方式以及它们解决问题的方式有一些直觉。这是一个很好的起点。接着，在进行微调之前建立基线非常重要，类似Canva的成功故事。他们使用了GPT-4进行了知识蒸馏实验。他们对自己尝试解决的问题有了深入了解，了解了这些模型的失败案例，也了解了在哪些方面表现良好，因此他们准确了解微调的目标。在微调过程中，他们建议从小规模着手，而不是一次性下载140,000条Slack消息。他们建议先开发一个小而高质量的数据集进行微调，然后评估模型并查看微调是否朝着正确的方向发展。在微调模型时，建议观察输出，了解模型在哪些领域表现不佳，然后针对这些领域使用新数据进行专门调整。他们指出，对于大语言模型而言，微调数据集的质量远比数量重要。在培训过程中，数据量的部分是在预训练中完成的。因此，现在似乎更注重少量高质量示例。最后，他们提到了微调和RAG，指出将它们结合在一起可能适用于某些用例。通常，微调模型是为了理解复杂的指令，而之后无需再提供。在微调模型时，通过简化复杂指令和采样示例，使其使用更高效。这意味着减少采样时所需的提示标记，因为不再需要进行复杂的prompt工程。这些信息会被融入到微调的模型中，从而有更多空间来检索上下文。然后，可以使用RAG将相关知识注入到上下文中，已经最大化了可用的上下文。然而，需要小心不要过度饱和上下文，否则可能导致与实际问题无关的虚假相关性。总的来说，这为更重要的目的打开了上下文窗口。现在，我们将讨论该理论的应用，而非仅停留在理论层面。让我们把话题转回给科林，继续向前迈进。- 谢谢，约翰。[掌声] - 酷。现在让我们看看这些理论。我们将要解决的问题是Spider，在基准测试中，一个有效的方法是根据给定的自然语言问题和数据库模式生成语法正确的SQL查询来解答该问题。


我们开始尝试使用快速工程和RAG方法。首先，我们尝试简单的检索方法，即使用问题来查询SQL以回答类似的问题。我们还尝试了不同方式来格式化Token嵌入。尽管我们只是通过几个示例尝试了一系列快速工程方法，但结果并不理想。我们意识到问题的多样性可能会导致完全不同的答案，即使问题非常相似。因此，在处理问题时，我们必须考虑到这一点。


在解决问题时，使用问题所设定的答案进行搜索可能会获得更好的结果。我们采用了假设文档嵌入的方法。生成一个假设的SQL查询，然后用于相似性搜索。针对这一问题，我们实际上取得了显著的性能提升。尝试了上下文检索，采用简单过滤。我们按照问题的难度对问题进行排名，然后从RAG模型中选择同等难度的示例。这带来了更好的改进。接着尝试了一些更先进的技术，考虑了链式推理。识别列，识别表，构建查询。最终采取的方法相当简单，进行自我一致性检查。系统构建查询，运行查询，如果失败，提供错误消息和注释，再次尝试。GPT自我修复变得有趣起来。延迟和成本不是大问题，因此这种方法运作顺利。结果如下，想与你分享。

在快速工程中效果不佳，初始成功率为69%。添加例子后取得改进，RAG可以进一步提升表现。通过这方法表现提升3%，再使用答案（假设文档嵌入），又有5%的提升。通过假设问题搜索，表现有巨大改善。增加示例数量，却比现有技术水平低四分之一。从快速工程到RAG，几天时间展示出不俗的提升。微调过程交给约翰完成。

模型微调委托给首选合作伙伴Scale AI。建立基准线，与前一基准线69%相同，仅需简单快速工程技术。然后使用简单技巧微调GPT-4，对模型进行调整，将性能提升至82%。接着结合RAG技术，动态注入示例到上下文中，解决实际问题。成功率达83.5%，使我们进一步接近先进水平。


在讨论数据集排名时，我们需要意识到所采用的技术常常非常复杂。通常情况下，人们必须进行大量的数据预处理和数据后处理工作，甚至需要将一些特殊情况硬编码到用于评估模型性能的脚本中。然而，实际上，并不需要过度依赖这些复杂技术。通过简单的微调和一些及时的技术改进，我们就能够取得长足的进步，只需遵循最佳实践即可。众所周知，这一基准已经达到了领先水平，显示了微调和RAG方法的有效结合。因此，当解决问题并希望提高大语言模型性能时，启用快速工程技术是一个明智选择。这些工作投入成本低，能够帮助您快速迭代，验证大语言模型作为解决问题的有效技术。可以持续迭代，直到性能稳定，并需对遇到的错误类型进行分析。若需要向模型引入新知识或更多背景信息，选择RAG技术路径。如果模型未能一致地遵循指示，或需要遵循特定的输出结构，或者希望更有效地与模型进行交互，或许应该考虑进行微调。必须牢记这一过程并非线性的，这点至关重要。或许需要进行多达49次迭代才能达到满意的水平，并且在不同技术之间频繁切换。