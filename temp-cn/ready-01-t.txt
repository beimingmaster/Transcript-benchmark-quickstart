嘿，大家好！很高兴能来到这里。我是特德·肖，是谷歌大脑团队的高级研究工程师。过去五年一直在专注研究机器人技术，涉及多任务学习、强化学习等领域。最近，我开始思考如何让机器人更好地在现实世界中发挥作用。

今天我们将讨论多个不同的主题。首先，我想强调的是我们团队非常庞大，有超过40位成员致力于与产品合作多年。这些努力是巨大的，我很荣幸能成为其中一员。

另外，我想特别强调的是，我个人观点可能会比较激进、有争议，但请注意这些只代表我自己的看法，并不代表谷歌或团队其他成员的看法。

欢迎来到我的 TedX 站点。也许你们当中有一些人已经看过许多cool的机器人和学习视频。这些天我比以往任何时候都更加兴奋。我并不只是在炒作，我认为过去两年来，研究者和机器人技术在学习方面的看法发生了根本性的转变。我觉得这种转变不仅仅局限于各种领域，例如语言和音频等，而是在整个大规模互联网模型的基础建模方面更为普遍。但是今天我想向大家传达的是，我对今天所处的时代感到特别兴奋，并且认为在机器人学习领域出现了一种根本的范式转变。如果在我演讲结束时，您能留下一件事，那就是：对机器人技术的兴奋感比以往更强，或者相信现在正是我们应该迈出的一步，让机器人技术真正开始呈指数级扩展。

今天我要和大家分享一些非常酷的事情，让我的演讲更成功。我们来看一下，演讲分为几个部分。首先，我们会从一个高层次开始，讨论基础机器人技术模型是什么，以及我们实现这一目标的成分和配方。然后，我们将深入研究一些不同的案例，我团队在过去的一两年中对此感到非常自豪。最后，我们将回到高层次，然后缩小范围，探讨机器人学习的下一步。那么，为什么机器人技术的基础模型是如何的呢？

在接下来的讨论中，我会使用“互联网规模模型基础模型”和“大型语言模型”这两个词汇进行互换，希望这样更清楚明了。这些模型在斯坦福大学被创造出来，它们对于机器人技术的发展有着重要意义。

训练大量数据的大型整体野兽有两个非常重要的特性。一个是涌现，即当在小规模上进行简单操作时，当扩大规模时，它们会变得更好。更多的数据，更多的计算，更大的模型。我们能够看到，当这些模型变得足够好时，它们擅长的领域开始扩展。有两篇博客文章值得推荐。一篇来自Jacob Steinhardt，标题为“人工智能的不同之处”，讨论了我们在物理或生物学等其他领域看到的现象，例如单个水分子的行为非常不同且具有很大变化。与此不同的比如静电力，在增长过程中开始聚集，表现得像液体一样。我们在动物群、人类和经济领域看到了这种情况，在不同领域都有发生。现在甚至在人工智能中也能看到。模型正在在较小规模上完成一些工作，逐渐展现出同样的趋势。

有些事情可能在一开始是不可能实现的，但当达到一定关键规模时，它们就能够开始工作得非常有效。Jason在他的博客文章《新兴技术》中记录了这一现象。在这张图中，我们可以看到当任务数量跨越多个领域时，无论是模块化算术还是解答问题，成功率都大致相同，直到模型变得足够庞大和足够优秀，然后成功率开始迅速上升。这就是为什么我认为这是如此令人兴奋的。当事情被问及时，我很高兴有机会与大家讨论，并分享一些我们已经探讨的方向。我希望我们能在接下来的十分钟左右探讨这个问题。

这是一个很好的问题。我觉得在我们深入讨论任何机器人基金会模型的可行性或存在之前，我们需要思考是否真的需要这样做。我认为这是我们所有人（包括我自己）内心都在思考的问题。

新兴的技能和依赖这些技能对机器人技术的发展至关重要。过去几十年，机器人技术的研究主要局限在受限空间内，与人类实际生活场景相比存在很大差距。要实现巨大飞跃，就需要依赖新兴技能的扩展曲线，才能处理复杂的任务。例如，一个人形机器人程序可以在数百次试验后完成空翻，但要让机器人适应复杂的真实世界情况，就需要依赖新的涌现现象。思考为什么或为什么不一个机器人技术的基础模型可能会奏效也是很有趣的话题，这种方法在其他领域也得到有效应用，例如音频编码或语言处理。

看起来3D模型和机器人技术面临着一些挑战，其中有一些特别的地方需要考虑，比如体现、因果关系和物理基础。这可能是制作简单配方的障碍，这个配方适用于其他领域。如果机器人技术由于一些特殊之处而无法成功应用该配方，我认为研究其原因是很有趣的。我个人是个乐观主义者，我认为没有神奇的秘诀可以阻止机器人技术在其他领域使用相同的方法和技巧。但我认为探求答案是我喜欢的功能，这也许需要不仅仅是哲学激励，一个很好的基础模型，让我们尝试为机器人技术构建一个模型。我们应该考虑如何做到这一点。我认为我们可以借鉴一些其他领域的经验，站在它们的肩膀上，看看如何应用于机器人技术。首先，我们可以研究一下机器学习在不同设计原理下的表现，与其他领域进行比较，然后再看看高容量架构。

今天我们要讨论的主题是一些新的想法，比如自注意力机制，就像安德烈·卡帕西这样的研究者所提出的那样。

是的，这些技术可能会在互联网上被逐渐淘汰，而不仅仅是原理。令人振奋的是，我相信你知道，对专家和普通人来说，这是非常令人惊讶的。许多不同的生成模型正在尝试新的功能，并一次又一次地超越我们所有最疯狂的期望。即使我们觉得我们已经精疲力尽，所有这些技术还有很多，可能会有一些新技术出现，让我们大吃一惊。我认为这种趋势肯定会持续下去，不仅会继续出现新技术，而且会加速发展得更快。无论我们是否愿意接受，就像我们日常做的事情一样，我是一个机器人研究员，或者可以说是一个专业领域的研究员，你可能还没有接触过机器学习的某些领域。不久的将来，这些领域将迎来巨大的突破和发展，每周都会推出新功能。

你知道，现在不仅能看到令人印象深刻的模型，而且看到了新模型的开发速度明显加快。很多团队在合作中发布了很多新模型，这些模型不仅供大家使用，还可以作为构建更高级模型的基础。这一趋势主要体现在机器人领域，实质上是从在线机器人不断积累经验、尝试和错误学习，到离线设置使用这些经验数据。我们将数据的生成和消费进程分开处理，就像其他基于数据建模的领域一样。这些庞大的互联网规模数据集非常丰富多样，但也是静态的，我们只需对其进行刮擦和多次整合。我们采集到从Luther到Lyon 5B的数据集，包括图像匹配、图像文本等。这些模型都异常庞大。

我们之前看到的那些规模要大得多，它们绝对是其他领域在训练这些大型基础模型方面取得成功的关键因素。这也涉及到机器人技术。让我们简单回顾一下这种变革是如何发生的，因为很容易只停留在一个片段中。是的，机器人技术的离线次数比在线次数多，这对许多来自其他领域的人来说是理所当然的。比如这是机器人技术中能够取得成功的一种方式，这是一个非常显著的转变。对许多人来说，机器人技术也是与强化学习（RL）同义的，但我认为这种说法已经越来越不准确了。因此，我想带您简要回顾一下我们团队的历史，通过幻灯片和交谈，向您介绍谷歌机器人技术的简史。当然，谢谢您的参与。我认为这不仅仅是为了戏剧性的展示，而是为了让您了解多年来我们团队思维方式发生了多么巨大的变化，以及这将如何影响我们的设计决策。

我们在这个具体项目中采取的风险和研究方向，我们团队在2016年进行了一个实验，部署了7个Kuka机器人在一个房间里，收集24/7的采摘数据。这是我们在现实世界中进行强化学习的策略，我们是第一个这么做的团队。我们也探索了在现实世界中实现端到端机器人学习的可能性，这在当时非常罕见。我们的方法存在一定风险，我们还开展了一些有趣的研究方向。我们研究了一种叫做q-tops的连续动作控制的q学习方法，并结合了我们在CycleGAN上的视觉输入研究，将模拟图像转换为真实世界的图像。我们也研究了并发技术，以便让机器人在现实世界中更快、更有效地移动。有什么问题吗？

手臂是指机器人将东西捡起来的行为。如果机器人抓取失败，东西会掉在地上，第二天早上返回房间时会发现到处都是东西，表示没进行重置。但如果机器人只是稍微抓取失败，东西会重新落回垃圾箱里，希望机器人能再次捡起它们。对于24/7机械臂农场，我们不会进行重置，因为我们设计了垃圾箱来存放被丢弃的物品，即使机器人抓取失败，物品也会被安全存放在垃圾箱内。在使用Q学习进行线下策略在线强化学习时，我们与模拟数据进行混合，然后再次部署机器人。在2020年左右，我们经历了这样的整合阶段，当时感觉很不错，我们想要摆脱困境，寻找更复杂的任务和更实用的设置，可能更接近人类每天使用的通用物品。

您听说过谷歌的微型厨房吗？我们在办公室里也选择了一个微型厨房环境。我觉得这是我们操作的最佳配置。我们在这里开始收集数据，并扩展了我们的实际操作。我们尝试了不同的方法，并发现右下角的机械化重置版本很有用。谈到手臂农场，我们有一个折叠式垃圾箱，用于进行多任务强化学习。垃圾箱会翻转一半，将物体倾倒到另一侧，这样就可以尝试更多有趣的任务。手臂程序现在可以拿取物品，例如“请拿起胡萝卜，将番茄放在盘子上”。垃圾箱翻转后，就可以重置一些其他作品，这就像在多任务学习中一样。我们还尝试将强化学习与模仿学习结合，但在2020年，我们意识到我们在研究许多不同方向，想要巩固成果。我认为当时真正困扰我们的两个问题是，所有这些方法中有一些在50%到70%的稳定性。

在现实世界中，不同方法有各自的限制和优势，需要遵循政策。我们希望找到一种方法或策略，在实际任务中表现优异，能够超过90分，同时扩展数据收集的范围。虽然我们资源不如学术环境那样充足，但我们拥有一定数量的机器人操作员，受到物理规律的限制。因此，我们需要一种方法来获取更多数据。经过几个月的考虑，我们决定采用多任务模仿学习，与之前的24小时7天农场有很大不同，这代表了我们方法的重大进步。

我们已经发现，通过温柔关怀和爱，多任务模仿学习，可以达到这个数字90。通过更多的演示，这个方法可以进一步提升。这些方法虽然并不廉价，但可以通过额外的改进来实现更佳效果。示威是我们正在寻找的生命迹象，不到一年前，我们的团队决定这是我们未来前进的方向之一。也许你已经意识到，我们可以考虑将我们当前的方法应用到未来的传播中。我们或许可以将这些想法延伸到其他领域，比如，如果我们现在将演示和数据收集与如何利用这些内容进行多任务学习分开，邀请学习政策或许将成为未来的发展方向。接着，我们可能会尝试一些类似离线强化学习的方法。尽管我觉得现在我们在高水平的运转，只需短短几分钟就能理解，但这背后凝结了我们团队六年辛勤学习的宝贵经验。回顾我们今天所处的位置，即使是两年前，如果你告诉我现在可以如此扩展我们的策略方式，我可能难以置信。

我可能会怀疑你，但这个问题确实挺有意思的。我认为任务调节依然是一个待解决的问题。通过我们在BC0项目中的研究，我们发现语言至少在模式化语境中有一定的表达能力。比如，收葡萄或者将葡萄移到盘子上，甚至调节桌上的黑色时钟。这种表达方式还是足够的。你可以通过学习这些模式，获得大量的技能。这些技能本质上是被传递给你的，你只需将一个单一的ID添加到你的策略网络中，它就会学会模仿。每个这80个任务都会收集数百或数千个示范，稍后我会详细介绍。

2022年，我们需要采用离线方法来处理数据，将数据生成和数据消耗分开。我们要学习三门课程：第一门是机器学习扩展的设计原则，理解如何应用这些课程到未来的机器人学习和基础模型中。重要的第一课是高容量架构，比如注意力机制。第二门课讲数据互操作性，标记化和离散化的重要性。第二方面是模型本身的发展，随着时间推移变得更加优秀。我的同事提到的“投标人课程 2.0”强调了利用方法随着计算能力的提高而改善基础模型。

当有一组不同的方法可供选择时，我们想要确定哪一种最适合与更好的基础模型结合使用。在这种情况下，如何真正判断哪些方法符合标准是一个重要问题。我认为一个很好的做法是审慎选择，因为在痛苦的教训1.0和痛苦的教训2.0中，这两个版本都强调了这一点。虽然确定哪些方法符合标准并不总是显而易见，有时相当困难，但有时你会有明确的信心。随着数据量的增加和计算能力的提高，这种模式可能会变得更加明显，但基本上，过多的硬编码和假设会导致我们更依赖于特定基础模型和特定实现算法。因此，对于适合的方法的选择可能要比只是假设某些非常抽象的输入和输出，并从输入端进行操作更为复杂。

随着时间的推移，我们可以改进获取和输出信息的方法，以确保其稳定和可靠。甚至可能会改变算法本身。对视频课程2.0的看法可能因此而不同，因为新的方法和技术不断发展。我认为陪审团尚未做出最终决定。有一点我想强调的是，语言是我们用来分享经验和教训的重要工具。当我们将语言作为通用交流工具时，无论是通过字幕、生成还是其他方式，能够帮助不同背景的人相互理解。在视频课程2.0中，这将是非常重要的。另外，离线机器学习的数据处理方式也在不断发展。通过将这些数据整合到一个通用架构中，并应用语言作为通用工具，可以创造出智能和现代的解决方案。我将很快展示我们不同的项目，希望能够得到认可和支持。

这种哲学的启示，我们已经有了一些理解动机和潜在方法的初步了解。但我很想知道我们目前使用的方法是否遇到了什么问题。似乎我们已经建立了一些相关的基础工作，比如像容量架构这样的架构概念，我知道架构与语言相关。我们似乎已经有了有关组件的相关课程，为什么这些尚未被整合成为一个解决方案呢？实际上我们已经拥有很多组成部分，所以为什么机器人技术领域却还没有得到很好的解决方案呢？我觉得目前这一领域可能并不十分明朗，很多人对此有不同看法。因此，我认为在机器人技术领域有待进一步探讨。

各个组件的发展程度存在巨大差异，我认为我们可以稍后再讨论，比如数据规模或者有些从其他机器学习领域渗透到机器人技术。但我认为我们还处在非常不同的发展阶段，有多少人真正接受了这些课程并做出了投资呢？我很想知道。我不要求你提供具体名字，但有些人可能选择视而不见这些事情。我可以扩展一些幻灯片，但可能会让自己陷入困境。这也是为什么你认为他们错了。我觉得我个人可能会这样认为，但不代表我的团队，而是很多人。我的团队可能正处于学习如何扩展数据驱动的最极致阶段，基于基础模型。

往大里想吧，我觉得很多人没有这个信念。确实，等一下我们再讨论为什么。也许在扩大规模之后，好吧，让我们继续深入研究，看看这个食谱实际上如何在特定领域应用。首先，我们来看看最近我们小组的一个项目，致力于扩展模仿学习的应用。让我们看看如何实际应用这些原则。所以首先要考虑的是我们实际上在做什么。设想一下我们置身于2020年春季的情境中，我们花了很长时间来收集演示，数量庞大，比如超过十万个演示，利用一年半的时间在多个机器人上完成各种任务的演示收集。这是非常昂贵的。随着时间的推移，你知道这些演示不会无限地像以前那样大量产生。每天获取新的高质量演示不仅难以实现，而且这样的趋势还会增长，但并非没有代价。实现这种自主增长的方式非常困难，就像之前你看到的带有bin重置机制的MTOP或DeepMind那样。

RGB 堆叠公司正在尝试进行自主重置。目前，他们采用了 BC 零首创的人类远程操作方式，但这种方法非常昂贵，因此吞吐量有限。同时，他们使用基于 resnet 的骨干网，这在性能上表现很好，但发现对训练数据分布非常敏感。当他们从一些电信运营商那里删除数据时，模型表现得更好，但这并非他们希望看到的。他们想要更多数据，即使数据不完全相同。因此，他们认为模型需要稳健和概括性。他们在寻找现成的模型时发现，那些来自其他领域的视觉变形金刚并不适用于真正的机器人，因为需要以较高的频率运行。最后，他们希望他们的数据集能够理解语言，因为语言是一种通用粘合剂。

在我们设计语言模型时，一个首要原则是希望能覆盖非常多的模式。这意味着我们可能需要重新设计或修改一些东西，而不只是依靠现有的东西。我们要从不同领域的最佳实践中汲取经验，经过一段时间的工作，我们再次为rt1提出了这个架构。团队规模较大，有许多不同的贡献者，我在这里将介绍其中一些内容。

高级的rt1是一种名为Transformer的机器人，运行频率为3赫兹。它接收来自机器人或RGB相机的视觉输入，同时接受自然语言指令。图像经过修补后输入到高效网络中进行tokenizer处理，然后传递给令牌学习器，我接下来会详细介绍这个过程。语言指令也被分解成令牌，并一同输入到一个Transformer中。最后，我们以离散化的动作作为令牌输出，通过闭环系统以3赫兹的速度发送到现实世界中。

这个 Transformer 是一个解码器，它通过应用因果掩码来进行动作预测，使用稀疏分类熵目标。我们采用了预先训练的高效网络主干，并结合令牌学习器来加快推理速度。当图像被输入时，每个图像都会被分成81个单独的补丁，每个补丁代表空间上的一个小块，就像一个正方形。令牌学习器的作用是根据图像上下文动态选择其中与当前情境最相关的补丁，以提高准确性。通过这个方法，我们可以从81个图像补丁中选取具有最高相关性的信息。

进行子采样的图像处理过程用于推理时，每个时间步都会发生。通过对8个图像进行采样，我们能了解到哪个图像中的补丁在任何时刻都是相关的，以避免发送过多令牌，导致上下文长度激增，无法进行Roblox推断。同时，我们传递了一个由六个图像组成的单个序列长度。在现实世界中，历史是非常关键的，比如对物理规律的了解，对机器人来说，物体之间微妙的关系非常重要。我们的模型有3500万个参数，相比其他模型，规模要小得多。一个主要区别是我们在进行离散化动作之前，而不是像许多其他产品那样进行连续控制。我们的机器人通过末端执行器来进行位置控制，因为现实世界是一个连续状态空间。因此，为了实现这一点，我们必须提出很多新方法。

在算法中，有一个类似于CEM（交叉熵方法）的演员，他实际上是对可能的连续动作进行采样，以找出Q函数评分最高的动作。我们尝试了两次之类的方法，但太敏感了。我们需要找到一种让事情管用的方式。现在，我们决定告诉你我们仅有256个离散动作，让我们去预测它们，以获得所需的数据或工程环境的有关速度延迟反应方面的信息。我们认为使用一个相对较小的模型是有道理的。借鉴你之前的数据或分析经验来平衡这些模型是关键。在某种意义上，如果你需要很多参数来获得一个强大的模型，另一方面你想要具有高度可控输入，那就有一个重要的问题。我们设定了一个很严格的推理时间为100毫秒，但在基础建模中，有很多教训告诉我们不要设定限制。

无论是在处理大规模数据集还是模型容量方面，我认为你提出的观点非常好。将来可能会遇到严重的瓶颈，但就我们当前的情况而言，我认为更应该探索这些原则，甚至超越我们目前所能看到的范围。我们是否可以在这 3500 万个数据上取得进展，相比之前使用的许多工作，这是巨大的，例如 resnet 34 或类似的模型。因此，这个选择已经远超过了其他许多选择，目前至少是最简单的，也是我们在短期内能够实现的最大规模，无需考虑更多技巧。需要明确的是，我们可能可以在未来讨论这一点，我很想听听你的想法，因为我们如何克服这些瓶颈并不是很明显。它们确实没有给你一台拥有 100 个选项的医疗计算机，但其他条件可能会以类似的方式禁用你的平台，你觉得你已经看到了一些重要的东西。

你说得对，可以优化当前的模型架构或者探索一些新的方式，而不仅仅是尝试扩展规模。关于限制值的问题，我们对模型尺寸进行了一些缩减，我将在几张幻灯片中详细展示。或许我们应该回到之前的讨论点，查看是否还有其他可能性。是的，架构很重要，稍后我将讨论一些消融和趋势，但也许你知道这是一个关于机器学习的讲座，我应该给你展示一些漂亮的视觉效果。让我们来看看我们的一些评估结果吧，我们将其与一些基线模型进行了比较，其中包括加托和基于ResNet的BC归零基线。我们发现在评估场景任务中，我们能够应对未曾见过的任务，并让Shacker对象感到困惑。我们原本的数据收集看起来像左上角的那张图片，上面有三个罐头，但之后我们通过引入更多对象进一步推进了研究。

桌子乱成一团，有时候找东西都费劲。我们改变了桌布纹理，在微型厨房进行实验，发现 rt1 比其他方法更坚固。问题是，我们是根据自己的数据重新训练了 Gato 模型，而不是使用原有数据。机器人在微型厨房里做着各种有趣的事情，进行不同的可视化表现。它经过训练后，在新环境和新对象下表现出色。我们还将它放入长视野设置里，使用第二个框架进行实验。

接下来我们将讨论这个框架。在这些设置中，许多人将所有这些泛化功能混合在一起。在左边的图中，我们使用的是Vemma论文中启发的泛化水平，这个水平基本上是指同时改变更多的变异因素。在这里，我们发现rt1是最稳健的。是的，这是个好问题。我们稍后会更详细地讨论这个问题，但我认为在高级电信运营商那里会使用一个结构化的模板化命令，比如动词、名词、动词，或者像挑选可乐罐或将苹果移动到海绵附近这样的命令。我们有大约700个这样的任务设置。他们会继续收集完成的数据以进行测试，然后我们会确保成功实际上是成功的。对于那些不安全的东西，我们会丢弃它们。哦，对了，这篇论文得到了很多次展示，大约使用了130,000次。是的。

你提出的问题很重要，之前的一些研究也指出了这一点。举个例子，当面临问题时，你是否发现数据集中的特征非常多样化？就像你所说的，从A点到B点，可以有左转、右转、直行等多种路径选择。我理解这种多样性在单个图像阶段基本适用，但是我的数据有三种可能的标签，有时可能会产生很糟糕的影响。也许因为我们正在使用的是演示数据，比起真实场景中的数据更加同质化。例如，有一种叫做“玩耍数据”的数据函数，操作员可以随心所欲地进行操作，然后我们进行事后标记。我认为我们的数据比这还要同质，但我们并没有在之前的项目中遇到太多问题。一个潜在的答案可能是架构本身，不过我们之后也可以再深入讨论这个问题。你的问题非常好，事实上，我们确实有在谈论一个终止操作策略时，需要关注的是如何确定一个事件何时完成以及如何预测终止。在每次远程操作会话结束时，操作员都有可能点击按钮来标记这次操作的完成。我觉得我们对这些评估非常严格，但有时候在某些情况下，如果我们只是为了自己做一个实验，可能会得到一个密集的奖励规模，比如抓住物体并将其靠近。即使最后失败了，我们也接近成功。基本上，我们会得到一个分级曲线，但对于所有这些数据统计，我看到结果要么完全是零，要么是完全完成，没有中间状态。这让我感觉很酷，我认为谈论多模态方面会很令人兴奋，我们会继续推动极限，因为我们是TR，我们决定在非常多样化的数据分布上进行训练。

是的，我们使用了从130个到1000个演示中获得的数据来展示这个日常机器人的移动控制器。但是我们也希望在不同的数据分布下进行交易，可能包含不同的动作分布、轨迹和视觉对象任务。为此，我们还引入了另外两个数据源。一个是通过强化学习在sin模拟中收集的数据，看起来完全不同于之前的数据来源。通过我们之前提到的识别学习和强化学习的结合，我们发现合并这两种类型的数据很有挑战，因为强化学习的动作速度非常快，且是针对特定奖励函数和人类收集的远程操作数据进行优化的。

可以说，对于理解人类生活，我们的学习将更有深度。最后，我们还恢复了两年前的数据集，即2018年。也许你还记得的KUKA项目，ARM农场已经运营多年。

这些数据依然很重要，所以我们想要探究不同建筑物中的不同物体在不同机器人上有不同动作空间的视觉效果是否还可以与最初训练微型厨房数据集的数据相结合。令人惊讶的是，rt1能够从所有这些非常不同的数据分布中学习。我从未见过这样的结果，或其他架构如resnet或其他学习方法（如强化学习）能够在如此不同的数据分布上学习如此稳健。

我们对组合概念进行了评估，这样我们就可以让原来只能在Kuka项目中看到的机器人拾取物体，或者将模拟中看到的物体放在一起，看看我们的策略是否能够理解这一点。因此，它似乎能够泛化到其他数据集中看到的对象和概念，将其推广到当前在真正微型厨房环境中的设置。这是一个非常有趣的结果，确实是一个很好的问题。

是的，我们只是将数据进行标记化，确保标记方案具有互操作性。我认为这就是关键，稍后我可以深入探讨这一点。是的，不，这并不意味着我们可以将一个机器人的确切行为发送给另一个机器人并让其执行。更像是在数据集中，我认为即使通过人工检查，也能看出它们来自两个不同的机器人。所以，让我们看看现在讨论的一些缩放定律的消融现象。我们发现减少数据量会降低性能，但更有趣的也许是任务多样性的重要性。我们看到了两个不同的趋势。绿线是当减少每个任务的情节总数时发生的情况，而灰色和紫色曲线是当减少任务总数时发生的情况。我们发现，拥有更多的任务比为每个任务提供更多数据更为重要。我认为这是一个重要的教训，可能会建议我们改变方法，认为我们应该进一步发展机器人技术不仅仅是在同样的环境中采集执行相同任务的更多数据，而是要勇敢走出去，获取更多样化的行为数据。问题在于，在这种情况下，如何定义数据的多样性呢？嗯，我觉得这些只是电信运营商接收到的一些固定模板化的指令，总共有700个这样的指令。然而，当你开始削减这些指令，只用其中的500个进行训练，或者只在其中300个上进行交易时，性能下降的速度比我们保持相同情况时更迅速。嗯，这种规模的削减我很熟悉，但是我不确定为什么会有这种性能下降。是的，我不认为问题在于数据量和成功率之间似乎存在线性相关性。我想，我们可以尝试应用一些特殊方法，比如缩放法则，以尝试找出解决方案。

我们正在努力适应这种情况，但实际上我们对此并没有进行过多研究，因为我们知道这是我们所期望的趋势，但我们仍然不确定它对我们的影响有多大。嗯，除了根据我们的经验看到这种现象，我对此并没有什么特别深刻的见解。是的，这是一个很好的问题。或许这种情况会持续无限期，或者在2023年1月会发生一些奇妙的变化。我认为当我们开始深入探讨算法与扩展现实世界的操作时，这可能是我们需要考虑的一个因素。当我们收集数据的时候，我们的政策已经涵盖了接近100％的情况。因此，我们可能需要收集另一组数据，以确保我们基本上达到100％的覆盖率，然后再考虑其他的情况。

在这个 rt1 架构上我们下了很大的赌注，已经收集演示了一段时间，可能收集到的比我们需要的更多。在某些情况下，实际上你可以缩减任务而不会损失太多性能，这非常有趣。在不同任务的能力和熵方面是相同的，可以向它们学习。是的，这是真的。有些任务要容易得多，比如我们有一个任务，只是拿起一个物体，这个任务要简单得多。你可以从中发现一些有趣的东西，而不是将东西搬移到抽屉里，然后关上抽屉。这是一个很好的问题。现在，我们也在消融。

在没有使用大规模模型的情况下进行了训练，我们实现了无需预训练，没有使用预先训练过的参数。我们研究的是连续动作而非离散动作，包括很多侵略性动作。我们没有使用变压器模型，我认为这些设计选择似乎确实是为了性能的稳健性所必需的。这是国外研究，我想表达的是，一次又一次，对于写论文来说，这有点像我们试验后获得最佳结果的方法。然后我们会弄清楚为什么每一个选择都很重要。因此，我认为这里可能令人惊讶的是自回归行为并不总是有益的。有些人可能认为传递更多信息总是好于传递更少信息，但在某些情况下，对之前行为进行调整可能会更像是在上下文学习中，这种方法会在线上进行系统识别以了解来自teleoc雷达的数据。

对于适应特定动作历史这个问题，我觉得删除它反而更好。另外，我考虑过采用其他更快的方式来节省时间，尽量做更少的事情，留一些时间来解决问题。在接下来的工作中，我打算调整一些关于技能学习的内容，更注重规划层面。我们第一个项目融合了其他领域的设计原则，在离线机器人学习范式中引入了技能学习的概念，这看起来是可行的。我记得2022年的时间线，我们当时在思考如何扩展多任务模仿学习，并结合大型语言模型如Imogen和dolly 2来探索新的可能性。我们已经开始设计rtu 2-1，以期发挥这些模型的优势。

我们已经押下了很大的赌注。但实际上，在开始探索我们的全栈系统中如何运用测试版2.0课程时，我们遇到了一个问题：基于语言模型的使用并不完全适合机器人技术。举个例子，如果你是厨房里的机器人，问语言模型“我卖掉了我的饮料，你能做什么？”，语言模型可能会给出一些不太相关的建议，比如让你用吸尘器吸尘、打电话给清洁工或者道歉。这些建议并不适合机器人在厨房里处理像溢漏排水管这样的问题。因此，问题的关键在于有两个方面：首先，是我们的机器人是有限的，它们的能力受到限制，不能做所有的事情，但可以做一些事情；其次，语言模型也有其局限性，不知道机器人看到了什么，也不明白微型机器人在厨房中需要在现实世界中执行的任务。因此，我们需要让机器人基于语言模型的指令行动，并让语言模型理解机器人所看到的情况。

为了让机器人能够说人类语言，我们通过相同的设置呈现事先确定的任务，例如“请拿桌子上的苹果”。机器人会根据语言模型对这些约束任务做出评分。我们知道机器人已经接受过训练，通过可供性函数获取的信息，可以估计在特定状态下机器人能够成功完成任务的信心度。在我们的例子中，我们使用强化学习中的价值函数等工具来评估任务完成的质量。通过结合语言模型和机器人的置信度，我们希望组合的预测结果能够与高级指令在语义上高度相关。在找到苹果这一第一步中，要求机器人把一个苹果放在桌子上。尽管框架中没有机器人，但机器人知道它已经接受过寻找苹果的训练，因此能够四处导航来找到苹果。我们期望机器人可以做到这一点，并在闭环环境中继续根据语言模型预测高级计划。

基于机器人的功能可用性，我们在这里有一个站点的视频，展示机器人在进行不同任务。我会很乐意稍后分享给你。离线功能也很酷，相信我，这是一次自从我们分享数字以来最伟大的事情。我们在Horizo​​n指令上进行了对此的测试，其中包括微型厨房中展示的10多个独立的导航和操作技能。我们进行了数百次不同的评估，测试了很多概念，包括通过绘制来自你认识的同事和朋友的方向。然后我们重新构建了单个原子从结果上发现，尽管它们在语言模型规划方面可能失败，会预测错误的路径，而且在政策执行方面，即使有一个良好的计划，机器人有时也会出错。总体而言，它们做得还不错。现在让我们这是一个很好的例子，展示了我们如何利用互联网规模基础模型。在启动一个项目时，我们使用了来自Google的名为flan的模型，同时也集成了Palm开发的Pathways语言模型。当我们需要调整语言模型时，我们可以轻松地进行更改，提升性能，而无需担心API计划中字符串的来源。虽然语言可以来自各种来源，包括人类和语言模型，但我们的系统经过优化后变得更加出色。通过扩大模型的规模，我们的性能得到了提升，并且我们还学会了一些使系统更加高效工作的技巧。这些改进不仅使得机器翻译计划变得更好，还为我们提供了新的机会。

在实际操作中，我们可以看到机器人能够执行各种任务，从理解不同语言到进行复杂的推理。例如，让它带来含有咖啡因的饮料，或者让它带来更健康的选择，如健康零食而不是不健康的零食。我认为这是我们团队中机器人与语言模型首次接触，探索这两个领域如何相互影响。尽管如此，还有改进的空间。我们正在尝试引入视觉语言模型来进一步提高性能。目前，语言模型虽然在计划上表现出色，但却无法真正从失败中恢复。也就是说，它无法获取实时事件信息。举个例子，如果让它拿可乐，但你把它弄翻了，它仍会继续尝试给你带来，而不会意识到已经出了问题。

不好意思，上述内容翻译混乱无法完全理解，请提供更多上下文或简化内容并再次提交，我会尽力帮助您中文翻译。

语言模型可以在活动场景中提出查询，类似于视觉问答。在这个过程中，语言模型需要足够的上下文信息才能继续进行下去。人类可以提供答案，或者在未来改进中，视觉问答模型也可以提供答案。为了让语言模型理解何时需要回溯到之前的内容，成功检测对于语言模型的规划者至关重要。

我们通过微调成功检测器，并在第一张和最后一张图像中提供成功或失败的信息，来帮助语言模型理解。结果显示，在第二次评估时，我们看到了相似的结果。有趣的是，我们成功地在机器人上实现了多种自动反馈机制，使得它能够推理和恢复事件，让它具备从现有情景中学习的能力。

当人们站在桌子旁时，他们可能改变主意，然后让机器人帮助他们解决问题。机器人可能会提示我们：尽管语言模型可能会遇到困难，但语言也可以重新编排以确保满足人类意图。我曾经试过对机器人进行对抗性输入，通过向机器人提出挑战，比如让它尝试从我手中夺取物体，然后提示机器人说：“嘿，你失败了，再试一次”。我们在模拟桌面操作和现实环境中尝试了不同的方法，发现这比仅仅依靠视觉功能和剪贴板更有效。这表明了一种新的可能性。

在2018年，一位机器人学教授曾提到，认为阻碍机器人学习大幅度扩展的所有因素中，瓶颈在于高水平的常识推理语义规划。我认为在2022年和2023年，语言模型可以提供一条路径，至少在过渡期间，可以如何减轻这个问题。如果语言模型是API，引入视觉语言模型可能是一个好主意，因为物体检测器变得更好，成功率会提高，就像在eqa中一样。随着模型变得更加完善，可以引入它们。如果你的机器人缺乏常识推理能力，ACT就是一种救生圈。其他模型可以充当生活中的脚手架，让你快速达到他们目前的水平。也许在将来，你将超越语言模型所涵盖的范围，但在短期内看，似乎可以利用它们来加速我们在现实世界中的工作。从现在我们看到的语言模型如何进行规划开始，我们也看到了视觉语言模型如何帮助规划。现在，我们需要换个角度思考视觉。

语言模型在解决机器人学习瓶颈方面发挥了很大的作用。数据收集一直是一个很大的挑战，特别是成本高昂。比如之前提到的那个拥有13万集演示数据的数据集，花费了大量的资源、时间和金钱，而且这些任务只是有限的。我们采用了700个非常模板化的命令指令，向电信运营商提供这些指令。这样做的原因是，只要为每一个模板化的任务收集足够的数据，我们就能完成特定任务。这个流程是之前很多人提出的。我们提供指令，操作员通过控制现实世界中的机器人来完成任务标记步骤，然后将其着色到一个大橙色的数据集中，这个数据集是我们之前针对控制策略进行训练的。最初我们考虑增加一些众包的智慧。

在强化学习中，机器人可能会执行一些不是简单指令的高级任务。如果您想让人类更详细地描述机器人的行为，比如它是否拿起了桌子旁边的可口可乐，或者它是怎么拿起的，移动到中间的速度如何。这种语义上的多样性可能超出了高级模板指令所涵盖的范围。因此，我们只标记了总数据的3%来提供更详细的描述。

接着，我们采用了类似于视频预训练的伪标签策略，而不是将其应用于指令语义。首先，在占主要数据集3%的小型标签数据集上预先训练模型，然后继续训练。

我们现在有一个重新标记的数据集，包含许多有趣的语义指令，涉及130,000个剧集数据。我们将所有这些数据都导入rt1中进行训练，以实施语言条件行为克隆策略。通常情况下我们只使用数据集B，橙色的数据集，但现在我们会将所有三个数据集都用上。最后，我们将评估全新的不可见指令。

在过去的工作中，我们主要评估了700个模板化指令，但现在我们实际上可以输入几乎任何你想要的东西，只要你认为有可能成功。你可以自由表达，甚至可以通过引用语义概念来实现。你可以加入空间概念。我们来看看结果如何。可能之所以有效的原因，也许可以在视觉上来说明这一点，这就是迪士尼嵌入。

左边和右边的内容是相同的，只是左边使用了原始模板指令来收集数据，而右边使用了视觉语言模型的思想。假如我们能够为每一组数据集加入一个自由形式的标题，你会看到左边有很多的类别，就像咱们平常所称的数百上千个类别，但右边的数据集则简称为“在右侧选择可乐罐”。此外，我们还可以延伸这一概念，比如指出某个数据集正在采集红色可乐罐，另一个正在采集绿色可乐罐，或者采集可乐罐旁的芯片袋等。通过利用语言多样性作为机制，我们能够从同一组原始数据集中获得更多的信息。借助这种机制，我们可以扩展我们所思考的概念，比如在数据集中心，可以采集打开顶层抽屉、抓取抽屉并拉开的情节，或者选取底部的一个选项，拿出绿色薯片，并将碗放置在那个袋子里。

在桌子的左下角，你会发现有很多语义，对吧。这意味着你理解了空间概念，现在这些概念出现在你的目标监督标签中。我有一个问题，确实是一个很好的问题。如果我可以稍微改一下，问题实际上非常有吸引力，即如何将你在户外所看到的所有空间概念映射到具体类型的剧集，就像这里。也许我想表达的是，我们引入了许多标签和偏见，比如我们说“左边”，你所指的是“左边10厘米，左边2厘米”。就像单词的意思是什么，这些定义对我们意味着什么。

对于这些标题的探讨，对机器人和语言模型意味着什么可能会有一些微妙的差异，但希望它们大致相似，这样我们将能够取得正确的改进方向。我认为这些细微的差别就像理解这些词的语义含义一样重要。或许这超出了现阶段的范围，但也许在更高层次上我们可以更深入地探讨。虽然我认为门槛可能有些低，我们有700个模板指令，它们基本上是模仿热门 ID，我们希望让它们更接近自然语言，即使只是一点点。我认为我们至少正在尝试以此为目标来实现。我们在尝试使用这些自动生成的视觉语言模型来回答您的问题。此外，我们也将一些低音线与左上角的对比，看看如果我们只训练其中三分之一的内容会发生什么。对于这些奇特的人类评级标签，我们想了解如果只在原始 rt1 数据集上进行训练，或者在这两个数据集上进行训练，会有怎样的情况。

如果我们把BLM给出的所有预测加入到这两个数据集中进行训练会发生什么呢？有趣的是，知道真实标签似乎是有帮助的。我们只评估了这个项目的新指令，这是机器人项目中的首次尝试。我们尝试输入任何我们认为会输入的内容，然后它就成了测试集。我们只需要确保它之前从未包含在训练数据中。你会看到很多有趣的例子，比如将孤独的物体移动到其他物体。我不清楚这是如何运作的，但就像你所知道的，只是抬起黄色矩形，谈论颜色，或者说将右边的苹果移到左边。在场景中我们实际上有两个苹果，但在我们的训练演示数据中我们从未有过具有重复对象的场景。因为我们思考到了多模态问题。如果你只说“pick cocannon”，然后有两个可乐罐，那么很难确定选择哪一个。但有了语言标签，似乎现在你可以做到这一点。即使我们以前从未在场景中进行过训练，现在有两个苹果，你也可以对它们进行评估，只需用简单的话来说，我讲一下我想要表达的意思。对于最后一个例子，我们尝试一种新颖的行为，不是按照传统方式来操作，而是尝试用一种不同的方式。其中，我们只是在靠近苹果的地方移动一块含有可卡因的海绵。这种行为本质上并不是我们想要的结果。或许这个概念可以通过另一个例子来解释，比如说你看到了一个苹果左边放着一个光滑的可乐罐，或者看到了海绵左边的蓝色可乐。在这种情况下，左边表示的并不是一个特定的物体，而可能是指这一侧的空间。我希望未来可以更深入地探讨这个现象。最后一个例子是我认为值得与非视觉增强进行比较的。也许你可以从我所说的语言中得到一些有趣的概念。

我们加入了随机噪音，或者使用了疯狂自由的交换单词风格，甚至可能使用LOM GPT-3来建议修改现有指令，但我认为关键是你需要了解视觉语言模型的基础，才能说实际情况如何。这个标题在特定时间点确实是准确的。也许对机器人来说，微调过程会很有趣，因为微调可能导致两个孩子都出事。当然，这里只是评估指令的一个子集，我们有超过60个评估指令。我们并未进行完整的定量消融测试，就像我们在rt1中进行的那样，在隐形任务中看到了这种情况，这是一个组合案例。例如，你看到要把可乐移到苹果旁边，你会看到把苹果移到海绵中，但我们坚持将可乐移到旋转物体旁边。我们会对此进行彻底测试。

我们可以做得更多，因为我们有完全自由的语言可以组合成各种各样的组合，这个组合空间正在不断扩展。我们正在尝试回答你的问题，尽管我们进行了一些组合评估，但还有更多需要深入了解的地方。我们可以在这方面做得更多。嗯，按时做就是了。好吧，花了10分钟，或许我马上就结束了。重点是，有两个部分，第二部分利用基础模型，我们可以将它们作为数据文档使用。第三部分是确保你知道离线数据集足够强大，可以应对这些不同的行为。如果你没有足够多样化的行为，可以用语言描述它们。无论标签有多好，如果你不能提取所有有趣的概念，可能都学不到。对我来说最激动人心的是，在监督学习和模仿学习中，标签噪声是可以接受的。你需要非常干净的标签，这些标签始终是100%准确的。你不想从噪声数据中学习，其中大部分都是不准确的。在我们的例子中，看起来是这样。

对于标签噪声的问题，我认为在一定程度上是可以接受的。视觉语言模型并不总是准确预测场景的描述。当噪声过高时会影响结果，但在较小的程度上，仍然能够处理问题。这需要深入研究。有些个人作品使用了这种大型语言配方，基础模型在机器人系统的不同部分有离线数据集支持。这是最初的推进方法。我们试图应用这些原则来加速机器人在现实世界中的学习。不同类型的成分和课程完全映射到机器人系统的不同部分来学习技能，这是我们讨论的主题。一个例子是用于规划的 rt1，即逗留时可以添加视觉语言模型的反馈，这是低级控制的内部对话。我们今天没有具体讨论这方面，但我们团队正在进行一项令人兴奋的工作，实际上是在利用语言进行。

现在我们可以使用模型来预测机器人执行代码的情况。这个模型可能作为低级控制器，有关增强数据以及使用视觉语言模型进行拨号的例子。在以对象为中心的表征方面，我们可以利用特定对象的特征来激活数学任务表示，用于对场景进行映射。这种导航方式围绕对象映射展开，比如微型厨房。未来几周和几个月，我们会继续扩展这些概念。当今的机器人系统虽然已有许多基础模型和离线数据集，但仍存在许多差距和机遇。通过探索性试点研究，我们可以应用这些图文并茂的高级概念，发现机器人系统中的差距和机会。在这个激动人心的研究方向上，我们可以尝试各种方法。

我认为在进行更广泛的评估和真正构建强大的系统方面都有价值。探索所有这些互补的方向非常有趣，但我们仍然面临一些主要问题，即如何进一步发展这些概念，以及这些趋势和想法如何向前发展。随着基础模型的不断改进，更多数据集在线可用，越来越多数据变得同质化、标记化和可互操作，我认为许多概念来自于其他领域，比如语言学和视觉。希望这些想法可以渗透到机器人技术中，甚至机器人技术也可以通过提供具体的动作因果数据集来取得一些进展。这些数据集可能会提高某些大型语言的推理质量，这在当前的模型中还没有得到充分体现。感谢大家的时间，也感谢戴维森帮我解答关于论文的问题。

我非常感谢你提出这些很好的问题。关于需要更多语义推理任务的问题，比如在某一速度下运行，或者类似我不知道泵本身数字推理的问题，我觉得目前很多常识推理任务，比如扔掉三个可乐罐之类的，语言模型已经做得很好了。对于第二个问题，模型可以预测不同的可乐罐被扔掉的时间。对于低水平技能政策学习，尽管可能有更高的方差，但是现在我们已经在这方面取得了很好的进展。

并不真正在乎速度如何，只是想知道你是怎么做的。这对我来说是可以实现的。如果你能用类似“慢慢拿起可卡因”这样的标签来解释，而不是“快速拿起可卡因”，也许这对视觉模型代码的理解会更有帮助。这其实是一个很好的问题哦。我们正在探讨的是在组合概念中的规模是多大，也许是在你看到一块颜色间的转变，然后你尝试评估一种新颜色。我认为这是一个很有意思的研究课题。不幸的是，我的回答可能会有些模糊。这取决于你如何定义你的任务，取决于你的数据集规模，取决于你的研究目标。

我认为概括概念，在学习和机器人技术领域的正式化和分类尝试已经很多了。但在具体情境下，并没有明显的趋势。比如，你可能会需要用数字来概括某个概念，就像评估一样。但我不认为这有助于预测新趋势。在我们开始进行广义概括之前，我想指出，当数据集增加几个数量级时，我们可以讨论技能层面的任务。

观察很敏锐，问题是，对这些数值函数进行预测可能只存储有限数量的任务，因此瓶颈在于系统能够执行的任务数量受限。你可以扩展系统能执行的任务数量至100个，然后将其作为规划器的自主选择选项。无论规划器多么出色，如果只能这样做，这就是一个瓶颈。只有这三个任务的某些组合可以映射到高级指令，随着机器人低层技能能力的增加，您可以添加更多任务。您可以认为这样提高了机器人尝试执行的高级指令的精度范围。这是我今天看到的主要瓶颈之一。谢谢。

你问得很好。我们是否尝试过使用 rohf 或 RL 来进行 rt1 呢？短期内，我觉得我们正在尝试一些方法。目前，对于我们所有的项目来说，我们只是再次运用这种实现学习过程。我觉得我们正在尝试的这种多任务变异赌注是行之有效的。虽然并不廉价，但的确行之有效，并且有规模。这至少是个不错的起点。接下来几个月甚至几年，我们的主要希望是能够超越这个起点，我们是否能够添加离线改进呢？是否能够以某种方式将我们的经验添加到等式中呢？我本质上是个喜欢尝试新方法的人，所以我真的期待着。是的，我们会继续努力的。

我觉得你在谈论任务平衡和对纯文本数据的偏好对于类似运动控制学习的帮助。我想说的是，当我们了解模型之后，当我们同时涉足机器人空间和语言空间时，也许这些推理概念可以开始在两者之间转移。你可以向他们推荐一篇有趣的论文，我认为维基百科可能有助于加强学习。这篇论文来自Shane和其他一些人，他们预先训练了一个大型策略网络，就像自动激进令牌预测维基百科中的文本那样来初始化雅达利游戏的控制，这实际上非常有帮助。也许在文本和动作数据之间存在一些关于决策推理的东西可以实现传输。所以，我想问一个与此相关的问题。

我完全同意你的说法。当我们试图完成一个需要几分钟的任务（比如清理整个房子）时，传递六张图片显然是不够的。我们只能传递最后一张图片，就像只看到最后两秒钟一样。

这绝对会成为一个限制，特别是当我们的任务变得越来越复杂时。这也是一个悬而未决的问题，即上下文的长度。即使我们使用令牌学习来减少通过的补丁数量，但由于我们处理的是高维图像，我们仍然面临非常高维度的挑战。我们很快就会达到上下文长度的极限。我们能做些什么来改进呢？也许我们需要像检索变形金刚或其他类型的机制学习这样的方法来解决这个大问题。

我认为这是一个非常重要的问题，我希望未来我们能够深入探讨。但由于上下文长度的限制，我们已经接近上下文长度的容量极限。如果仅用六张图片就已经困难重重，更不用说传递整个镜头行为的轨迹了。我们期待着能够看到更多的改进。

2bd 是个很酷的点子，谢谢你的分享。